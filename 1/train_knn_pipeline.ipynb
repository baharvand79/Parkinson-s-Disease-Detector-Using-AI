{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-10T21:25:52.066907Z",
     "start_time": "2025-09-10T21:25:46.341387Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib # NEW: For saving the k-NN model\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import (Input, Conv2D, MaxPooling2D, Dropout, Flatten,\n",
    "                                     Dense, LSTM, MultiHeadAttention, Concatenate, Reshape)\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier # NEW: Import k-NN\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay # NEW: For k-NN evaluation\n",
    "\n",
    "# =============================================================================\n",
    "# --- Configuration --\n",
    "# =============================================================================\n",
    "\n",
    "# --- SELECT YOUR CONFIGURATION HERE ---\n",
    "DATASET = \"MPOWER_DATASET\"\n",
    "MODE = \"ALL_VALIDS\"\n",
    "FEATURE_MODE = \"ALL\"\n",
    "MODEL_NAME = \"feature_extractor_cnn_att_lstm\" # MODIFIED: Model name updated\n",
    "# ------------------------------------\n",
    "\n",
    "# Path Setup\n",
    "dataset = \"mPower\"\n",
    "FEATURES_FILE_PATH = os.path.join(os.getcwd(), dataset, \"data\", f\"features_{MODE}_{FEATURE_MODE}.npz\")\n",
    "RESULTS_PATH = os.path.join(os.getcwd(), dataset, f\"results_{MODE}_{FEATURE_MODE}\")\n",
    "MODEL_PATH = os.path.join(RESULTS_PATH, MODEL_NAME)\n",
    "os.makedirs(MODEL_PATH, exist_ok=True)\n",
    "\n",
    "HISTORY_SAVE_PATH = os.path.join(MODEL_PATH, \"history.csv\")\n",
    "BEST_EXTRACTOR_PATH = os.path.join(MODEL_PATH, \"best_feature_extractor.keras\") # MODIFIED: Path name updated\n",
    "KNN_MODEL_PATH = os.path.join(MODEL_PATH, \"knn_classifier.joblib\") # NEW: Path for k-NN model\n",
    "\n",
    "# Hyperparameters\n",
    "EPOCHS = 30\n",
    "BATCH_SIZE = 32\n",
    "LEARNING_RATE = 0.001\n",
    "DROPOUT_RATE = 0.5\n",
    "L2_STRENGTH = 0.01\n",
    "K_NEIGHBORS = 5 # NEW: k for the k-NN classifier\n",
    "\n",
    "# Model Checkpoint Callback\n",
    "# We still need a final dense layer during training to learn the features effectively\n",
    "checkpoint_cb = ModelCheckpoint(BEST_EXTRACTOR_PATH, monitor='val_loss', mode='min', save_best_only=True, verbose=1)\n",
    "\n",
    "# =============================================================================\n",
    "# --- Data Loading and Preparation ---\n",
    "# =============================================================================\n",
    "\n",
    "def load_data(path: str) -> tuple:\n",
    "    \"\"\"\n",
    "    MODIFIED: Loads only features and labels from the .npz file, excluding age and sex.\n",
    "    \"\"\"\n",
    "    print(f\"--- Loading data from {path} ---\")\n",
    "    with np.load(path) as data:\n",
    "        mel_spectrograms = data['mel_spectrogram']\n",
    "        mfccs = data['mfcc']\n",
    "        labels = data['labels']\n",
    "        # Combine mel spectrograms and MFCCs\n",
    "        X = np.concatenate((mel_spectrograms, mfccs), axis=1)\n",
    "    print(\"Data loaded successfully.\")\n",
    "    return X, labels\n",
    "\n",
    "# =============================================================================\n",
    "# --- Model Architecture (Feature Extractor) ---\n",
    "# =============================================================================\n",
    "from tensorflow.keras.saving import register_keras_serializable\n",
    "\n",
    "@register_keras_serializable()\n",
    "class FeatureExtractor(Model):\n",
    "    \"\"\"\n",
    "    MODIFIED: This model is now just the feature extractor.\n",
    "    It stops before the final classification layers.\n",
    "    \"\"\"\n",
    "    def __init__(self, input_shape, **kwargs):\n",
    "        super(FeatureExtractor, self).__init__(**kwargs)\n",
    "        self.input_shape_config = input_shape\n",
    "\n",
    "        # CNN Layers\n",
    "        self.reshape_in = Reshape((input_shape[0], input_shape[1], 1))\n",
    "        self.conv1a = Conv2D(64, 5, activation='relu', kernel_regularizer=l2(L2_STRENGTH), padding='same')\n",
    "        self.conv1b = Conv2D(64, 5, activation='relu', kernel_regularizer=l2(L2_STRENGTH), padding='same')\n",
    "        self.pool1 = MaxPooling2D(5)\n",
    "        self.drop1 = Dropout(DROPOUT_RATE)\n",
    "        self.conv2a = Conv2D(64, 5, activation='relu', kernel_regularizer=l2(L2_STRENGTH), padding='same')\n",
    "        self.conv2b = Conv2D(64, 5, activation='relu', kernel_regularizer=l2(L2_STRENGTH), padding='same')\n",
    "        self.pool2 = MaxPooling2D(5)\n",
    "        self.drop2 = Dropout(DROPOUT_RATE)\n",
    "        self.flatten_cnn = Flatten()\n",
    "\n",
    "        # Attention and LSTM Layers\n",
    "        self.attention = MultiHeadAttention(num_heads=2, key_dim=64)\n",
    "        self.flatten_att = Flatten()\n",
    "        self.lstm1 = LSTM(128, return_sequences=True)\n",
    "        self.lstm2 = LSTM(128, return_sequences=False)\n",
    "        self.drop_lstm = Dropout(DROPOUT_RATE)\n",
    "\n",
    "        # Final Concatenation to produce the feature vector (embedding)\n",
    "        self.concat = Concatenate(name='embedding_output')\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # CNN Path\n",
    "        x = self.reshape_in(inputs)\n",
    "        x = self.conv1a(x)\n",
    "        x = self.conv1b(x)\n",
    "        x = self.pool1(x)\n",
    "        x = self.drop1(x)\n",
    "        x = self.conv2a(x)\n",
    "        x = self.conv2b(x)\n",
    "        x = self.pool2(x)\n",
    "        x = self.drop2(x)\n",
    "        cnn_flat = self.flatten_cnn(x)\n",
    "\n",
    "        # Attention and LSTM Path\n",
    "        shape = tf.shape(x)\n",
    "        sequence = tf.reshape(x, [-1, shape[1] * shape[2], shape[3]])\n",
    "        att_out = self.attention(query=sequence, key=sequence, value=sequence)\n",
    "        att_flat = self.flatten_att(att_out)\n",
    "        lstm_seq = self.lstm1(sequence)\n",
    "        lstm_out = self.lstm2(lstm_seq)\n",
    "        lstm_out = self.drop_lstm(lstm_out)\n",
    "\n",
    "        # MODIFIED: The output is the concatenated feature vector.\n",
    "        return self.concat([cnn_flat, att_flat, lstm_out])\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super(FeatureExtractor, self).get_config()\n",
    "        config.update({\"input_shape\": self.input_shape_config})\n",
    "        return config\n",
    "\n",
    "    @classmethod\n",
    "    def from_config(cls, config):\n",
    "        return cls(**config)\n",
    "\n",
    "def build_training_model(input_shape: tuple) -> Model:\n",
    "    \"\"\"\n",
    "    MODIFIED: Builds a temporary model for training the feature extractor.\n",
    "    This includes a final dense layer needed for calculating loss during training.\n",
    "    \"\"\"\n",
    "    print(\"--- Building the training model ---\")\n",
    "    inputs = Input(shape=input_shape)\n",
    "\n",
    "    # Instantiate the feature extractor\n",
    "    feature_extractor = FeatureExtractor(input_shape=input_shape)\n",
    "\n",
    "    # Get the embedding output\n",
    "    embeddings = feature_extractor(inputs)\n",
    "\n",
    "    # Add a temporary classification head for training purposes\n",
    "    outputs = Dense(1, activation='sigmoid', name='classification_head')(embeddings)\n",
    "\n",
    "    # Create the training model\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "    print(\"Training model built successfully.\")\n",
    "    return model\n",
    "\n",
    "# =============================================================================\n",
    "# --- NEW: k-NN Training and Evaluation ---\n",
    "# =============================================================================\n",
    "from sklearn.preprocessing import StandardScaler # NEW: For feature scaling\n",
    "from sklearn.model_selection import GridSearchCV # NEW: For hyperparameter tuning\n",
    "\n",
    "# =============================================================================\n",
    "# --- MODIFIED: k-NN Training, Tuning, and Evaluation ---\n",
    "# =============================================================================\n",
    "\n",
    "def train_and_evaluate_knn(X_train_features, y_train, X_test_features, y_test):\n",
    "    \"\"\"\n",
    "    MODIFIED: Scales features, finds the best k-NN hyperparameters using GridSearchCV,\n",
    "    trains the best model, and evaluates it.\n",
    "    \"\"\"\n",
    "    # --- 1. Scale the Extracted Features ---\n",
    "    print(\"\\n--- Scaling Features ---\")\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    # Fit the scaler on the TRAINING data and transform it\n",
    "    X_train_scaled = scaler.fit_transform(X_train_features)\n",
    "\n",
    "    # Apply the SAME transformation to the test data\n",
    "    X_test_scaled = scaler.transform(X_test_features)\n",
    "    print(\"Features scaled successfully.\")\n",
    "\n",
    "    # --- 2. Hyperparameter Tuning with GridSearchCV ---\n",
    "    print(\"\\n--- Searching for the best k-NN hyperparameters ---\")\n",
    "\n",
    "    # Define the grid of parameters to search\n",
    "    param_grid = {\n",
    "        'n_neighbors': [3, 5, 7, 9, 11, 13, 15], # Test a range of odd numbers for k\n",
    "        'weights': ['uniform', 'distance'],      # Test uniform vs. distance-weighted voting\n",
    "        'metric': ['euclidean', 'manhattan']     # Test different distance metrics\n",
    "    }\n",
    "\n",
    "    # Set up the grid search with 5-fold cross-validation\n",
    "    grid_search = GridSearchCV(\n",
    "        KNeighborsClassifier(),\n",
    "        param_grid,\n",
    "        cv=5, # 5-fold cross-validation\n",
    "        scoring='accuracy',\n",
    "        verbose=1,\n",
    "        n_jobs=-1 # Use all available CPU cores\n",
    "    )\n",
    "\n",
    "    # Run the search on the scaled training data\n",
    "    grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "    # --- 3. Train and Evaluate the Best Model ---\n",
    "    print(\"\\n--- Best Hyperparameters Found ---\")\n",
    "    print(grid_search.best_params_)\n",
    "\n",
    "    # Get the best model found by the grid search\n",
    "    best_knn = grid_search.best_estimator_\n",
    "\n",
    "    # Save the best trained k-NN model\n",
    "    joblib.dump(best_knn, KNN_MODEL_PATH)\n",
    "    print(f\"\\nBest k-NN model saved to '{KNN_MODEL_PATH}'\")\n",
    "\n",
    "    # --- Evaluation ---\n",
    "    print(\"\\n--- Evaluating Best k-NN on Test Set ---\")\n",
    "    y_pred = best_knn.predict(X_test_scaled)\n",
    "\n",
    "    # Print classification report\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, y_pred, target_names=['Healthy', 'Parkinson']))\n",
    "\n",
    "    # Plot and save confusion matrix\n",
    "    print(\"Confusion Matrix:\")\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Healthy', 'Parkinson'])\n",
    "    disp.plot(cmap=plt.cm.Blues)\n",
    "    plt.title(\"Best k-NN Confusion Matrix\")\n",
    "    cm_path = os.path.join(MODEL_PATH, \"knn_best_confusion_matrix.png\")\n",
    "    plt.savefig(cm_path, dpi=300)\n",
    "    plt.show()\n",
    "    print(f\"Confusion matrix saved to '{cm_path}'\")"
   ],
   "id": "2757f64f1f4066",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-10T21:54:06.196161400Z",
     "start_time": "2025-09-10T21:53:07.947009Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import joblib\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier, NeighborhoodComponentsAnalysis\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "def tune_and_evaluate_knn_pipeline(X_train, y_train, X_test, y_test, results_path):\n",
    "    \"\"\"\n",
    "    Streamlined to find the best k-NN pipeline using SMOTE for class\n",
    "    imbalance and NCA for dimensionality reduction.\n",
    "    \"\"\"\n",
    "    # --- 1. Define the Optimized k-NN Pipeline and Search Space ---\n",
    "    # This pipeline bundles scaling, resampling (SMOTE), dimensionality reduction (NCA),\n",
    "    # and the final classifier (k-NN).\n",
    "    knn_pipeline = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('smote', SMOTE(random_state=42)),\n",
    "        ('nca', NeighborhoodComponentsAnalysis(random_state=42)),\n",
    "        ('classifier', KNeighborsClassifier())\n",
    "    ])\n",
    "\n",
    "    # Define the parameters to be tuned for each step of the pipeline\n",
    "    param_dist = {\n",
    "        'nca__n_components': [10, 13, 16, 20, 25, 31],\n",
    "        'classifier__n_neighbors': [5, 7, 9, 11, 13, 15],\n",
    "        'classifier__weights': ['distance'],\n",
    "        'classifier__metric': ['manhattan']\n",
    "    }\n",
    "\n",
    "    # --- 2. Run the Automated Hyperparameter Search ---\n",
    "    print(\"\\n--- Tuning Optimized k-NN Pipeline ---\")\n",
    "\n",
    "    # Use RandomizedSearchCV for an efficient search\n",
    "    search = RandomizedSearchCV(\n",
    "        knn_pipeline,\n",
    "        param_dist,\n",
    "        n_iter=15,\n",
    "        cv=5,\n",
    "        scoring='roc_auc',\n",
    "        random_state=42,\n",
    "        verbose=1\n",
    "    )\n",
    "    search.fit(X_train, y_train)\n",
    "\n",
    "    # --- 3. Evaluate, Report, and Save the Best Model ---\n",
    "    best_pipeline = search.best_estimator_\n",
    "    y_pred = best_pipeline.predict(X_test)\n",
    "    test_accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    print(f\"\\nBest cross-validation score: {search.best_score_:.4f}\")\n",
    "\n",
    "    print(\"\\n\\n--- Detailed Report for Best k-NN Pipeline ---\")\n",
    "    print(f\"Test Set Accuracy: {test_accuracy:.4f}\")\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, y_pred, digits=4))\n",
    "    print(\"\\nBest Hyperparameters Found:\")\n",
    "    print(search.best_params_)\n",
    "\n",
    "    # Save the best pipeline object to a file for future use\n",
    "    best_pipeline_path = os.path.join(results_path, \"best_knn_pipeline.joblib\")\n",
    "    joblib.dump(best_pipeline, best_pipeline_path)\n",
    "    print(f\"\\n✅ Best k-NN pipeline saved to: {best_pipeline_path}\")"
   ],
   "id": "ce3de42b44fd6385",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-10T21:43:01.775460Z",
     "start_time": "2025-09-10T21:25:56.429030Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# =============================================================================\n",
    "# --- Main Execution ---\n",
    "# =============================================================================\n",
    "if __name__ == '__main__':\n",
    "    # MODIFIED: Load data without age and sex\n",
    "    X, y = load_data(FEATURES_FILE_PATH)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42, stratify=y\n",
    "    )\n",
    "    print(f\"\\nData split into training ({len(y_train)}) and testing ({len(y_test)}) sets.\")\n",
    "\n",
    "    # 1. Train the Feature Extractor\n",
    "    training_model = build_training_model(input_shape=(X_train.shape[1], X_train.shape[2]))\n",
    "    training_model.summary()\n",
    "\n",
    "    optimizer = Adam(learning_rate=LEARNING_RATE)\n",
    "    training_model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    print(\"\\n--- Starting feature extractor training ---\")\n",
    "    history = training_model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_test, y_test),\n",
    "        epochs=EPOCHS,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        callbacks=[checkpoint_cb],\n",
    "        verbose=1\n",
    "    )\n",
    "    print(\"--- Feature extractor training finished ---\")\n",
    "    pd.DataFrame(history.history).to_csv(HISTORY_SAVE_PATH, index_label='epoch')\n",
    "    print(f\"\\nTraining history saved to '{HISTORY_SAVE_PATH}'\")"
   ],
   "id": "7dabca2748e3ffdc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Loading data from D:\\Projects\\Voice\\Parkinson-s-Disease-Detector-Using-AI\\Parkinson-s-Disease-Detector-Using-AI\\1\\mPower\\data\\features_ALL_VALIDS_ALL.npz ---\n",
      "Data loaded successfully.\n",
      "\n",
      "Data split into training (1664) and testing (416) sets.\n",
      "--- Building the training model ---\n",
      "WARNING:tensorflow:From C:\\Users\\bahar\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\core.py:232: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "Training model built successfully.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1mModel: \"functional\"\u001B[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001B[1m \u001B[0m\u001B[1mLayer (type)                   \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mOutput Shape          \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m      Param #\u001B[0m\u001B[1m \u001B[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (\u001B[38;5;33mInputLayer\u001B[0m)        │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m60\u001B[0m, \u001B[38;5;34m94\u001B[0m)         │             \u001B[38;5;34m0\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ feature_extractor               │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m896\u001B[0m)            │       \u001B[38;5;34m572,672\u001B[0m │\n",
       "│ (\u001B[38;5;33mFeatureExtractor\u001B[0m)              │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ classification_head (\u001B[38;5;33mDense\u001B[0m)     │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m1\u001B[0m)              │           \u001B[38;5;34m897\u001B[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">94</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ feature_extractor               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">572,672</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">FeatureExtractor</span>)              │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ classification_head (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">897</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Total params: \u001B[0m\u001B[38;5;34m573,569\u001B[0m (2.19 MB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">573,569</span> (2.19 MB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Trainable params: \u001B[0m\u001B[38;5;34m573,569\u001B[0m (2.19 MB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">573,569</span> (2.19 MB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Non-trainable params: \u001B[0m\u001B[38;5;34m0\u001B[0m (0.00 B)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Starting feature extractor training ---\n",
      "Epoch 1/30\n",
      "\u001B[1m52/52\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 420ms/step - accuracy: 0.5356 - loss: 4.6076\n",
      "Epoch 1: val_loss improved from None to 2.55848, saving model to D:\\Projects\\Voice\\Parkinson-s-Disease-Detector-Using-AI\\Parkinson-s-Disease-Detector-Using-AI\\1\\mPower\\results_ALL_VALIDS_ALL\\feature_extractor_cnn_att_lstm\\best_feature_extractor.keras\n",
      "\u001B[1m52/52\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m32s\u001B[0m 465ms/step - accuracy: 0.5114 - loss: 3.2799 - val_accuracy: 0.5168 - val_loss: 2.5585\n",
      "Epoch 2/30\n",
      "\u001B[1m52/52\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 517ms/step - accuracy: 0.4993 - loss: 2.5207\n",
      "Epoch 2: val_loss improved from 2.55848 to 2.33255, saving model to D:\\Projects\\Voice\\Parkinson-s-Disease-Detector-Using-AI\\Parkinson-s-Disease-Detector-Using-AI\\1\\mPower\\results_ALL_VALIDS_ALL\\feature_extractor_cnn_att_lstm\\best_feature_extractor.keras\n",
      "\u001B[1m52/52\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m29s\u001B[0m 558ms/step - accuracy: 0.4994 - loss: 2.4632 - val_accuracy: 0.5048 - val_loss: 2.3325\n",
      "Epoch 3/30\n",
      "\u001B[1m52/52\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 502ms/step - accuracy: 0.5194 - loss: 2.2904\n",
      "Epoch 3: val_loss improved from 2.33255 to 2.11216, saving model to D:\\Projects\\Voice\\Parkinson-s-Disease-Detector-Using-AI\\Parkinson-s-Disease-Detector-Using-AI\\1\\mPower\\results_ALL_VALIDS_ALL\\feature_extractor_cnn_att_lstm\\best_feature_extractor.keras\n",
      "\u001B[1m52/52\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m28s\u001B[0m 537ms/step - accuracy: 0.5186 - loss: 2.2326 - val_accuracy: 0.5120 - val_loss: 2.1122\n",
      "Epoch 4/30\n",
      "\u001B[1m52/52\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 441ms/step - accuracy: 0.5179 - loss: 2.0638\n",
      "Epoch 4: val_loss improved from 2.11216 to 1.91295, saving model to D:\\Projects\\Voice\\Parkinson-s-Disease-Detector-Using-AI\\Parkinson-s-Disease-Detector-Using-AI\\1\\mPower\\results_ALL_VALIDS_ALL\\feature_extractor_cnn_att_lstm\\best_feature_extractor.keras\n",
      "\u001B[1m52/52\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m25s\u001B[0m 474ms/step - accuracy: 0.5168 - loss: 2.0194 - val_accuracy: 0.5505 - val_loss: 1.9129\n",
      "Epoch 5/30\n",
      "\u001B[1m52/52\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 434ms/step - accuracy: 0.5303 - loss: 1.8754\n",
      "Epoch 5: val_loss improved from 1.91295 to 1.73988, saving model to D:\\Projects\\Voice\\Parkinson-s-Disease-Detector-Using-AI\\Parkinson-s-Disease-Detector-Using-AI\\1\\mPower\\results_ALL_VALIDS_ALL\\feature_extractor_cnn_att_lstm\\best_feature_extractor.keras\n",
      "\u001B[1m52/52\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m25s\u001B[0m 481ms/step - accuracy: 0.5319 - loss: 1.8380 - val_accuracy: 0.5505 - val_loss: 1.7399\n",
      "Epoch 6/30\n",
      "\u001B[1m52/52\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 728ms/step - accuracy: 0.4788 - loss: 1.7150\n",
      "Epoch 6: val_loss improved from 1.73988 to 1.59626, saving model to D:\\Projects\\Voice\\Parkinson-s-Disease-Detector-Using-AI\\Parkinson-s-Disease-Detector-Using-AI\\1\\mPower\\results_ALL_VALIDS_ALL\\feature_extractor_cnn_att_lstm\\best_feature_extractor.keras\n",
      "\u001B[1m52/52\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m40s\u001B[0m 771ms/step - accuracy: 0.4982 - loss: 1.6772 - val_accuracy: 0.5553 - val_loss: 1.5963\n",
      "Epoch 7/30\n",
      "\u001B[1m52/52\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 754ms/step - accuracy: 0.5242 - loss: 1.5696\n",
      "Epoch 7: val_loss improved from 1.59626 to 1.46572, saving model to D:\\Projects\\Voice\\Parkinson-s-Disease-Detector-Using-AI\\Parkinson-s-Disease-Detector-Using-AI\\1\\mPower\\results_ALL_VALIDS_ALL\\feature_extractor_cnn_att_lstm\\best_feature_extractor.keras\n",
      "\u001B[1m52/52\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m42s\u001B[0m 806ms/step - accuracy: 0.5264 - loss: 1.5379 - val_accuracy: 0.5216 - val_loss: 1.4657\n",
      "Epoch 8/30\n",
      "\u001B[1m52/52\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 848ms/step - accuracy: 0.5405 - loss: 1.4396\n",
      "Epoch 8: val_loss improved from 1.46572 to 1.35401, saving model to D:\\Projects\\Voice\\Parkinson-s-Disease-Detector-Using-AI\\Parkinson-s-Disease-Detector-Using-AI\\1\\mPower\\results_ALL_VALIDS_ALL\\feature_extractor_cnn_att_lstm\\best_feature_extractor.keras\n",
      "\u001B[1m52/52\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m47s\u001B[0m 906ms/step - accuracy: 0.5505 - loss: 1.4137 - val_accuracy: 0.5457 - val_loss: 1.3540\n",
      "Epoch 9/30\n",
      "\u001B[1m52/52\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 809ms/step - accuracy: 0.5729 - loss: 1.3316\n",
      "Epoch 9: val_loss improved from 1.35401 to 1.25135, saving model to D:\\Projects\\Voice\\Parkinson-s-Disease-Detector-Using-AI\\Parkinson-s-Disease-Detector-Using-AI\\1\\mPower\\results_ALL_VALIDS_ALL\\feature_extractor_cnn_att_lstm\\best_feature_extractor.keras\n",
      "\u001B[1m52/52\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m45s\u001B[0m 871ms/step - accuracy: 0.5655 - loss: 1.3047 - val_accuracy: 0.5673 - val_loss: 1.2513\n",
      "Epoch 10/30\n",
      "\u001B[1m52/52\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 824ms/step - accuracy: 0.5478 - loss: 1.2523\n",
      "Epoch 10: val_loss improved from 1.25135 to 1.17730, saving model to D:\\Projects\\Voice\\Parkinson-s-Disease-Detector-Using-AI\\Parkinson-s-Disease-Detector-Using-AI\\1\\mPower\\results_ALL_VALIDS_ALL\\feature_extractor_cnn_att_lstm\\best_feature_extractor.keras\n",
      "\u001B[1m52/52\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m46s\u001B[0m 888ms/step - accuracy: 0.5415 - loss: 1.2254 - val_accuracy: 0.5312 - val_loss: 1.1773\n",
      "Epoch 11/30\n",
      "\u001B[1m52/52\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 830ms/step - accuracy: 0.5522 - loss: 1.1569\n",
      "Epoch 11: val_loss improved from 1.17730 to 1.11345, saving model to D:\\Projects\\Voice\\Parkinson-s-Disease-Detector-Using-AI\\Parkinson-s-Disease-Detector-Using-AI\\1\\mPower\\results_ALL_VALIDS_ALL\\feature_extractor_cnn_att_lstm\\best_feature_extractor.keras\n",
      "\u001B[1m52/52\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m46s\u001B[0m 884ms/step - accuracy: 0.5535 - loss: 1.1465 - val_accuracy: 0.5072 - val_loss: 1.1134\n",
      "Epoch 12/30\n",
      "\u001B[1m52/52\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 873ms/step - accuracy: 0.5528 - loss: 1.0961\n",
      "Epoch 12: val_loss improved from 1.11345 to 1.05007, saving model to D:\\Projects\\Voice\\Parkinson-s-Disease-Detector-Using-AI\\Parkinson-s-Disease-Detector-Using-AI\\1\\mPower\\results_ALL_VALIDS_ALL\\feature_extractor_cnn_att_lstm\\best_feature_extractor.keras\n",
      "\u001B[1m52/52\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m48s\u001B[0m 933ms/step - accuracy: 0.5571 - loss: 1.0816 - val_accuracy: 0.5553 - val_loss: 1.0501\n",
      "Epoch 13/30\n",
      "\u001B[1m52/52\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 856ms/step - accuracy: 0.5627 - loss: 1.0337\n",
      "Epoch 13: val_loss improved from 1.05007 to 0.99466, saving model to D:\\Projects\\Voice\\Parkinson-s-Disease-Detector-Using-AI\\Parkinson-s-Disease-Detector-Using-AI\\1\\mPower\\results_ALL_VALIDS_ALL\\feature_extractor_cnn_att_lstm\\best_feature_extractor.keras\n",
      "\u001B[1m52/52\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m49s\u001B[0m 945ms/step - accuracy: 0.5637 - loss: 1.0239 - val_accuracy: 0.5481 - val_loss: 0.9947\n",
      "Epoch 14/30\n",
      "\u001B[1m52/52\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 921ms/step - accuracy: 0.5776 - loss: 0.9874\n",
      "Epoch 14: val_loss improved from 0.99466 to 0.95031, saving model to D:\\Projects\\Voice\\Parkinson-s-Disease-Detector-Using-AI\\Parkinson-s-Disease-Detector-Using-AI\\1\\mPower\\results_ALL_VALIDS_ALL\\feature_extractor_cnn_att_lstm\\best_feature_extractor.keras\n",
      "\u001B[1m52/52\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m51s\u001B[0m 991ms/step - accuracy: 0.5787 - loss: 0.9724 - val_accuracy: 0.5625 - val_loss: 0.9503\n",
      "Epoch 15/30\n",
      "\u001B[1m52/52\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 822ms/step - accuracy: 0.5739 - loss: 0.9502\n",
      "Epoch 15: val_loss improved from 0.95031 to 0.92498, saving model to D:\\Projects\\Voice\\Parkinson-s-Disease-Detector-Using-AI\\Parkinson-s-Disease-Detector-Using-AI\\1\\mPower\\results_ALL_VALIDS_ALL\\feature_extractor_cnn_att_lstm\\best_feature_extractor.keras\n",
      "\u001B[1m52/52\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m46s\u001B[0m 888ms/step - accuracy: 0.5685 - loss: 0.9422 - val_accuracy: 0.5577 - val_loss: 0.9250\n",
      "Epoch 16/30\n",
      "\u001B[1m52/52\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 841ms/step - accuracy: 0.5544 - loss: 0.9226\n",
      "Epoch 16: val_loss improved from 0.92498 to 0.88043, saving model to D:\\Projects\\Voice\\Parkinson-s-Disease-Detector-Using-AI\\Parkinson-s-Disease-Detector-Using-AI\\1\\mPower\\results_ALL_VALIDS_ALL\\feature_extractor_cnn_att_lstm\\best_feature_extractor.keras\n",
      "\u001B[1m52/52\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m47s\u001B[0m 913ms/step - accuracy: 0.5787 - loss: 0.9071 - val_accuracy: 0.5913 - val_loss: 0.8804\n",
      "Epoch 17/30\n",
      "\u001B[1m52/52\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 624ms/step - accuracy: 0.5628 - loss: 0.8920\n",
      "Epoch 17: val_loss improved from 0.88043 to 0.87542, saving model to D:\\Projects\\Voice\\Parkinson-s-Disease-Detector-Using-AI\\Parkinson-s-Disease-Detector-Using-AI\\1\\mPower\\results_ALL_VALIDS_ALL\\feature_extractor_cnn_att_lstm\\best_feature_extractor.keras\n",
      "\u001B[1m52/52\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m35s\u001B[0m 669ms/step - accuracy: 0.5739 - loss: 0.8759 - val_accuracy: 0.5264 - val_loss: 0.8754\n",
      "Epoch 18/30\n",
      "\u001B[1m52/52\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 578ms/step - accuracy: 0.5773 - loss: 0.8571\n",
      "Epoch 18: val_loss improved from 0.87542 to 0.83129, saving model to D:\\Projects\\Voice\\Parkinson-s-Disease-Detector-Using-AI\\Parkinson-s-Disease-Detector-Using-AI\\1\\mPower\\results_ALL_VALIDS_ALL\\feature_extractor_cnn_att_lstm\\best_feature_extractor.keras\n",
      "\u001B[1m52/52\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m32s\u001B[0m 623ms/step - accuracy: 0.5865 - loss: 0.8509 - val_accuracy: 0.5505 - val_loss: 0.8313\n",
      "Epoch 19/30\n",
      "\u001B[1m52/52\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 449ms/step - accuracy: 0.6033 - loss: 0.8280\n",
      "Epoch 19: val_loss improved from 0.83129 to 0.82477, saving model to D:\\Projects\\Voice\\Parkinson-s-Disease-Detector-Using-AI\\Parkinson-s-Disease-Detector-Using-AI\\1\\mPower\\results_ALL_VALIDS_ALL\\feature_extractor_cnn_att_lstm\\best_feature_extractor.keras\n",
      "\u001B[1m52/52\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m26s\u001B[0m 491ms/step - accuracy: 0.5992 - loss: 0.8269 - val_accuracy: 0.5769 - val_loss: 0.8248\n",
      "Epoch 20/30\n",
      "\u001B[1m52/52\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 454ms/step - accuracy: 0.5591 - loss: 0.8237\n",
      "Epoch 20: val_loss improved from 0.82477 to 0.79652, saving model to D:\\Projects\\Voice\\Parkinson-s-Disease-Detector-Using-AI\\Parkinson-s-Disease-Detector-Using-AI\\1\\mPower\\results_ALL_VALIDS_ALL\\feature_extractor_cnn_att_lstm\\best_feature_extractor.keras\n",
      "\u001B[1m52/52\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m25s\u001B[0m 486ms/step - accuracy: 0.5631 - loss: 0.8175 - val_accuracy: 0.5577 - val_loss: 0.7965\n",
      "Epoch 21/30\n",
      "\u001B[1m52/52\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 457ms/step - accuracy: 0.6006 - loss: 0.7919\n",
      "Epoch 21: val_loss improved from 0.79652 to 0.77570, saving model to D:\\Projects\\Voice\\Parkinson-s-Disease-Detector-Using-AI\\Parkinson-s-Disease-Detector-Using-AI\\1\\mPower\\results_ALL_VALIDS_ALL\\feature_extractor_cnn_att_lstm\\best_feature_extractor.keras\n",
      "\u001B[1m52/52\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m25s\u001B[0m 489ms/step - accuracy: 0.6046 - loss: 0.7854 - val_accuracy: 0.5889 - val_loss: 0.7757\n",
      "Epoch 22/30\n",
      "\u001B[1m52/52\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 439ms/step - accuracy: 0.5870 - loss: 0.7738\n",
      "Epoch 22: val_loss improved from 0.77570 to 0.75876, saving model to D:\\Projects\\Voice\\Parkinson-s-Disease-Detector-Using-AI\\Parkinson-s-Disease-Detector-Using-AI\\1\\mPower\\results_ALL_VALIDS_ALL\\feature_extractor_cnn_att_lstm\\best_feature_extractor.keras\n",
      "\u001B[1m52/52\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m25s\u001B[0m 472ms/step - accuracy: 0.5781 - loss: 0.7726 - val_accuracy: 0.5841 - val_loss: 0.7588\n",
      "Epoch 23/30\n",
      "\u001B[1m52/52\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 460ms/step - accuracy: 0.5994 - loss: 0.7670\n",
      "Epoch 23: val_loss improved from 0.75876 to 0.75299, saving model to D:\\Projects\\Voice\\Parkinson-s-Disease-Detector-Using-AI\\Parkinson-s-Disease-Detector-Using-AI\\1\\mPower\\results_ALL_VALIDS_ALL\\feature_extractor_cnn_att_lstm\\best_feature_extractor.keras\n",
      "\u001B[1m52/52\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m26s\u001B[0m 500ms/step - accuracy: 0.6088 - loss: 0.7637 - val_accuracy: 0.5913 - val_loss: 0.7530\n",
      "Epoch 24/30\n",
      "\u001B[1m52/52\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 432ms/step - accuracy: 0.6271 - loss: 0.7472\n",
      "Epoch 24: val_loss did not improve from 0.75299\n",
      "\u001B[1m52/52\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m24s\u001B[0m 462ms/step - accuracy: 0.6010 - loss: 0.7572 - val_accuracy: 0.5938 - val_loss: 0.7542\n",
      "Epoch 25/30\n",
      "\u001B[1m52/52\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 493ms/step - accuracy: 0.6201 - loss: 0.7411\n",
      "Epoch 25: val_loss did not improve from 0.75299\n",
      "\u001B[1m52/52\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m28s\u001B[0m 535ms/step - accuracy: 0.6016 - loss: 0.7521 - val_accuracy: 0.5793 - val_loss: 0.7594\n",
      "Epoch 26/30\n",
      "\u001B[1m52/52\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 465ms/step - accuracy: 0.5895 - loss: 0.7490\n",
      "Epoch 26: val_loss improved from 0.75299 to 0.73347, saving model to D:\\Projects\\Voice\\Parkinson-s-Disease-Detector-Using-AI\\Parkinson-s-Disease-Detector-Using-AI\\1\\mPower\\results_ALL_VALIDS_ALL\\feature_extractor_cnn_att_lstm\\best_feature_extractor.keras\n",
      "\u001B[1m52/52\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m26s\u001B[0m 495ms/step - accuracy: 0.6052 - loss: 0.7385 - val_accuracy: 0.5793 - val_loss: 0.7335\n",
      "Epoch 27/30\n",
      "\u001B[1m52/52\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 449ms/step - accuracy: 0.5864 - loss: 0.7418\n",
      "Epoch 27: val_loss improved from 0.73347 to 0.72630, saving model to D:\\Projects\\Voice\\Parkinson-s-Disease-Detector-Using-AI\\Parkinson-s-Disease-Detector-Using-AI\\1\\mPower\\results_ALL_VALIDS_ALL\\feature_extractor_cnn_att_lstm\\best_feature_extractor.keras\n",
      "\u001B[1m52/52\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m26s\u001B[0m 492ms/step - accuracy: 0.6076 - loss: 0.7294 - val_accuracy: 0.5889 - val_loss: 0.7263\n",
      "Epoch 28/30\n",
      "\u001B[1m52/52\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 436ms/step - accuracy: 0.6010 - loss: 0.7261\n",
      "Epoch 28: val_loss improved from 0.72630 to 0.71661, saving model to D:\\Projects\\Voice\\Parkinson-s-Disease-Detector-Using-AI\\Parkinson-s-Disease-Detector-Using-AI\\1\\mPower\\results_ALL_VALIDS_ALL\\feature_extractor_cnn_att_lstm\\best_feature_extractor.keras\n",
      "\u001B[1m52/52\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m25s\u001B[0m 483ms/step - accuracy: 0.5998 - loss: 0.7264 - val_accuracy: 0.5865 - val_loss: 0.7166\n",
      "Epoch 29/30\n",
      "\u001B[1m52/52\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 488ms/step - accuracy: 0.6046 - loss: 0.7181\n",
      "Epoch 29: val_loss improved from 0.71661 to 0.71456, saving model to D:\\Projects\\Voice\\Parkinson-s-Disease-Detector-Using-AI\\Parkinson-s-Disease-Detector-Using-AI\\1\\mPower\\results_ALL_VALIDS_ALL\\feature_extractor_cnn_att_lstm\\best_feature_extractor.keras\n",
      "\u001B[1m52/52\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m28s\u001B[0m 528ms/step - accuracy: 0.6088 - loss: 0.7251 - val_accuracy: 0.5962 - val_loss: 0.7146\n",
      "Epoch 30/30\n",
      "\u001B[1m52/52\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 442ms/step - accuracy: 0.6027 - loss: 0.7259\n",
      "Epoch 30: val_loss did not improve from 0.71456\n",
      "\u001B[1m52/52\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m25s\u001B[0m 472ms/step - accuracy: 0.6028 - loss: 0.7221 - val_accuracy: 0.5433 - val_loss: 0.7641\n",
      "--- Feature extractor training finished ---\n",
      "\n",
      "Training history saved to 'D:\\Projects\\Voice\\Parkinson-s-Disease-Detector-Using-AI\\Parkinson-s-Disease-Detector-Using-AI\\1\\mPower\\results_ALL_VALIDS_ALL\\feature_extractor_cnn_att_lstm\\history.csv'\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-10T21:43:21.605981Z",
     "start_time": "2025-09-10T21:43:11.606407Z"
    }
   },
   "cell_type": "code",
   "source": [
    "    # 2. Load the best feature extractor and extract embeddings\n",
    "    print(\"\\n--- Loading best feature extractor model ---\")\n",
    "\n",
    "    # --- MODIFIED: Correctly build the inference model from the subclass ---\n",
    "    # First, load the entire model that was saved during training\n",
    "    full_model_to_load = tf.keras.models.load_model(BEST_EXTRACTOR_PATH)\n",
    "\n",
    "    # Now, build the standalone feature extractor model\n",
    "    input_shape = (X_train.shape[1], X_train.shape[2])\n",
    "    inputs = Input(shape=input_shape)\n",
    "\n",
    "    # Instantiate your custom FeatureExtractor class\n",
    "    feature_extractor_instance = FeatureExtractor(input_shape=input_shape)\n",
    "\n",
    "    # Call the instance on the input tensor to get the output\n",
    "    outputs = feature_extractor_instance(inputs)\n",
    "\n",
    "    # Create the final inference model from the inputs and outputs\n",
    "    inference_extractor_model = Model(inputs, outputs)\n",
    "\n",
    "    # The saved model has weights for the extractor AND the final dense layer.\n",
    "    # We slice off the last two weights (weights and bias for the dense layer).\n",
    "    extractor_weights = full_model_to_load.get_weights()[:-2]\n",
    "    inference_extractor_model.set_weights(extractor_weights)\n",
    "\n",
    "    print(\"Feature extractor model built and weights loaded successfully.\")\n",
    "    # --- End of MODIFIED section ---\n",
    "\n",
    "    print(\"--- Extracting features (embeddings) ---\")\n",
    "    # Use the newly created model to predict\n",
    "    X_train_features = inference_extractor_model.predict(X_train, batch_size=BATCH_SIZE)\n",
    "    X_test_features = inference_extractor_model.predict(X_test, batch_size=BATCH_SIZE)\n",
    "\n",
    "    print(f\"Shape of training features: {X_train_features.shape}\")\n",
    "    print(f\"Shape of testing features: {X_test_features.shape}\")\n"
   ],
   "id": "4a1887e572d30611",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Loading best feature extractor model ---\n",
      "Feature extractor model built and weights loaded successfully.\n",
      "--- Extracting features (embeddings) ---\n",
      "\u001B[1m52/52\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 109ms/step\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 114ms/step\n",
      "Shape of training features: (1664, 896)\n",
      "Shape of testing features: (416, 896)\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-10T21:48:28.707575Z",
     "start_time": "2025-09-10T21:43:23.908493Z"
    }
   },
   "cell_type": "code",
   "source": "    tune_and_evaluate_knn_pipeline(X_train_features, y_train, X_test_features, y_test, RESULTS_PATH)",
   "id": "b8b73df3465abe32",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Tuning Optimized k-NN Pipeline ---\n",
      "Fitting 10 folds for each of 15 candidates, totalling 150 fits\n",
      "\n",
      "Best cross-validation score: 0.7509\n",
      "\n",
      "\n",
      "--- Detailed Report for Best k-NN Pipeline ---\n",
      "Test Set Accuracy: 0.6827\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6727    0.7115    0.6916       208\n",
      "           1     0.6939    0.6538    0.6733       208\n",
      "\n",
      "    accuracy                         0.6827       416\n",
      "   macro avg     0.6833    0.6827    0.6824       416\n",
      "weighted avg     0.6833    0.6827    0.6824       416\n",
      "\n",
      "\n",
      "Best Hyperparameters Found:\n",
      "{'nca__n_components': 31, 'classifier__weights': 'distance', 'classifier__n_neighbors': 15, 'classifier__metric': 'manhattan'}\n",
      "\n",
      "✅ Best k-NN pipeline saved to: D:\\Projects\\Voice\\Parkinson-s-Disease-Detector-Using-AI\\Parkinson-s-Disease-Detector-Using-AI\\1\\mPower\\results_ALL_VALIDS_ALL\\best_knn_pipeline.joblib\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-10T21:59:27.402635Z",
     "start_time": "2025-09-10T21:56:29.218304Z"
    }
   },
   "cell_type": "code",
   "source": [
    "    # --- FIX: Reshape the data from 3D to 2D before scaling ---\n",
    "    # Get the original dimensions\n",
    "    n_samples_train, d1, d2 = X_train.shape\n",
    "    n_samples_test = X_test.shape[0]\n",
    "\n",
    "    # Reshape by multiplying the last two dimensions together\n",
    "    X_train_reshaped = X_train.reshape((n_samples_train, d1 * d2))\n",
    "    X_test_reshaped = X_test.reshape((n_samples_test, d1 * d2))\n",
    "\n",
    "    print(f\"Reshaped X_train shape: {X_train_reshaped.shape}\") # Will be (80, 2400)\n",
    "\n",
    "    # Now, you can scale the reshaped data without error\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X_train_reshaped)\n",
    "\n",
    "    X_train_scaled = scaler.transform(X_train_reshaped)\n",
    "    X_test_scaled = scaler.transform(X_test_reshaped)\n",
    "\n",
    "    print(\"\\nData successfully reshaped and scaled!\")\n",
    "    tune_and_evaluate_knn_pipeline(X_train_scaled, y_train, X_test_scaled, y_test, RESULTS_PATH)"
   ],
   "id": "1ab70cca33be1daf",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reshaped X_train shape: (1664, 5640)\n",
      "\n",
      "Data successfully reshaped and scaled!\n",
      "\n",
      "--- Tuning Optimized k-NN Pipeline ---\n",
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n",
      "\n",
      "Best cross-validation score: 0.7648\n",
      "\n",
      "\n",
      "--- Detailed Report for Best k-NN Pipeline ---\n",
      "Test Set Accuracy: 0.7067\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6748    0.7981    0.7313       208\n",
      "           1     0.7529    0.6154    0.6772       208\n",
      "\n",
      "    accuracy                         0.7067       416\n",
      "   macro avg     0.7139    0.7067    0.7043       416\n",
      "weighted avg     0.7139    0.7067    0.7043       416\n",
      "\n",
      "\n",
      "Best Hyperparameters Found:\n",
      "{'nca__n_components': 31, 'classifier__weights': 'distance', 'classifier__n_neighbors': 9, 'classifier__metric': 'manhattan'}\n",
      "\n",
      "✅ Best k-NN pipeline saved to: D:\\Projects\\Voice\\Parkinson-s-Disease-Detector-Using-AI\\Parkinson-s-Disease-Detector-Using-AI\\1\\mPower\\results_ALL_VALIDS_ALL\\best_knn_pipeline.joblib\n"
     ]
    }
   ],
   "execution_count": 11
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
