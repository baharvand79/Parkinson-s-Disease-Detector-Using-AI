{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import os\n",
    "import gc\n",
    "from typing import List, Dict, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "# =============================================================================\n",
    "# --- Configuration ---\n",
    "# =============================================================================\n",
    "\n",
    "# Class definitions\n",
    "HEALTHY_CLASS: str = \"healthy_control\"\n",
    "PARKINSON_CLASS: str = \"parkinson_patient\"\n",
    "CLASSES: List[str] = [HEALTHY_CLASS, PARKINSON_CLASS]\n",
    "\n",
    "ITALIAN_DATASET = \"ITALIAN_DATASET\"\n",
    "UAMS_DATASET = \"UAMS_DATASET\"\n",
    "NEUROVOZ_DATASET = \"NEUROVOZ_DATASET\"\n",
    "MPOWER_DATASET = \"MPOWER_DATASET\"\n",
    "SYNTHETIC_DATASET = \"SYNTHETIC_DATASET\"\n",
    "\n",
    "\n",
    "MODE_A = \"A\"\n",
    "MODE_ALL_VALIDS = \"ALL_VALIDS\"\n",
    "\n",
    "FEATURE_MODE_BASIC = \"BASIC\"        # mel_spectrogram, mfcc, spectrogram\n",
    "FEATURE_MODE_ALL = \"ALL\"            # basic + fsc\n",
    "FEATURE_MODE_ACOUSTIC = \"ACOUSTIC\"  # acoustic_features only\n",
    "FEATURE_MODE_COMBINED = \"COMBINED\"  # all spectral + acoustic features\n",
    "\n",
    "# --- SELECT YOUR CONFIGURATION HERE ---\n",
    "DATASET = UAMS_DATASET\n",
    "MODE = MODE_ALL_VALIDS\n",
    "FEATURE_MODE = FEATURE_MODE_ALL\n",
    "FOLDER_NAME = \"features_characteristics\"\n",
    "# ------------------------------------\n",
    "\n",
    "# Path Setup\n",
    "if DATASET == ITALIAN_DATASET:\n",
    "    dataset_folder_name = \"Italian\"\n",
    "elif DATASET == UAMS_DATASET:\n",
    "    dataset_folder_name = \"UAMS\"\n",
    "elif DATASET == NEUROVOZ_DATASET:\n",
    "    dataset_folder_name = \"Neurovoz\"\n",
    "elif DATASET == MPOWER_DATASET:\n",
    "    dataset_folder_name = \"mPower\"\n",
    "elif DATASET == SYNTHETIC_DATASET:\n",
    "    dataset_folder_name = \"Synthetic\"\n",
    "\n",
    "FEATURES_FILE: str = os.path.join(os.getcwd(), dataset_folder_name, \"data\", f\"features_{MODE}_{FEATURE_MODE}.npz\")\n",
    "RESULTS_OUTPUT_PATH: str = os.path.join(os.getcwd(), dataset_folder_name, f\"results_{MODE}_{FEATURE_MODE}\", FOLDER_NAME)\n",
    "os.makedirs(RESULTS_OUTPUT_PATH, exist_ok=True)\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# --- Data Loading and Preparation ---\n",
    "# =============================================================================\n",
    "\n",
    "def get_feature_keys(feature_mode: str) -> List[str]:\n",
    "    \"\"\"Returns the list of audio feature keys based on the selected mode.\"\"\"\n",
    "    if feature_mode == \"BASIC\":\n",
    "        return ['mel_spectrogram', 'mfcc']\n",
    "    elif feature_mode == \"ALL\":\n",
    "        return ['spectrogram', 'mel_spectrogram', 'mfcc', 'fsc']\n",
    "    raise ValueError(f\"Unknown FEATURE_MODE: {feature_mode}\")\n",
    "\n",
    "def load_features(features_file: str) -> Dict[str, np.ndarray]:\n",
    "    \"\"\"Loads all data arrays from the specified .npz file.\"\"\"\n",
    "    print(f\"Loading features from {features_file}\")\n",
    "    if not os.path.exists(features_file):\n",
    "        raise FileNotFoundError(f\"Features file not found: {features_file}\")\n",
    "\n",
    "    with np.load(features_file) as data:\n",
    "        features = {key: data[key] for key in data.keys()}\n",
    "\n",
    "    print(\"Loaded data shapes:\")\n",
    "    for key, value in features.items():\n",
    "        print(f\"  - {key}: {value.shape}\")\n",
    "    return features\n",
    "\n",
    "def prepare_and_clean_features(\n",
    "    features_dict: Dict[str, np.ndarray],\n",
    "    feature_mode: str\n",
    ") -> Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray, bool]:\n",
    "    \"\"\"\n",
    "    Prepares and cleans feature data for visualization using the full dataset.\n",
    "    \"\"\"\n",
    "    print(f\"\\n--- Preparing and Cleaning Features for Mode: {feature_mode} ---\")\n",
    "    feature_keys = get_feature_keys(feature_mode)\n",
    "    labels = features_dict['labels']\n",
    "\n",
    "    has_demographics = 'age' in features_dict and 'sex' in features_dict\n",
    "    if has_demographics:\n",
    "        ages = features_dict['age']\n",
    "        sexes = features_dict['sex']\n",
    "        print(\"Found 'age' and 'sex' data.\")\n",
    "    else:\n",
    "        ages = np.full_like(labels, np.nan)\n",
    "        sexes = np.full_like(labels, np.nan)\n",
    "\n",
    "    # --- MODIFIED: Subsampling has been removed to use all data ---\n",
    "    n_samples = len(labels)\n",
    "    print(f\"Using all {n_samples} samples for analysis. Note: This may be slow.\")\n",
    "    indices = np.arange(n_samples)\n",
    "\n",
    "    labels_sub, ages_sub, sexes_sub = labels[indices], ages[indices], sexes[indices]\n",
    "    X_sub = np.array([np.concatenate([features_dict[key][idx].flatten() for key in feature_keys]) for idx in indices])\n",
    "\n",
    "    # Clean data by removing rows with NaN in age or sex\n",
    "    if has_demographics:\n",
    "        nan_mask = pd.isna(ages_sub) | pd.isna(sexes_sub)\n",
    "        num_removed = np.sum(nan_mask)\n",
    "        if num_removed > 0:\n",
    "            print(f\"Removing {num_removed} samples with missing age/sex data for clean visualization.\")\n",
    "            clean_mask = ~nan_mask\n",
    "            X_sub, labels_sub, ages_sub, sexes_sub = X_sub[clean_mask], labels_sub[clean_mask], ages_sub[clean_mask], sexes_sub[clean_mask]\n",
    "\n",
    "    print(f\"Final feature matrix shape for visualization: {X_sub.shape}\")\n",
    "    return X_sub, labels_sub, ages_sub, sexes_sub, has_demographics\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# --- Visualization Functions ---\n",
    "# =============================================================================\n",
    "\n",
    "def plot_comprehensive_analysis(X: np.ndarray, y: np.ndarray, age: np.ndarray, output_path: str, min_age: float, max_age: float):\n",
    "    \"\"\"\n",
    "    Creates a comprehensive 3x2 plot including PCA variance curves,\n",
    "    class-based projections, and an age-colored t-SNE projection.\n",
    "    \"\"\"\n",
    "    print(\"\\n--- Creating Comprehensive Analysis Plot ---\")\n",
    "    if X.shape[0] < 2: return\n",
    "\n",
    "    X_scaled = StandardScaler().fit_transform(X)\n",
    "    class_names = [cls.replace('_', ' ').title() for cls in CLASSES]\n",
    "    colors = ['#2E86C1', '#E74C3C']\n",
    "\n",
    "    fig, axes = plt.subplots(3, 2, figsize=(16, 21))\n",
    "    fig.suptitle('Comprehensive Feature Analysis', fontsize=20)\n",
    "\n",
    "    # --- Row 1: PCA Variance Analysis ---\n",
    "    print(\"Computing PCA for variance curves...\")\n",
    "    n_curve_comps = min(50, X_scaled.shape[1], X_scaled.shape[0] - 1)\n",
    "    pca_variance = PCA(n_components=n_curve_comps, random_state=42)\n",
    "    pca_variance.fit(X_scaled)\n",
    "    axes[0, 0].plot(range(1, n_curve_comps + 1), pca_variance.explained_variance_ratio_, 'bo-', markersize=4)\n",
    "    axes[0, 0].set(title='PCA: Explained Variance per Component', xlabel='Principal Component', ylabel='Explained Variance Ratio'); axes[0, 0].grid(True, alpha=0.5, linestyle=':')\n",
    "    cumulative_variance = np.cumsum(pca_variance.explained_variance_ratio_)\n",
    "    axes[0, 1].plot(range(1, n_curve_comps + 1), cumulative_variance, 'ro-', markersize=4)\n",
    "    axes[0, 1].axhline(y=0.95, color='k', linestyle='--', alpha=0.8, label='95% Variance')\n",
    "    axes[0, 1].set(title='PCA: Cumulative Explained Variance', xlabel='Number of Components', ylabel='Cumulative Variance'); axes[0, 1].legend(); axes[0, 1].grid(True, alpha=0.5, linestyle=':')\n",
    "\n",
    "    # --- Row 2: Projections by Class ---\n",
    "    pca_95 = PCA(n_components=0.95, random_state=42); X_pca = pca_95.fit_transform(X_scaled)\n",
    "    for i, name in enumerate(class_names): axes[1, 0].scatter(X_pca[y == i, 0], X_pca[y == i, 1], c=colors[i], label=f'{name} (n={np.sum(y == i)})', alpha=0.7, s=25)\n",
    "    axes[1, 0].set(title=f'PCA Projection (First 2 of {pca_95.n_components_} Components)', xlabel=f'PC1 ({pca_95.explained_variance_ratio_[0]:.2%})', ylabel=f'PC2 ({pca_95.explained_variance_ratio_[1]:.2%})'); axes[1, 0].legend(); axes[1, 0].grid(True, alpha=0.5, linestyle=':')\n",
    "\n",
    "    print(\"Computing t-SNE...\")\n",
    "    perplexity = min(30, max(5, (X.shape[0] // 5) - 1)); tsne = TSNE(n_components=2, random_state=42, perplexity=perplexity, init='pca', learning_rate='auto'); X_tsne = tsne.fit_transform(X_scaled)\n",
    "    for i, name in enumerate(class_names): axes[1, 1].scatter(X_tsne[y == i, 0], X_tsne[y == i, 1], c=colors[i], label=f'{name} (n={np.sum(y == i)})', alpha=0.7, s=25)\n",
    "    axes[1, 1].set(title='t-SNE Projection by Class', xlabel='t-SNE Dimension 1', ylabel='t-SNE Dimension 2'); axes[1, 1].legend(); axes[1, 1].grid(True, alpha=0.5, linestyle=':')\n",
    "\n",
    "    # --- Row 3: LDA and t-SNE by Age ---\n",
    "    lda = LinearDiscriminantAnalysis(n_components=1); X_lda = lda.fit_transform(X_scaled, y)\n",
    "    for i, name in enumerate(class_names): sns.kdeplot(X_lda[y == i].ravel(), ax=axes[2, 0], color=colors[i], label=f'{name} (n={np.sum(y == i)})', fill=True, alpha=0.5)\n",
    "    axes[2, 0].set(title='LDA Projection', xlabel='LD1', ylabel='Density'); axes[2, 0].legend(); axes[2, 0].grid(True, alpha=0.5, linestyle=':')\n",
    "\n",
    "    scatter = axes[2, 1].scatter(X_tsne[:, 0], X_tsne[:, 1], c=age, cmap='plasma', s=25, alpha=0.8, vmin=min_age, vmax=max_age)\n",
    "    fig.colorbar(scatter, ax=axes[2, 1], label='Age'); axes[2, 1].set(title='t-SNE Projection by Age', xlabel='t-SNE Dimension 1', ylabel='t-SNE Dimension 2'); axes[2, 1].grid(True, alpha=0.5, linestyle=':')\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 0.97]); save_path = os.path.join(output_path, \"comprehensive_analysis.png\")\n",
    "    plt.savefig(save_path, dpi=300, bbox_inches='tight'); plt.close()\n",
    "    print(f\"Saved comprehensive analysis plots to '{os.path.basename(save_path)}'\")\n",
    "\n",
    "def plot_demographic_analysis(X: np.ndarray, y: np.ndarray, age: np.ndarray, sex: np.ndarray, output_path: str, min_age: float, max_age: float):\n",
    "    \"\"\"\n",
    "    Creates a 2x2 plot showing demographic distributions and their relation to features,\n",
    "    with age plots stacked and sex plots stacked.\n",
    "    \"\"\"\n",
    "    print(\"\\n--- Creating Demographic Analysis Plots (Stacked) ---\")\n",
    "    if X.shape[0] < 2: return\n",
    "\n",
    "    sex_labels = ['Female' if s == 0 else 'Male' for s in sex]\n",
    "    df = pd.DataFrame({'Age': age, 'Sex': sex_labels, 'Class': [CLASSES[int(label)].replace('_', ' ').title() for label in y]})\n",
    "\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 18)) # Increased height for better stacking\n",
    "    fig.suptitle('Demographic and Feature Analysis', fontsize=20, y=1.02)\n",
    "    class_colors = {'Healthy Control': '#2E86C1', 'Parkinson Patient': '#E74C3C'}\n",
    "    sex_colors = {'Female': '#DB7093', 'Male': '#4682B4'}\n",
    "\n",
    "    X_scaled = StandardScaler().fit_transform(X)\n",
    "    pca = PCA(n_components=2, random_state=42)\n",
    "    X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "    # --- Column 1: Age Plots ---\n",
    "    # 1. Age Distribution by Class (Top-Left)\n",
    "    sns.violinplot(ax=axes[0, 0], data=df, x='Class', y='Age', hue='Class', palette=class_colors, legend=False)\n",
    "    axes[0, 0].set_title('Age Distribution by Class'); axes[0, 0].grid(True, alpha=0.5, linestyle=':')\n",
    "\n",
    "    # 2. PCA of Audio Features, Colored by Age (Bottom-Left)\n",
    "    scatter_age = axes[1, 0].scatter(X_pca[:, 0], X_pca[:, 1], c=age, cmap='plasma', s=25, alpha=0.8, vmin=min_age, vmax=max_age)\n",
    "    fig.colorbar(scatter_age, ax=axes[1, 0], label='Age')\n",
    "    axes[1, 1].set_title('PCA of Audio Features, Colored by Age')\n",
    "    axes[1, 1].set_xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.2%})')\n",
    "    axes[1, 1].set_ylabel(f'PC2 ({pca.explained_variance_ratio_[1]:.2%})')\n",
    "    axes[1, 1].grid(True, alpha=0.5, linestyle=':')\n",
    "\n",
    "    # --- Column 2: Sex Plots ---\n",
    "    # 3. Sex Distribution by Class (Top-Right)\n",
    "    sns.countplot(ax=axes[0, 1], data=df, x='Sex', hue='Class', palette=class_colors, order=['Female', 'Male'])\n",
    "    axes[0, 1].set_title('Sex Distribution by Class'); axes[0, 1].set_ylabel('Count')\n",
    "\n",
    "    # 4. PCA of Audio Features, Colored by Sex (Bottom-Right)\n",
    "    sns.scatterplot(ax=axes[1, 1], x=X_pca[:, 0], y=X_pca[:, 1], hue=df['Sex'], palette=sex_colors, s=25, alpha=0.8)\n",
    "    axes[1, 0].set_title('PCA of Audio Features, Colored by Sex')\n",
    "    axes[1, 0].set_xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.2%})')\n",
    "    axes[1, 0].set_ylabel(f'PC2 ({pca.explained_variance_ratio_[1]:.2%})')\n",
    "    axes[1, 0].grid(True, alpha=0.5, linestyle=':')\n",
    "\n",
    "    # Adjust layout to prevent labels from overlapping\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.98])\n",
    "    save_path = os.path.join(output_path, \"demographic_analysis.png\")\n",
    "    plt.savefig(save_path, dpi=300, bbox_inches='tight'); plt.close()\n",
    "    print(f\"Saved demographic analysis to '{os.path.basename(save_path)}'\")\n",
    "\n",
    "def plot_individual_feature_separation(features_dict: Dict[str, np.ndarray], output_path: str, feature_mode: str):\n",
    "    \"\"\"\n",
    "    Creates separate PCA, t-SNE, and LDA plots for each audio feature type.\n",
    "    Forces PCA to 2 components if the 95% variance rule results in fewer than 2.\n",
    "    \"\"\"\n",
    "    print(\"\\n--- Creating Individual Audio Feature Analysis ---\")\n",
    "    feature_keys = get_feature_keys(feature_mode)\n",
    "    titles = {'spectrogram': 'Spectrogram', 'mel_spectrogram': 'Mel Spectrogram', 'mfcc': 'MFCC', 'fsc': 'Spectral Centroid'}\n",
    "    labels, n_samples = features_dict['labels'], len(features_dict['labels'])\n",
    "\n",
    "    indices = np.arange(n_samples)\n",
    "    labels_sub = labels[indices]\n",
    "    class_names, colors = [\"Healthy Control\", \"Parkinson Patient\"], ['#2E86C1', '#E74C3C']\n",
    "\n",
    "    fig, axes = plt.subplots(3, len(feature_keys), figsize=(7 * len(feature_keys), 15), squeeze=False, constrained_layout=True)\n",
    "    fig.suptitle('Individual Audio Feature Analysis', fontsize=16)\n",
    "\n",
    "    for col, feat_key in enumerate(feature_keys):\n",
    "        feat_title = titles.get(feat_key, feat_key)\n",
    "        print(f\"  Processing {feat_title}...\")\n",
    "        X = np.array([features_dict[feat_key][i].flatten() for i in indices])\n",
    "        X_scaled = StandardScaler().fit_transform(X)\n",
    "\n",
    "        # --- NEW LOGIC: Check components needed and decide PCA strategy ---\n",
    "        # 1. First, check how many components are needed for 95% variance.\n",
    "        pca_check = PCA(n_components=0.95, random_state=42)\n",
    "        pca_check.fit(X_scaled)\n",
    "\n",
    "        # 2. If it's less than 2, force n_components to be 2 for a consistent plot.\n",
    "        if pca_check.n_components_ < 2:\n",
    "            print(f\"  --> Forcing PCA to 2 components for '{feat_title}' (95% rule gave {pca_check.n_components_}).\")\n",
    "            pca = PCA(n_components=2, random_state=42)\n",
    "        else:\n",
    "            # Otherwise, use the standard 95% variance rule.\n",
    "            pca = PCA(n_components=0.95, random_state=42)\n",
    "\n",
    "        # 3. Fit and transform with the chosen PCA settings.\n",
    "        X_pca = pca.fit_transform(X_scaled)\n",
    "        # --- End of New Logic ---\n",
    "\n",
    "        # The scatter plot now safely assumes X_pca has at least 2 columns.\n",
    "        ax = axes[0, col]\n",
    "        for i, name in enumerate(class_names):\n",
    "            ax.scatter(X_pca[labels_sub == i, 0], X_pca[labels_sub == i, 1], c=colors[i], label=name, alpha=0.7, s=15)\n",
    "\n",
    "        # Create a dynamic title\n",
    "        total_var_explained = np.sum(pca.explained_variance_ratio_)\n",
    "        title = f'PCA: {feat_title}\\n({pca.n_components_} comps for {total_var_explained:.1%} var.)'\n",
    "        ax.set(title=title, xlabel=f'PC1 ({pca.explained_variance_ratio_[0]:.2%})', ylabel=f'PC2 ({pca.explained_variance_ratio_[1]:.2%})')\n",
    "        ax.legend(); ax.grid(True, alpha=0.5, linestyle=':')\n",
    "\n",
    "        # t-SNE (unchanged)\n",
    "        perplexity = min(30, max(5, (X_scaled.shape[0] // 5) - 1))\n",
    "        tsne = TSNE(n_components=2, random_state=42, perplexity=perplexity, init='pca', learning_rate='auto')\n",
    "        X_tsne = tsne.fit_transform(X_scaled)\n",
    "        ax = axes[1, col]\n",
    "        for i, name in enumerate(class_names):\n",
    "            ax.scatter(X_tsne[labels_sub == i, 0], X_tsne[labels_sub == i, 1], c=colors[i], label=name, alpha=0.7, s=15)\n",
    "        ax.set(title=f't-SNE: {feat_title}', xlabel='t-SNE Dim 1', ylabel='t-SNE Dim 2'); ax.legend(); ax.grid(True, alpha=0.5, linestyle=':')\n",
    "\n",
    "        # LDA (unchanged)\n",
    "        lda = LinearDiscriminantAnalysis(n_components=1)\n",
    "        X_lda = lda.fit_transform(X_scaled, labels_sub)\n",
    "        ax = axes[2, col]\n",
    "        for i, name in enumerate(class_names):\n",
    "            sns.kdeplot(X_lda[labels_sub == i].ravel(), ax=ax, color=colors[i], label=name, fill=True, alpha=0.6)\n",
    "        ax.set(title=f'LDA: {feat_title}', xlabel='LD1', ylabel='Density'); ax.legend(); ax.grid(True, alpha=0.5, linestyle=':')\n",
    "        del X, X_scaled; gc.collect()\n",
    "\n",
    "    save_path = os.path.join(output_path, \"individual_feature_analysis.png\")\n",
    "    plt.savefig(save_path, dpi=300, bbox_inches='tight'); plt.close()\n",
    "    print(f\"Saved individual feature analysis to '{os.path.basename(save_path)}'\")\n",
    "\n",
    "def plot_individual_features_by_age(\n",
    "    features_dict: Dict[str, np.ndarray],\n",
    "    output_path: str,\n",
    "    feature_mode: str,\n",
    "    min_age: float,\n",
    "    max_age: float\n",
    "):\n",
    "    \"\"\"\n",
    "    Creates separate PCA and t-SNE plots for each audio feature, colored by age.\n",
    "    \"\"\"\n",
    "    print(\"\\n--- Creating Individual Audio Feature Analysis (Colored by Age) ---\")\n",
    "    feature_keys = get_feature_keys(feature_mode)\n",
    "    titles = {'spectrogram': 'Spectrogram', 'mel_spectrogram': 'Mel Spectrogram', 'mfcc': 'MFCC', 'fsc': 'Spectral Centroid'}\n",
    "\n",
    "    # --- MODIFIED: Subsampling removed ---\n",
    "    n_samples = len(features_dict['labels'])\n",
    "    indices = np.arange(n_samples)\n",
    "\n",
    "    ages_sub = features_dict['age'][indices]\n",
    "    clean_mask = ~pd.isna(ages_sub)\n",
    "    indices_clean = indices[clean_mask]\n",
    "    ages_clean = ages_sub[clean_mask]\n",
    "\n",
    "    if len(indices_clean) < 2:\n",
    "        print(\"Not enough data with valid age information to create plots. Skipping.\")\n",
    "        return\n",
    "\n",
    "    fig, axes = plt.subplots(\n",
    "        2, len(feature_keys),\n",
    "        figsize=(7 * len(feature_keys), 10),\n",
    "        squeeze=False,\n",
    "        constrained_layout=True\n",
    "    )\n",
    "    fig.suptitle('Individual Audio Feature Analysis by Age', fontsize=16)\n",
    "\n",
    "    mappable = None\n",
    "\n",
    "    for col, feat_key in enumerate(feature_keys):\n",
    "        feat_title = titles.get(feat_key, feat_key)\n",
    "        print(f\"  Processing {feat_title}...\")\n",
    "\n",
    "        X = np.array([features_dict[feat_key][i].flatten() for i in indices_clean])\n",
    "        X_scaled = StandardScaler().fit_transform(X)\n",
    "\n",
    "        pca_check = PCA(n_components=0.95, random_state=42)\n",
    "        pca_check.fit(X_scaled)\n",
    "\n",
    "        # 2. If it's less than 2, force n_components to be 2 for a consistent plot.\n",
    "        if pca_check.n_components_ < 2:\n",
    "            print(f\"  --> Forcing PCA to 2 components for '{feat_title}' (95% rule gave {pca_check.n_components_}).\")\n",
    "            pca = PCA(n_components=2, random_state=42)\n",
    "        else:\n",
    "            # Otherwise, use the standard 95% variance rule.\n",
    "            pca = PCA(n_components=0.95, random_state=42)\n",
    "\n",
    "        # 3. Fit and transform with the chosen PCA settings.\n",
    "        X_pca = pca.fit_transform(X_scaled)\n",
    "        # --- End of New Logic ---\n",
    "        ax = axes[0, col]\n",
    "        scatter1 = ax.scatter(X_pca[:, 0], X_pca[:, 1], c=ages_clean, cmap='plasma', vmin=min_age, vmax=max_age, alpha=0.8, s=15)\n",
    "        ax.set(title=f'PCA: {feat_title}', xlabel=f'PC1 ({pca.explained_variance_ratio_[0]:.2%})', ylabel=f'PC2 ({pca.explained_variance_ratio_[1]:.2%})')\n",
    "        ax.grid(True, alpha=0.5, linestyle=':')\n",
    "        if mappable is None: mappable = scatter1\n",
    "\n",
    "        # t-SNE colored by Age\n",
    "        perplexity = min(30, max(5, (X_scaled.shape[0] // 5) - 1))\n",
    "        tsne = TSNE(n_components=2, random_state=42, perplexity=perplexity, init='pca', learning_rate='auto')\n",
    "        X_tsne = tsne.fit_transform(X_scaled)\n",
    "        ax = axes[1, col]\n",
    "        ax.scatter(X_tsne[:, 0], X_tsne[:, 1], c=ages_clean, cmap='plasma', vmin=min_age, vmax=max_age, alpha=0.8, s=15)\n",
    "        ax.set(title=f't-SNE: {feat_title}', xlabel='t-SNE Dim 1', ylabel='t-SNE Dim 2')\n",
    "        ax.grid(True, alpha=0.5, linestyle=':')\n",
    "        del X, X_scaled; gc.collect()\n",
    "\n",
    "    fig.colorbar(mappable, ax=axes.ravel().tolist(), label='Age', pad=0.01, aspect=30)\n",
    "\n",
    "    save_path = os.path.join(output_path, \"individual_feature_analysis_by_age.png\")\n",
    "    plt.savefig(save_path, dpi=300, bbox_inches='tight'); plt.close()\n",
    "    print(f\"Saved individual feature analysis by age to '{os.path.basename(save_path)}'\")\n",
    "\n",
    "# =============================================================================\n",
    "# --- Main Execution ---\n",
    "# =============================================================================\n",
    "def main():\n",
    "    \"\"\"Main function to run the complete analysis workflow.\"\"\"\n",
    "    print(\"=\" * 50); print(\"=== Feature & Demographic Analysis ===\"); print(\"=\" * 50)\n",
    "    try:\n",
    "        features = load_features(FEATURES_FILE)\n",
    "\n",
    "        global_min_age, global_max_age = None, None\n",
    "        if 'age' in features:\n",
    "            global_min_age, global_max_age = np.nanmin(features['age']), np.nanmax(features['age'])\n",
    "\n",
    "        X, y, age, sex, has_demographics = prepare_and_clean_features(features, FEATURE_MODE)\n",
    "\n",
    "        plot_individual_feature_separation(features, RESULTS_OUTPUT_PATH, FEATURE_MODE)\n",
    "\n",
    "        if has_demographics:\n",
    "            plot_comprehensive_analysis(X, y, age, RESULTS_OUTPUT_PATH, global_min_age, global_max_age)\n",
    "            plot_demographic_analysis(X, y, age, sex, RESULTS_OUTPUT_PATH, global_min_age, global_max_age)\n",
    "\n",
    "            plot_individual_features_by_age(features, RESULTS_OUTPUT_PATH, FEATURE_MODE, global_min_age, global_max_age)\n",
    "        else:\n",
    "            print(\"\\nDemographic data not found. Skipping demographic-related plots.\")\n",
    "\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"\\nERROR: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\nAn unexpected error occurred: {e}\"); import traceback; traceback.print_exc()\n",
    "    finally:\n",
    "        print(\"\\n\" + \"=\" * 50); print(\"=== Analysis Complete ===\"); print(f\"All generated files are in: {RESULTS_OUTPUT_PATH}\"); print(\"=\" * 50)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# =============================================================================\n",
    "# --- Configuration ---\n",
    "# Instructions: Set these variables to match the .npz file you want to inspect.\n",
    "# =============================================================================\n",
    "DATASET = NEUROVOZ_DATASET\n",
    "MODE = \"A\"\n",
    "FEATURE_MODE = \"ALL\"\n",
    "\n",
    "# =============================================================================\n",
    "# --- Inspection Script ---\n",
    "# =============================================================================\n",
    "def inspect_feature_file(dataset, mode, feature_mode):\n",
    "    \"\"\"\n",
    "    Loads and inspects the contents of a .npz feature file.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Build the file path based on your project structure\n",
    "        dataset_folder_name = \"Italian\" if dataset == \"ITALIAN_DATASET\" else \"Neurovoz\"\n",
    "        features_file = os.path.join(os.getcwd(), dataset_folder_name, \"data\", f\"features_{mode}_{feature_mode}.npz\")\n",
    "\n",
    "        print(f\"Inspecting file: {features_file}\\n\")\n",
    "\n",
    "        # Check if the file exists\n",
    "        if not os.path.exists(features_file):\n",
    "            raise FileNotFoundError(f\"The specified file was not found.\")\n",
    "\n",
    "        # Load the .npz file\n",
    "        with np.load(features_file) as data:\n",
    "            print(\"✅ File loaded successfully. Here are its contents:\\n\")\n",
    "\n",
    "            # Get the list of arrays stored in the file\n",
    "            array_keys = list(data.keys())\n",
    "            print(f\"Stored arrays: {array_keys}\\n\")\n",
    "\n",
    "            # Print details for each array\n",
    "            for key in array_keys:\n",
    "                array = data[key]\n",
    "                print(\"-\" * 40)\n",
    "                print(f\"Array Name: '{key}'\")\n",
    "                print(f\"  - Shape: {array.shape}\")\n",
    "                print(f\"  - Data Type: {array.dtype}\")\n",
    "\n",
    "                # Show the first 5 elements for 1D arrays, or a note for multi-dimensional ones\n",
    "                if array.ndim == 1:\n",
    "                    print(f\"  - First 5 values: {array[:5]}\")\n",
    "                else:\n",
    "                    print(f\"  - (Multi-dimensional array, showing shape only)\")\n",
    "\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"❌ ERROR: {e}\")\n",
    "        print(\"Please check that the configuration variables at the top of the script are correct.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred: {e}\")\n",
    "\n",
    "# Run the inspection\n",
    "if __name__ == \"__main__\":\n",
    "    inspect_feature_file(DATASET, MODE, FEATURE_MODE)"
   ],
   "id": "3b3a6e529030dbdc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# =============================================================================\n",
    "# --- Configuration ---\n",
    "# Instructions: Set these variables to match the .npz file you want to inspect.\n",
    "# =============================================================================\n",
    "DATASET: str = NEUROVOZ_DATASET\n",
    "MODE: str = \"A\"\n",
    "FEATURE_MODE: str = \"ALL\"\n",
    "\n",
    "# =============================================================================\n",
    "# --- Analysis Script ---\n",
    "# =============================================================================\n",
    "\n",
    "def find_age_range(dataset: str, mode: str, feature_mode: str):\n",
    "    \"\"\"\n",
    "    Loads a feature file and calculates the minimum and maximum age.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Build the file path from configuration\n",
    "        dataset_folder_name: str = \"Italian\" if dataset == \"ITALIAN_DATASET\" else \"Neurovoz\"\n",
    "        features_file: str = os.path.join(os.getcwd(), dataset_folder_name, \"data\", f\"features_{mode}_{feature_mode}.npz\")\n",
    "\n",
    "        print(f\"Analyzing file: {features_file}\\n\")\n",
    "\n",
    "        if not os.path.exists(features_file):\n",
    "            raise FileNotFoundError(\"The specified feature file was not found.\")\n",
    "\n",
    "        # Load the data\n",
    "        with np.load(features_file) as data:\n",
    "            if 'age' not in data:\n",
    "                raise KeyError(\"The 'age' array was not found in the feature file.\")\n",
    "\n",
    "            age_array = data['age']\n",
    "\n",
    "            # Calculate min and max, safely ignoring any NaN values\n",
    "            min_age = np.nanmin(age_array)\n",
    "            max_age = np.nanmax(age_array)\n",
    "\n",
    "            print(\"📊 **Age Range Analysis Complete**\")\n",
    "            print(f\"   - Minimum Age: {min_age}\")\n",
    "            print(f\"   - Maximum Age: {max_age}\")\n",
    "\n",
    "    except (FileNotFoundError, KeyError) as e:\n",
    "        print(f\"❌ ERROR: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred: {e}\")\n",
    "\n",
    "# Run the analysis\n",
    "if __name__ == \"__main__\":\n",
    "    find_age_range(DATASET, MODE, FEATURE_MODE)"
   ],
   "id": "b5157cb0712fa711",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "26094c3419ab1a60",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "b06e1810804f8356",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os\n",
    "import gc\n",
    "from typing import List, Dict, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.neighbors import NeighborhoodComponentsAnalysis"
   ],
   "id": "f3c8c387bab31a13",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os\n",
    "import gc\n",
    "from typing import List, Dict, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.neighbors import NeighborhoodComponentsAnalysis"
   ],
   "id": "b3626c778f86d42d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-11T09:54:59.738238Z",
     "start_time": "2025-09-11T09:52:33.799881Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import gc\n",
    "from typing import List, Dict, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.neighbors import NeighborhoodComponentsAnalysis\n",
    "from sklearn.metrics import silhouette_score\n",
    "from scipy.spatial.distance import pdist, cdist\n",
    "\n",
    "# =============================================================================\n",
    "# --- Configuration ---\n",
    "# =============================================================================\n",
    "\n",
    "# Class definitions\n",
    "HEALTHY_CLASS: str = \"healthy_control\"\n",
    "PARKINSON_CLASS: str = \"parkinson_patient\"\n",
    "CLASSES: List[str] = [HEALTHY_CLASS, PARKINSON_CLASS]\n",
    "\n",
    "ITALIAN_DATASET = \"ITALIAN_DATASET\"\n",
    "UAMS_DATASET = \"UAMS_DATASET\"\n",
    "NEUROVOZ_DATASET = \"NEUROVOZ_DATASET\"\n",
    "MPOWER_DATASET = \"MPOWER_DATASET\"\n",
    "SYNTHETIC_DATASET = \"SYNTHETIC_DATASET\"\n",
    "\n",
    "MODE_A = \"A\"\n",
    "MODE_ALL_VALIDS = \"ALL_VALIDS\"\n",
    "\n",
    "FEATURE_MODE_BASIC = \"BASIC\"        # mel_spectrogram, mfcc, spectrogram\n",
    "FEATURE_MODE_ALL = \"ALL\"            # basic + fsc\n",
    "FEATURE_MODE_ACOUSTIC = \"ACOUSTIC\"  # acoustic_features only\n",
    "FEATURE_MODE_COMBINED = \"COMBINED\"  # all spectral + acoustic features\n",
    "\n",
    "# --- SELECT YOUR CONFIGURATION HERE ---\n",
    "DATASET = UAMS_DATASET\n",
    "MODE = MODE_ALL_VALIDS\n",
    "FEATURE_MODE = FEATURE_MODE_ALL\n",
    "FOLDER_NAME = \"features_characteristics_complete\"  # Changed to reflect both NCA and non-NCA\n",
    "# ------------------------------------\n",
    "\n",
    "# Path Setup and Dataset Names\n",
    "DATASET_DISPLAY_NAMES = {\n",
    "    ITALIAN_DATASET: \"IPVS\",\n",
    "    UAMS_DATASET: \"UAMS\",\n",
    "    NEUROVOZ_DATASET: \"Neurovoz_3\",\n",
    "    MPOWER_DATASET: \"mPower\",\n",
    "    SYNTHETIC_DATASET: \"Synthetic\"\n",
    "}\n",
    "\n",
    "if DATASET == ITALIAN_DATASET:\n",
    "    dataset_folder_name = \"Italian\"\n",
    "elif DATASET == UAMS_DATASET:\n",
    "    dataset_folder_name = \"UAMS\"\n",
    "elif DATASET == NEUROVOZ_DATASET:\n",
    "    dataset_folder_name = \"Neurovoz\"\n",
    "elif DATASET == MPOWER_DATASET:\n",
    "    dataset_folder_name = \"mPower\"\n",
    "elif DATASET == SYNTHETIC_DATASET:\n",
    "    dataset_folder_name = \"Synthetic\"\n",
    "\n",
    "DATASET_DISPLAY_NAME = DATASET_DISPLAY_NAMES[DATASET]\n",
    "\n",
    "FEATURES_FILE: str = os.path.join(os.getcwd(), dataset_folder_name, \"data\", f\"features_{MODE}_{FEATURE_MODE}.npz\")\n",
    "RESULTS_OUTPUT_PATH: str = os.path.join(os.getcwd(), dataset_folder_name, f\"results_{MODE}_{FEATURE_MODE}\", FOLDER_NAME)\n",
    "os.makedirs(RESULTS_OUTPUT_PATH, exist_ok=True)\n",
    "\n",
    "# =============================================================================\n",
    "# --- Metrics Calculation Functions ---\n",
    "# =============================================================================\n",
    "\n",
    "def calculate_within_class_scatter(X: np.ndarray, y: np.ndarray) -> float:\n",
    "    \"\"\"Calculate within-class scatter (average intra-class distance).\"\"\"\n",
    "    within_scatter = 0.0\n",
    "    n_total = 0\n",
    "\n",
    "    for class_label in np.unique(y):\n",
    "        class_mask = y == class_label\n",
    "        X_class = X[class_mask]\n",
    "\n",
    "        if len(X_class) > 1:\n",
    "            # Calculate pairwise distances within class\n",
    "            distances = pdist(X_class, metric='euclidean')\n",
    "            within_scatter += np.sum(distances)\n",
    "            n_total += len(distances)\n",
    "\n",
    "    return within_scatter / n_total if n_total > 0 else 0.0\n",
    "\n",
    "def calculate_between_class_scatter(X: np.ndarray, y: np.ndarray) -> float:\n",
    "    \"\"\"Calculate between-class scatter (distance between class centroids).\"\"\"\n",
    "    centroids = []\n",
    "    for class_label in np.unique(y):\n",
    "        class_mask = y == class_label\n",
    "        centroid = np.mean(X[class_mask], axis=0)\n",
    "        centroids.append(centroid)\n",
    "\n",
    "    if len(centroids) > 1:\n",
    "        # Calculate distance between centroids\n",
    "        centroids = np.array(centroids)\n",
    "        return np.linalg.norm(centroids[0] - centroids[1])\n",
    "\n",
    "    return 0.0\n",
    "\n",
    "def calculate_separation_ratio(X: np.ndarray, y: np.ndarray) -> float:\n",
    "    \"\"\"Calculate the ratio between between-class and within-class scatter.\"\"\"\n",
    "    within_scatter = calculate_within_class_scatter(X, y)\n",
    "    between_scatter = calculate_between_class_scatter(X, y)\n",
    "\n",
    "    if within_scatter > 0:\n",
    "        return between_scatter / within_scatter\n",
    "    return np.inf if between_scatter > 0 else 0.0\n",
    "\n",
    "def calculate_silhouette_coefficient(X: np.ndarray, y: np.ndarray) -> float:\n",
    "    \"\"\"Calculate silhouette coefficient for cluster separation quality.\"\"\"\n",
    "    if len(np.unique(y)) < 2 or X.shape[0] < 2:\n",
    "        return 0.0\n",
    "\n",
    "    try:\n",
    "        return silhouette_score(X, y)\n",
    "    except:\n",
    "        return 0.0\n",
    "\n",
    "def calculate_all_metrics(X: np.ndarray, y: np.ndarray) -> Dict[str, float]:\n",
    "    \"\"\"Calculate all separation metrics for given data.\"\"\"\n",
    "    metrics = {}\n",
    "\n",
    "    try:\n",
    "        metrics['within_class_scatter'] = calculate_within_class_scatter(X, y)\n",
    "        metrics['between_class_scatter'] = calculate_between_class_scatter(X, y)\n",
    "        metrics['separation_ratio'] = calculate_separation_ratio(X, y)\n",
    "        metrics['silhouette_score'] = calculate_silhouette_coefficient(X, y)\n",
    "    except Exception as e:\n",
    "        print(f\"Warning: Error calculating metrics: {e}\")\n",
    "        metrics = {\n",
    "            'within_class_scatter': 0.0,\n",
    "            'between_class_scatter': 0.0,\n",
    "            'separation_ratio': 0.0,\n",
    "            'silhouette_score': 0.0\n",
    "        }\n",
    "\n",
    "    return metrics\n",
    "\n",
    "# =============================================================================\n",
    "# --- Data Loading and Preparation ---\n",
    "# =============================================================================\n",
    "\n",
    "def get_feature_keys(feature_mode: str) -> List[str]:\n",
    "    \"\"\"Returns the list of audio feature keys based on the selected mode.\"\"\"\n",
    "    if feature_mode == \"BASIC\":\n",
    "        return ['mel_spectrogram', 'mfcc']\n",
    "    elif feature_mode == \"ALL\":\n",
    "        return ['spectrogram', 'mel_spectrogram', 'mfcc', 'fsc']\n",
    "    elif feature_mode == \"ACOUSTIC\":\n",
    "        return ['acoustic_features']\n",
    "    elif feature_mode == \"COMBINED\":\n",
    "        return ['spectrogram', 'mel_spectrogram', 'mfcc', 'fsc', 'acoustic_features']\n",
    "    raise ValueError(f\"Unknown FEATURE_MODE: {feature_mode}\")\n",
    "\n",
    "def load_features(features_file: str) -> Dict[str, np.ndarray]:\n",
    "    \"\"\"Loads all data arrays from the specified .npz file.\"\"\"\n",
    "    print(f\"Loading features from {features_file}\")\n",
    "    if not os.path.exists(features_file):\n",
    "        raise FileNotFoundError(f\"Features file not found: {features_file}\")\n",
    "\n",
    "    with np.load(features_file) as data:\n",
    "        features = {key: data[key] for key in data.keys()}\n",
    "\n",
    "    print(\"Loaded data shapes:\")\n",
    "    for key, value in features.items():\n",
    "        print(f\"  - {key}: {value.shape}\")\n",
    "    return features\n",
    "\n",
    "def check_demographics_validity(ages: np.ndarray, sexes: np.ndarray) -> bool:\n",
    "    \"\"\"Check if demographic data contains valid (non-NaN) values.\"\"\"\n",
    "    valid_ages = ~pd.isna(ages)\n",
    "    valid_sexes = ~pd.isna(sexes)\n",
    "\n",
    "    n_valid_ages = np.sum(valid_ages)\n",
    "    n_valid_sexes = np.sum(valid_sexes)\n",
    "\n",
    "    print(f\"Demographics check:\")\n",
    "    print(f\"  - Valid age values: {n_valid_ages} / {len(ages)}\")\n",
    "    print(f\"  - Valid sex values: {n_valid_sexes} / {len(sexes)}\")\n",
    "\n",
    "    # We need at least some valid demographic data for meaningful analysis\n",
    "    return n_valid_ages > 10 and n_valid_sexes > 10\n",
    "\n",
    "def prepare_and_clean_features(\n",
    "    features_dict: Dict[str, np.ndarray],\n",
    "    feature_mode: str\n",
    ") -> Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray, bool]:\n",
    "    \"\"\"\n",
    "    Prepares and cleans feature data for visualization using the full dataset.\n",
    "    Enhanced to handle NaN-only demographic columns.\n",
    "    \"\"\"\n",
    "    print(f\"\\n--- Preparing and Cleaning Features for Mode: {feature_mode} ---\")\n",
    "    feature_keys = get_feature_keys(feature_mode)\n",
    "    labels = features_dict['labels']\n",
    "\n",
    "    has_demographics = 'age' in features_dict and 'sex' in features_dict\n",
    "    if has_demographics:\n",
    "        ages = features_dict['age']\n",
    "        sexes = features_dict['sex']\n",
    "        print(\"Found 'age' and 'sex' columns in dataset.\")\n",
    "\n",
    "        # Check if demographic data is actually usable\n",
    "        demographics_valid = check_demographics_validity(ages, sexes)\n",
    "        if not demographics_valid:\n",
    "            print(\"Warning: Demographic columns contain insufficient valid data. Treating as unavailable.\")\n",
    "            has_demographics = False\n",
    "            ages = np.full_like(labels, np.nan)\n",
    "            sexes = np.full_like(labels, np.nan)\n",
    "    else:\n",
    "        ages = np.full_like(labels, np.nan)\n",
    "        sexes = np.full_like(labels, np.nan)\n",
    "        print(\"No demographic data found in dataset.\")\n",
    "\n",
    "    n_samples = len(labels)\n",
    "    print(f\"Using all {n_samples} samples for analysis.\")\n",
    "    indices = np.arange(n_samples)\n",
    "\n",
    "    labels_sub, ages_sub, sexes_sub = labels[indices], ages[indices], sexes[indices]\n",
    "\n",
    "    # Prepare feature matrix\n",
    "    X_sub_list = []\n",
    "    for idx in indices:\n",
    "        feature_vector = []\n",
    "        for key in feature_keys:\n",
    "            if key == 'acoustic_features':\n",
    "                # Acoustic features are already 1D vectors\n",
    "                feature_vector.append(features_dict[key][idx])\n",
    "            else:\n",
    "                # Spectral features need flattening\n",
    "                feature_vector.append(features_dict[key][idx].flatten())\n",
    "        X_sub_list.append(np.concatenate(feature_vector))\n",
    "\n",
    "    X_sub = np.array(X_sub_list)\n",
    "\n",
    "    # Clean data by removing rows with NaN in demographics (only if we have valid demographics)\n",
    "    if has_demographics:\n",
    "        nan_mask = pd.isna(ages_sub) | pd.isna(sexes_sub)\n",
    "        num_removed = np.sum(nan_mask)\n",
    "        if num_removed > 0:\n",
    "            print(f\"Removing {num_removed} samples with missing age/sex data for clean visualization.\")\n",
    "            clean_mask = ~nan_mask\n",
    "            X_sub, labels_sub, ages_sub, sexes_sub = X_sub[clean_mask], labels_sub[clean_mask], ages_sub[clean_mask], sexes_sub[clean_mask]\n",
    "\n",
    "    print(f\"Final feature matrix shape for visualization: {X_sub.shape}\")\n",
    "    return X_sub, labels_sub, ages_sub, sexes_sub, has_demographics\n",
    "\n",
    "def apply_nca_transform(X: np.ndarray, y: np.ndarray, n_components: int = 2) -> np.ndarray:\n",
    "    \"\"\"Apply NCA transformation to the feature matrix.\"\"\"\n",
    "    print(f\"Applying NCA transformation to {n_components} components...\")\n",
    "    try:\n",
    "        # Scale features first for better NCA performance\n",
    "        scaler = StandardScaler()\n",
    "        X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "        # Apply NCA\n",
    "        nca = NeighborhoodComponentsAnalysis(\n",
    "            n_components=n_components,\n",
    "            random_state=42,\n",
    "            max_iter=1000\n",
    "        )\n",
    "        X_nca = nca.fit_transform(X_scaled, y)\n",
    "\n",
    "        print(f\"NCA transformation successful. Output shape: {X_nca.shape}\")\n",
    "        return X_nca\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Warning: NCA transformation failed ({e}). Falling back to PCA.\")\n",
    "        # Fallback to PCA if NCA fails\n",
    "        pca = PCA(n_components=n_components, random_state=42)\n",
    "        X_scaled = StandardScaler().fit_transform(X)\n",
    "        return pca.fit_transform(X_scaled)\n",
    "\n",
    "# =============================================================================\n",
    "# --- Visualization Functions with Dataset Names and Metrics ---\n",
    "# =============================================================================\n",
    "\n",
    "def plot_comprehensive_analysis_complete(X: np.ndarray, y: np.ndarray, age: np.ndarray, output_path: str, min_age: float, max_age: float, has_demographics: bool) -> Dict[str, Dict[str, float]]:\n",
    "    \"\"\"\n",
    "    Creates a comprehensive analysis plot including both NCA and traditional methods.\n",
    "    Returns metrics for CSV export.\n",
    "    \"\"\"\n",
    "    print(\"\\n--- Creating Comprehensive Analysis Plot (NCA + Traditional) ---\")\n",
    "    if X.shape[0] < 2:\n",
    "        print(\"Not enough samples for analysis.\")\n",
    "        return {}\n",
    "\n",
    "    X_scaled = StandardScaler().fit_transform(X)\n",
    "    class_names = [cls.replace('_', ' ').title() for cls in CLASSES]\n",
    "    colors = ['#2E86C1', '#E74C3C']\n",
    "\n",
    "    # Initialize metrics dictionary\n",
    "    comprehensive_metrics = {}\n",
    "\n",
    "    # Determine layout based on demographic availability\n",
    "    if has_demographics:\n",
    "        fig, axes = plt.subplots(3, 3, figsize=(21, 18))\n",
    "        fig.suptitle(f'{DATASET_DISPLAY_NAME}: Comprehensive Feature Analysis - NCA vs Traditional Methods', fontsize=20, y=0.98)\n",
    "        age_row_idx = 2\n",
    "    else:\n",
    "        fig, axes = plt.subplots(2, 3, figsize=(21, 12))\n",
    "        fig.suptitle(f'{DATASET_DISPLAY_NAME}: Comprehensive Feature Analysis - NCA vs Traditional Methods', fontsize=20, y=0.96)\n",
    "        age_row_idx = None\n",
    "\n",
    "    # --- Row 1: NCA vs PCA ---\n",
    "    print(\"Computing NCA for 2D projection...\")\n",
    "    X_nca_2d = apply_nca_transform(X, y, n_components=2)\n",
    "    comprehensive_metrics['NCA_2D'] = calculate_all_metrics(X_nca_2d, y)\n",
    "\n",
    "    for i, name in enumerate(class_names):\n",
    "        axes[0, 0].scatter(X_nca_2d[y == i, 0], X_nca_2d[y == i, 1], c=colors[i],\n",
    "                          label=f'{name} (n={np.sum(y == i)})', alpha=0.7, s=25)\n",
    "    axes[0, 0].set(title='NCA 2D Projection by Class', xlabel='NCA Component 1', ylabel='NCA Component 2')\n",
    "    axes[0, 0].legend()\n",
    "    axes[0, 0].grid(True, alpha=0.5, linestyle=':')\n",
    "\n",
    "    # PCA for comparison\n",
    "    print(\"Computing PCA for comparison...\")\n",
    "    pca = PCA(n_components=2, random_state=42)\n",
    "    X_pca = pca.fit_transform(X_scaled)\n",
    "    comprehensive_metrics['PCA_2D'] = calculate_all_metrics(X_pca, y)\n",
    "\n",
    "    for i, name in enumerate(class_names):\n",
    "        axes[0, 1].scatter(X_pca[y == i, 0], X_pca[y == i, 1], c=colors[i],\n",
    "                          label=f'{name} (n={np.sum(y == i)})', alpha=0.7, s=25)\n",
    "    axes[0, 1].set(title='PCA 2D Projection by Class',\n",
    "                   xlabel=f'PC1 ({pca.explained_variance_ratio_[0]:.2%})',\n",
    "                   ylabel=f'PC2 ({pca.explained_variance_ratio_[1]:.2%})')\n",
    "    axes[0, 1].legend()\n",
    "    axes[0, 1].grid(True, alpha=0.5, linestyle=':')\n",
    "\n",
    "    # t-SNE\n",
    "    print(\"Computing t-SNE...\")\n",
    "    perplexity = min(30, max(5, (X.shape[0] // 5) - 1))\n",
    "    tsne = TSNE(n_components=2, random_state=42, perplexity=perplexity, init='pca', learning_rate='auto')\n",
    "    X_tsne = tsne.fit_transform(X_scaled)\n",
    "    comprehensive_metrics['TSNE_2D'] = calculate_all_metrics(X_tsne, y)\n",
    "\n",
    "    for i, name in enumerate(class_names):\n",
    "        axes[0, 2].scatter(X_tsne[y == i, 0], X_tsne[y == i, 1], c=colors[i],\n",
    "                          label=f'{name} (n={np.sum(y == i)})', alpha=0.7, s=25)\n",
    "    axes[0, 2].set(title='t-SNE Projection by Class', xlabel='t-SNE Dimension 1', ylabel='t-SNE Dimension 2')\n",
    "    axes[0, 2].legend()\n",
    "    axes[0, 2].grid(True, alpha=0.5, linestyle=':')\n",
    "\n",
    "    # --- Row 2: LDA Comparisons ---\n",
    "    # LDA on original features\n",
    "    print(\"Computing LDA on original features...\")\n",
    "    lda_orig = LinearDiscriminantAnalysis(n_components=1)\n",
    "    X_lda_orig = lda_orig.fit_transform(X_scaled, y)\n",
    "    comprehensive_metrics['LDA_Original'] = calculate_all_metrics(X_lda_orig, y)\n",
    "\n",
    "    for i, name in enumerate(class_names):\n",
    "        sns.kdeplot(X_lda_orig[y == i].ravel(), ax=axes[1, 0], color=colors[i],\n",
    "                   label=f'{name} (n={np.sum(y == i)})', fill=True, alpha=0.5)\n",
    "    axes[1, 0].set(title='LDA on Original Features', xlabel='LD1', ylabel='Density')\n",
    "    axes[1, 0].legend()\n",
    "    axes[1, 0].grid(True, alpha=0.5, linestyle=':')\n",
    "\n",
    "    # LDA on PCA features\n",
    "    print(\"Computing LDA on PCA features...\")\n",
    "    max_pca_components = min(10, X.shape[1], X.shape[0] - len(np.unique(y)))\n",
    "    pca_high = PCA(n_components=max_pca_components, random_state=42)\n",
    "    X_pca_high = pca_high.fit_transform(X_scaled)\n",
    "\n",
    "    lda_pca = LinearDiscriminantAnalysis(n_components=1)\n",
    "    X_lda_pca = lda_pca.fit_transform(X_pca_high, y)\n",
    "    comprehensive_metrics['LDA_PCA'] = calculate_all_metrics(X_lda_pca, y)\n",
    "\n",
    "    for i, name in enumerate(class_names):\n",
    "        sns.kdeplot(X_lda_pca[y == i].ravel(), ax=axes[1, 1], color=colors[i],\n",
    "                   label=f'{name} (n={np.sum(y == i)})', fill=True, alpha=0.5)\n",
    "    axes[1, 1].set(title='LDA on PCA Features', xlabel='LD1', ylabel='Density')\n",
    "    axes[1, 1].legend()\n",
    "    axes[1, 1].grid(True, alpha=0.5, linestyle=':')\n",
    "\n",
    "    # LDA on NCA features\n",
    "    print(\"Computing LDA on NCA features...\")\n",
    "    max_nca_components = min(10, X.shape[1], X.shape[0] - len(np.unique(y)))\n",
    "    X_nca_high = apply_nca_transform(X, y, n_components=max_nca_components)\n",
    "\n",
    "    lda_nca = LinearDiscriminantAnalysis(n_components=1)\n",
    "    X_lda_nca = lda_nca.fit_transform(X_nca_high, y)\n",
    "    comprehensive_metrics['LDA_NCA'] = calculate_all_metrics(X_lda_nca, y)\n",
    "\n",
    "    for i, name in enumerate(class_names):\n",
    "        sns.kdeplot(X_lda_nca[y == i].ravel(), ax=axes[1, 2], color=colors[i],\n",
    "                   label=f'{name} (n={np.sum(y == i)})', fill=True, alpha=0.5)\n",
    "    axes[1, 2].set(title='LDA on NCA Features', xlabel='LD1', ylabel='Density')\n",
    "    axes[1, 2].legend()\n",
    "    axes[1, 2].grid(True, alpha=0.5, linestyle=':')\n",
    "\n",
    "    # --- Row 3: Age-colored visualizations (only if demographics available) ---\n",
    "    if has_demographics and age_row_idx is not None:\n",
    "        scatter_nca_age = axes[age_row_idx, 0].scatter(X_nca_2d[:, 0], X_nca_2d[:, 1], c=age, cmap='plasma',\n",
    "                                            s=25, alpha=0.8, vmin=min_age, vmax=max_age)\n",
    "        fig.colorbar(scatter_nca_age, ax=axes[age_row_idx, 0], label='Age')\n",
    "        axes[age_row_idx, 0].set(title='NCA Projection by Age', xlabel='NCA Component 1', ylabel='NCA Component 2')\n",
    "        axes[age_row_idx, 0].grid(True, alpha=0.5, linestyle=':')\n",
    "\n",
    "        scatter_pca_age = axes[age_row_idx, 1].scatter(X_pca[:, 0], X_pca[:, 1], c=age, cmap='plasma',\n",
    "                                         s=25, alpha=0.8, vmin=min_age, vmax=max_age)\n",
    "        fig.colorbar(scatter_pca_age, ax=axes[age_row_idx, 1], label='Age')\n",
    "        axes[age_row_idx, 1].set(title='PCA Projection by Age', xlabel='PC1', ylabel='PC2')\n",
    "        axes[age_row_idx, 1].grid(True, alpha=0.5, linestyle=':')\n",
    "\n",
    "        scatter_tsne_age = axes[age_row_idx, 2].scatter(X_tsne[:, 0], X_tsne[:, 1], c=age, cmap='plasma',\n",
    "                                             s=25, alpha=0.8, vmin=min_age, vmax=max_age)\n",
    "        fig.colorbar(scatter_tsne_age, ax=axes[age_row_idx, 2], label='Age')\n",
    "        axes[age_row_idx, 2].set(title='t-SNE Projection by Age', xlabel='t-SNE Dimension 1', ylabel='t-SNE Dimension 2')\n",
    "        axes[age_row_idx, 2].grid(True, alpha=0.5, linestyle=':')\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 0.97])\n",
    "    save_path = os.path.join(output_path, \"comprehensive_analysis_complete.png\")\n",
    "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"Saved comprehensive analysis plots to '{os.path.basename(save_path)}'\")\n",
    "\n",
    "    return comprehensive_metrics\n",
    "\n",
    "def plot_demographic_analysis_complete(X: np.ndarray, y: np.ndarray, age: np.ndarray, sex: np.ndarray, output_path: str, min_age: float, max_age: float):\n",
    "    \"\"\"\n",
    "    Creates demographic analysis plots with both NCA and traditional methods.\n",
    "    \"\"\"\n",
    "    print(\"\\n--- Creating Demographic Analysis Plots (Complete) ---\")\n",
    "    if X.shape[0] < 2:\n",
    "        print(\"Not enough samples for analysis.\")\n",
    "        return\n",
    "\n",
    "    sex_labels = ['Female' if s == 0 else 'Male' for s in sex]\n",
    "    df = pd.DataFrame({\n",
    "        'Age': age,\n",
    "        'Sex': sex_labels,\n",
    "        'Class': [CLASSES[int(label)].replace('_', ' ').title() for label in y]\n",
    "    })\n",
    "\n",
    "    fig, axes = plt.subplots(3, 2, figsize=(16, 21))\n",
    "    fig.suptitle(f'{DATASET_DISPLAY_NAME}: Demographic Analysis - NCA vs Traditional Methods', fontsize=20, y=0.98)\n",
    "    class_colors = {'Healthy Control': '#2E86C1', 'Parkinson Patient': '#E74C3C'}\n",
    "    sex_colors = {'Female': '#DB7093', 'Male': '#4682B4'}\n",
    "\n",
    "    # Apply transformations\n",
    "    X_nca = apply_nca_transform(X, y, n_components=2)\n",
    "    X_scaled = StandardScaler().fit_transform(X)\n",
    "    pca = PCA(n_components=2, random_state=42)\n",
    "    X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "    # --- Row 1: Age Distributions ---\n",
    "    sns.violinplot(ax=axes[0, 0], data=df, x='Class', y='Age', hue='Class', palette=class_colors, legend=False)\n",
    "    axes[0, 0].set_title('Age Distribution by Class')\n",
    "    axes[0, 0].grid(True, alpha=0.5, linestyle=':')\n",
    "\n",
    "    sns.countplot(ax=axes[0, 1], data=df, x='Sex', hue='Class', palette=class_colors, order=['Female', 'Male'])\n",
    "    axes[0, 1].set_title('Sex Distribution by Class')\n",
    "    axes[0, 1].set_ylabel('Count')\n",
    "\n",
    "    # --- Row 2: NCA Projections ---\n",
    "    scatter_age_nca = axes[1, 0].scatter(X_nca[:, 0], X_nca[:, 1], c=age, cmap='plasma',\n",
    "                                   s=25, alpha=0.8, vmin=min_age, vmax=max_age)\n",
    "    fig.colorbar(scatter_age_nca, ax=axes[1, 0], label='Age')\n",
    "    axes[1, 0].set_title('NCA Projection by Age')\n",
    "    axes[1, 0].set_xlabel('NCA Component 1')\n",
    "    axes[1, 0].set_ylabel('NCA Component 2')\n",
    "    axes[1, 0].grid(True, alpha=0.5, linestyle=':')\n",
    "\n",
    "    sns.scatterplot(ax=axes[1, 1], x=X_nca[:, 0], y=X_nca[:, 1], hue=df['Sex'],\n",
    "                   palette=sex_colors, s=25, alpha=0.8)\n",
    "    axes[1, 1].set_title('NCA Projection by Sex')\n",
    "    axes[1, 1].set_xlabel('NCA Component 1')\n",
    "    axes[1, 1].set_ylabel('NCA Component 2')\n",
    "    axes[1, 1].grid(True, alpha=0.5, linestyle=':')\n",
    "\n",
    "    # --- Row 3: PCA Projections for Comparison ---\n",
    "    scatter_age_pca = axes[2, 0].scatter(X_pca[:, 0], X_pca[:, 1], c=age, cmap='plasma',\n",
    "                                   s=25, alpha=0.8, vmin=min_age, vmax=max_age)\n",
    "    fig.colorbar(scatter_age_pca, ax=axes[2, 0], label='Age')\n",
    "    axes[2, 0].set_title('PCA Projection by Age')\n",
    "    axes[2, 0].set_xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.2%})')\n",
    "    axes[2, 0].set_ylabel(f'PC2 ({pca.explained_variance_ratio_[1]:.2%})')\n",
    "    axes[2, 0].grid(True, alpha=0.5, linestyle=':')\n",
    "\n",
    "    sns.scatterplot(ax=axes[2, 1], x=X_pca[:, 0], y=X_pca[:, 1], hue=df['Sex'],\n",
    "                   palette=sex_colors, s=25, alpha=0.8)\n",
    "    axes[2, 1].set_title('PCA Projection by Sex')\n",
    "    axes[2, 1].set_xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.2%})')\n",
    "    axes[2, 1].set_ylabel(f'PC2 ({pca.explained_variance_ratio_[1]:.2%})')\n",
    "    axes[2, 1].grid(True, alpha=0.5, linestyle=':')\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "    save_path = os.path.join(output_path, \"demographic_analysis_complete.png\")\n",
    "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"Saved demographic analysis to '{os.path.basename(save_path)}'\")\n",
    "\n",
    "def plot_individual_feature_separation_complete(features_dict: Dict[str, np.ndarray], output_path: str, feature_mode: str) -> Dict[str, Dict[str, Dict[str, float]]]:\n",
    "    \"\"\"\n",
    "    Creates comprehensive plots for each audio feature type with NCA, PCA, t-SNE, and LDA.\n",
    "    Returns metrics for CSV export.\n",
    "    \"\"\"\n",
    "    print(\"\\n--- Creating Individual Audio Feature Analysis (Complete) ---\")\n",
    "    feature_keys = get_feature_keys(feature_mode)\n",
    "\n",
    "    titles = {\n",
    "        'spectrogram': 'Spectrogram',\n",
    "        'mel_spectrogram': 'Mel Spectrogram',\n",
    "        'mfcc': 'MFCC',\n",
    "        'fsc': 'Spectral Centroid',\n",
    "        'acoustic_features': 'Acoustic Features'\n",
    "    }\n",
    "\n",
    "    labels, n_samples = features_dict['labels'], len(features_dict['labels'])\n",
    "    indices = np.arange(n_samples)\n",
    "    labels_sub = labels[indices]\n",
    "    class_names, colors = [\"Healthy Control\", \"Parkinson Patient\"], ['#2E86C1', '#E74C3C']\n",
    "\n",
    "    # Initialize metrics dictionary\n",
    "    individual_metrics = {}\n",
    "\n",
    "    fig, axes = plt.subplots(4, len(feature_keys), figsize=(7 * len(feature_keys), 20),\n",
    "                           squeeze=False, constrained_layout=True)\n",
    "    fig.suptitle(f'{DATASET_DISPLAY_NAME}: Individual Audio Feature Analysis - Complete Comparison', fontsize=16)\n",
    "\n",
    "    for col, feat_key in enumerate(feature_keys):\n",
    "        feat_title = titles.get(feat_key, feat_key)\n",
    "        print(f\"  Processing {feat_title}...\")\n",
    "        individual_metrics[feat_key] = {}\n",
    "\n",
    "        # Prepare feature matrix\n",
    "        if feat_key == 'acoustic_features':\n",
    "            X = np.array([features_dict[feat_key][i] for i in indices])\n",
    "        else:\n",
    "            X = np.array([features_dict[feat_key][i].flatten() for i in indices])\n",
    "\n",
    "        X_scaled = StandardScaler().fit_transform(X)\n",
    "\n",
    "        # Row 1: NCA\n",
    "        X_nca = apply_nca_transform(X, labels_sub, n_components=2)\n",
    "        individual_metrics[feat_key]['NCA_2D'] = calculate_all_metrics(X_nca, labels_sub)\n",
    "        ax = axes[0, col]\n",
    "        for i, name in enumerate(class_names):\n",
    "            ax.scatter(X_nca[labels_sub == i, 0], X_nca[labels_sub == i, 1],\n",
    "                      c=colors[i], label=name, alpha=0.7, s=15)\n",
    "        ax.set(title=f'NCA: {feat_title}', xlabel='NCA Component 1', ylabel='NCA Component 2')\n",
    "        ax.legend()\n",
    "        ax.grid(True, alpha=0.5, linestyle=':')\n",
    "\n",
    "        # Row 2: PCA\n",
    "        pca = PCA(n_components=2, random_state=42)\n",
    "        X_pca = pca.fit_transform(X_scaled)\n",
    "        individual_metrics[feat_key]['PCA_2D'] = calculate_all_metrics(X_pca, labels_sub)\n",
    "        ax = axes[1, col]\n",
    "        for i, name in enumerate(class_names):\n",
    "            ax.scatter(X_pca[labels_sub == i, 0], X_pca[labels_sub == i, 1],\n",
    "                      c=colors[i], label=name, alpha=0.7, s=15)\n",
    "        ax.set(title=f'PCA: {feat_title}',\n",
    "               xlabel=f'PC1 ({pca.explained_variance_ratio_[0]:.2%})',\n",
    "               ylabel=f'PC2 ({pca.explained_variance_ratio_[1]:.2%})')\n",
    "        ax.legend()\n",
    "        ax.grid(True, alpha=0.5, linestyle=':')\n",
    "\n",
    "        # Row 3: t-SNE\n",
    "        perplexity = min(30, max(5, (X_scaled.shape[0] // 5) - 1))\n",
    "        tsne = TSNE(n_components=2, random_state=42, perplexity=perplexity, init='pca', learning_rate='auto')\n",
    "        X_tsne = tsne.fit_transform(X_scaled)\n",
    "        individual_metrics[feat_key]['TSNE_2D'] = calculate_all_metrics(X_tsne, labels_sub)\n",
    "        ax = axes[2, col]\n",
    "        for i, name in enumerate(class_names):\n",
    "            ax.scatter(X_tsne[labels_sub == i, 0], X_tsne[labels_sub == i, 1],\n",
    "                      c=colors[i], label=name, alpha=0.7, s=15)\n",
    "        ax.set(title=f't-SNE: {feat_title}', xlabel='t-SNE Dim 1', ylabel='t-SNE Dim 2')\n",
    "        ax.legend()\n",
    "        ax.grid(True, alpha=0.5, linestyle=':')\n",
    "\n",
    "        # Row 4: LDA (comparing NCA vs Original features)\n",
    "        ax = axes[3, col]\n",
    "\n",
    "        # LDA on original features\n",
    "        lda_orig = LinearDiscriminantAnalysis(n_components=1)\n",
    "        X_lda_orig = lda_orig.fit_transform(X_scaled, labels_sub)\n",
    "        individual_metrics[feat_key]['LDA_Original'] = calculate_all_metrics(X_lda_orig, labels_sub)\n",
    "\n",
    "        # LDA on NCA features\n",
    "        max_components = min(5, X.shape[1], X.shape[0] - len(np.unique(labels_sub)))\n",
    "        X_nca_high = apply_nca_transform(X, labels_sub, n_components=max_components)\n",
    "        lda_nca = LinearDiscriminantAnalysis(n_components=1)\n",
    "        X_lda_nca = lda_nca.fit_transform(X_nca_high, labels_sub)\n",
    "        individual_metrics[feat_key]['LDA_NCA'] = calculate_all_metrics(X_lda_nca, labels_sub)\n",
    "\n",
    "        for i, name in enumerate(class_names):\n",
    "            sns.kdeplot(X_lda_orig[labels_sub == i].ravel(), ax=ax, color=colors[i],\n",
    "                       label=f'{name} (Orig)', fill=False, alpha=0.8, linestyle='-')\n",
    "            sns.kdeplot(X_lda_nca[labels_sub == i].ravel(), ax=ax, color=colors[i],\n",
    "                       label=f'{name} (NCA)', fill=False, alpha=0.8, linestyle='--')\n",
    "\n",
    "        ax.set(title=f'LDA: {feat_title}', xlabel='LD1', ylabel='Density')\n",
    "        ax.legend()\n",
    "        ax.grid(True, alpha=0.5, linestyle=':')\n",
    "\n",
    "        del X, X_scaled\n",
    "        gc.collect()\n",
    "\n",
    "    save_path = os.path.join(output_path, \"individual_feature_analysis_complete.png\")\n",
    "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"Saved individual feature complete analysis to '{os.path.basename(save_path)}'\")\n",
    "\n",
    "    return individual_metrics\n",
    "\n",
    "def plot_individual_features_by_age_complete(\n",
    "    features_dict: Dict[str, np.ndarray],\n",
    "    output_path: str,\n",
    "    feature_mode: str,\n",
    "    min_age: float,\n",
    "    max_age: float\n",
    "):\n",
    "    \"\"\"\n",
    "    Creates comprehensive age-colored plots for each audio feature with NCA, PCA, and t-SNE.\n",
    "    \"\"\"\n",
    "    print(\"\\n--- Creating Individual Audio Feature Analysis by Age (Complete) ---\")\n",
    "    feature_keys = get_feature_keys(feature_mode)\n",
    "\n",
    "    titles = {\n",
    "        'spectrogram': 'Spectrogram',\n",
    "        'mel_spectrogram': 'Mel Spectrogram',\n",
    "        'mfcc': 'MFCC',\n",
    "        'fsc': 'Spectral Centroid',\n",
    "        'acoustic_features': 'Acoustic Features'\n",
    "    }\n",
    "\n",
    "    n_samples = len(features_dict['labels'])\n",
    "    indices = np.arange(n_samples)\n",
    "    ages_sub = features_dict['age'][indices]\n",
    "    clean_mask = ~pd.isna(ages_sub)\n",
    "    indices_clean = indices[clean_mask]\n",
    "    ages_clean = ages_sub[clean_mask]\n",
    "\n",
    "    if len(indices_clean) < 2:\n",
    "        print(\"Not enough data with valid age information to create plots. Skipping.\")\n",
    "        return\n",
    "\n",
    "    labels_clean = features_dict['labels'][indices_clean]\n",
    "\n",
    "    fig, axes = plt.subplots(\n",
    "        3, len(feature_keys),\n",
    "        figsize=(7 * len(feature_keys), 15),\n",
    "        squeeze=False,\n",
    "        constrained_layout=True\n",
    "    )\n",
    "    fig.suptitle(f'{DATASET_DISPLAY_NAME}: Individual Audio Feature Analysis by Age - Complete Comparison', fontsize=16)\n",
    "\n",
    "    mappable = None\n",
    "\n",
    "    for col, feat_key in enumerate(feature_keys):\n",
    "        feat_title = titles.get(feat_key, feat_key)\n",
    "        print(f\"  Processing {feat_title}...\")\n",
    "\n",
    "        # Prepare feature matrix\n",
    "        if feat_key == 'acoustic_features':\n",
    "            X = np.array([features_dict[feat_key][i] for i in indices_clean])\n",
    "        else:\n",
    "            X = np.array([features_dict[feat_key][i].flatten() for i in indices_clean])\n",
    "\n",
    "        X_scaled = StandardScaler().fit_transform(X)\n",
    "\n",
    "        # Row 1: NCA colored by Age\n",
    "        X_nca = apply_nca_transform(X, labels_clean, n_components=2)\n",
    "        ax = axes[0, col]\n",
    "        scatter1 = ax.scatter(X_nca[:, 0], X_nca[:, 1], c=ages_clean, cmap='plasma',\n",
    "                            vmin=min_age, vmax=max_age, alpha=0.8, s=15)\n",
    "        ax.set(title=f'NCA: {feat_title}', xlabel='NCA Component 1', ylabel='NCA Component 2')\n",
    "        ax.grid(True, alpha=0.5, linestyle=':')\n",
    "        if mappable is None:\n",
    "            mappable = scatter1\n",
    "\n",
    "        # Row 2: PCA colored by Age\n",
    "        pca = PCA(n_components=2, random_state=42)\n",
    "        X_pca = pca.fit_transform(X_scaled)\n",
    "        ax = axes[1, col]\n",
    "        ax.scatter(X_pca[:, 0], X_pca[:, 1], c=ages_clean, cmap='plasma',\n",
    "                  vmin=min_age, vmax=max_age, alpha=0.8, s=15)\n",
    "        ax.set(title=f'PCA: {feat_title}',\n",
    "               xlabel=f'PC1 ({pca.explained_variance_ratio_[0]:.2%})',\n",
    "               ylabel=f'PC2 ({pca.explained_variance_ratio_[1]:.2%})')\n",
    "        ax.grid(True, alpha=0.5, linestyle=':')\n",
    "\n",
    "        # Row 3: t-SNE colored by Age\n",
    "        perplexity = min(30, max(5, (X_scaled.shape[0] // 5) - 1))\n",
    "        tsne = TSNE(n_components=2, random_state=42, perplexity=perplexity, init='pca', learning_rate='auto')\n",
    "        X_tsne = tsne.fit_transform(X_scaled)\n",
    "        ax = axes[2, col]\n",
    "        ax.scatter(X_tsne[:, 0], X_tsne[:, 1], c=ages_clean, cmap='plasma',\n",
    "                  vmin=min_age, vmax=max_age, alpha=0.8, s=15)\n",
    "        ax.set(title=f't-SNE: {feat_title}', xlabel='t-SNE Dim 1', ylabel='t-SNE Dim 2')\n",
    "        ax.grid(True, alpha=0.5, linestyle=':')\n",
    "\n",
    "        del X, X_scaled\n",
    "        gc.collect()\n",
    "\n",
    "    fig.colorbar(mappable, ax=axes.ravel().tolist(), label='Age', pad=0.01, aspect=30)\n",
    "\n",
    "    save_path = os.path.join(output_path, \"individual_feature_analysis_by_age_complete.png\")\n",
    "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"Saved individual feature analysis by age (complete) to '{os.path.basename(save_path)}'\")\n",
    "\n",
    "def plot_method_comparison_summary(X: np.ndarray, y: np.ndarray, output_path: str) -> Dict[str, Dict[str, float]]:\n",
    "    \"\"\"\n",
    "    Creates a summary comparison of all dimensionality reduction methods.\n",
    "    Returns metrics for CSV export.\n",
    "    \"\"\"\n",
    "    print(\"\\n--- Creating Method Comparison Summary ---\")\n",
    "    if X.shape[0] < 2:\n",
    "        print(\"Not enough samples for analysis.\")\n",
    "        return {}\n",
    "\n",
    "    X_scaled = StandardScaler().fit_transform(X)\n",
    "    class_names = [cls.replace('_', ' ').title() for cls in CLASSES]\n",
    "    colors = ['#2E86C1', '#E74C3C']\n",
    "\n",
    "    # Initialize metrics dictionary\n",
    "    summary_metrics = {}\n",
    "\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    fig.suptitle(f'{DATASET_DISPLAY_NAME}: Dimensionality Reduction Methods Comparison', fontsize=18, y=0.98)\n",
    "\n",
    "    # NCA\n",
    "    print(\"Computing NCA...\")\n",
    "    X_nca = apply_nca_transform(X, y, n_components=2)\n",
    "    summary_metrics['NCA'] = calculate_all_metrics(X_nca, y)\n",
    "    for i, name in enumerate(class_names):\n",
    "        axes[0, 0].scatter(X_nca[y == i, 0], X_nca[y == i, 1], c=colors[i],\n",
    "                          label=f'{name} (n={np.sum(y == i)})', alpha=0.7, s=25)\n",
    "    axes[0, 0].set(title='Neighborhood Component Analysis (NCA)',\n",
    "                   xlabel='NCA Component 1', ylabel='NCA Component 2')\n",
    "    axes[0, 0].legend()\n",
    "    axes[0, 0].grid(True, alpha=0.5, linestyle=':')\n",
    "\n",
    "    # PCA\n",
    "    print(\"Computing PCA...\")\n",
    "    pca = PCA(n_components=2, random_state=42)\n",
    "    X_pca = pca.fit_transform(X_scaled)\n",
    "    summary_metrics['PCA'] = calculate_all_metrics(X_pca, y)\n",
    "    for i, name in enumerate(class_names):\n",
    "        axes[0, 1].scatter(X_pca[y == i, 0], X_pca[y == i, 1], c=colors[i],\n",
    "                          label=f'{name} (n={np.sum(y == i)})', alpha=0.7, s=25)\n",
    "    axes[0, 1].set(title='Principal Component Analysis (PCA)',\n",
    "                   xlabel=f'PC1 ({pca.explained_variance_ratio_[0]:.2%})',\n",
    "                   ylabel=f'PC2 ({pca.explained_variance_ratio_[1]:.2%})')\n",
    "    axes[0, 1].legend()\n",
    "    axes[0, 1].grid(True, alpha=0.5, linestyle=':')\n",
    "\n",
    "    # t-SNE\n",
    "    print(\"Computing t-SNE...\")\n",
    "    perplexity = min(30, max(5, (X.shape[0] // 5) - 1))\n",
    "    tsne = TSNE(n_components=2, random_state=42, perplexity=perplexity, init='pca', learning_rate='auto')\n",
    "    X_tsne = tsne.fit_transform(X_scaled)\n",
    "    summary_metrics['TSNE'] = calculate_all_metrics(X_tsne, y)\n",
    "    for i, name in enumerate(class_names):\n",
    "        axes[1, 0].scatter(X_tsne[y == i, 0], X_tsne[y == i, 1], c=colors[i],\n",
    "                          label=f'{name} (n={np.sum(y == i)})', alpha=0.7, s=25)\n",
    "    axes[1, 0].set(title='t-Distributed Stochastic Neighbor Embedding (t-SNE)',\n",
    "                   xlabel='t-SNE Dimension 1', ylabel='t-SNE Dimension 2')\n",
    "    axes[1, 0].legend()\n",
    "    axes[1, 0].grid(True, alpha=0.5, linestyle=':')\n",
    "\n",
    "    # LDA Comparison\n",
    "    print(\"Computing LDA comparison...\")\n",
    "    lda_orig = LinearDiscriminantAnalysis(n_components=1)\n",
    "    X_lda_orig = lda_orig.fit_transform(X_scaled, y)\n",
    "    summary_metrics['LDA_Original'] = calculate_all_metrics(X_lda_orig, y)\n",
    "\n",
    "    max_components = min(10, X.shape[1], X.shape[0] - len(np.unique(y)))\n",
    "    X_nca_high = apply_nca_transform(X, y, n_components=max_components)\n",
    "    lda_nca = LinearDiscriminantAnalysis(n_components=1)\n",
    "    X_lda_nca = lda_nca.fit_transform(X_nca_high, y)\n",
    "    summary_metrics['LDA_NCA'] = calculate_all_metrics(X_lda_nca, y)\n",
    "\n",
    "    for i, name in enumerate(class_names):\n",
    "        sns.kdeplot(X_lda_orig[y == i].ravel(), ax=axes[1, 1], color=colors[i],\n",
    "                   label=f'{name} (Original)', fill=False, alpha=0.8, linestyle='-', linewidth=2)\n",
    "        sns.kdeplot(X_lda_nca[y == i].ravel(), ax=axes[1, 1], color=colors[i],\n",
    "                   label=f'{name} (NCA-enhanced)', fill=False, alpha=0.8, linestyle='--', linewidth=2)\n",
    "\n",
    "    axes[1, 1].set(title='Linear Discriminant Analysis (LDA) Comparison', xlabel='LD1', ylabel='Density')\n",
    "    axes[1, 1].legend()\n",
    "    axes[1, 1].grid(True, alpha=0.5, linestyle=':')\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 0.97])\n",
    "    save_path = os.path.join(output_path, \"method_comparison_summary.png\")\n",
    "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"Saved method comparison summary to '{os.path.basename(save_path)}'\")\n",
    "\n",
    "    return summary_metrics\n",
    "\n",
    "# =============================================================================\n",
    "# --- CSV Export Functions ---\n",
    "# =============================================================================\n",
    "\n",
    "def save_comprehensive_metrics_to_csv(metrics: Dict[str, Dict[str, float]], output_path: str):\n",
    "    \"\"\"Save comprehensive analysis metrics to CSV.\"\"\"\n",
    "    if not metrics:\n",
    "        return\n",
    "\n",
    "    df_data = []\n",
    "    for method, method_metrics in metrics.items():\n",
    "        row = {'Method': method, 'Dataset': DATASET_DISPLAY_NAME}\n",
    "        row.update(method_metrics)\n",
    "        df_data.append(row)\n",
    "\n",
    "    df = pd.DataFrame(df_data)\n",
    "    csv_path = os.path.join(output_path, \"comprehensive_analysis_metrics.csv\")\n",
    "    df.to_csv(csv_path, index=False)\n",
    "    print(f\"Saved comprehensive metrics to '{os.path.basename(csv_path)}'\")\n",
    "\n",
    "def save_summary_metrics_to_csv(metrics: Dict[str, Dict[str, float]], output_path: str):\n",
    "    \"\"\"Save method comparison summary metrics to CSV.\"\"\"\n",
    "    if not metrics:\n",
    "        return\n",
    "\n",
    "    df_data = []\n",
    "    for method, method_metrics in metrics.items():\n",
    "        row = {'Method': method, 'Dataset': DATASET_DISPLAY_NAME}\n",
    "        row.update(method_metrics)\n",
    "        df_data.append(row)\n",
    "\n",
    "    df = pd.DataFrame(df_data)\n",
    "    csv_path = os.path.join(output_path, \"method_comparison_metrics.csv\")\n",
    "    df.to_csv(csv_path, index=False)\n",
    "    print(f\"Saved method comparison metrics to '{os.path.basename(csv_path)}'\")\n",
    "\n",
    "def save_individual_features_metrics_to_csv(metrics: Dict[str, Dict[str, Dict[str, float]]], output_path: str):\n",
    "    \"\"\"Save individual feature analysis metrics to CSV.\"\"\"\n",
    "    if not metrics:\n",
    "        return\n",
    "\n",
    "    df_data = []\n",
    "    for feature, feature_methods in metrics.items():\n",
    "        for method, method_metrics in feature_methods.items():\n",
    "            row = {'Feature': feature, 'Method': method, 'Dataset': DATASET_DISPLAY_NAME}\n",
    "            row.update(method_metrics)\n",
    "            df_data.append(row)\n",
    "\n",
    "    df = pd.DataFrame(df_data)\n",
    "    csv_path = os.path.join(output_path, \"individual_features_metrics.csv\")\n",
    "    df.to_csv(csv_path, index=False)\n",
    "    print(f\"Saved individual features metrics to '{os.path.basename(csv_path)}'\")\n",
    "\n",
    "# =============================================================================\n",
    "# --- Main Execution ---\n",
    "# =============================================================================\n",
    "def main():\n",
    "    \"\"\"Main function to run the complete analysis workflow with both NCA and traditional methods.\"\"\"\n",
    "    print(\"=\" * 70)\n",
    "    print(\"=== Comprehensive Feature & Demographic Analysis ===\")\n",
    "    print(\"=== (NCA + Traditional Methods + Metrics) ===\")\n",
    "    print(\"=\" * 70)\n",
    "\n",
    "    try:\n",
    "        features = load_features(FEATURES_FILE)\n",
    "\n",
    "        # Check for global age range (handle all-NaN case)\n",
    "        global_min_age, global_max_age = None, None\n",
    "        if 'age' in features:\n",
    "            valid_ages = features['age'][~pd.isna(features['age'])]\n",
    "            if len(valid_ages) > 0:\n",
    "                global_min_age, global_max_age = np.min(valid_ages), np.max(valid_ages)\n",
    "                print(f\"Global age range: {global_min_age:.1f} - {global_max_age:.1f}\")\n",
    "            else:\n",
    "                print(\"Warning: All age values are NaN\")\n",
    "                global_min_age, global_max_age = 0, 100  # Default range\n",
    "\n",
    "        X, y, age, sex, has_demographics = prepare_and_clean_features(features, FEATURE_MODE)\n",
    "\n",
    "        # Generate method comparison summary (always create this)\n",
    "        summary_metrics = plot_method_comparison_summary(X, y, RESULTS_OUTPUT_PATH)\n",
    "        save_summary_metrics_to_csv(summary_metrics, RESULTS_OUTPUT_PATH)\n",
    "\n",
    "        # Generate comprehensive analysis\n",
    "        comprehensive_metrics = plot_comprehensive_analysis_complete(X, y, age, RESULTS_OUTPUT_PATH,\n",
    "                                           global_min_age or 0, global_max_age or 100, has_demographics)\n",
    "        save_comprehensive_metrics_to_csv(comprehensive_metrics, RESULTS_OUTPUT_PATH)\n",
    "\n",
    "        # Generate individual feature analysis (always create this)\n",
    "        individual_metrics = plot_individual_feature_separation_complete(features, RESULTS_OUTPUT_PATH, FEATURE_MODE)\n",
    "        save_individual_features_metrics_to_csv(individual_metrics, RESULTS_OUTPUT_PATH)\n",
    "\n",
    "        # Generate demographic-specific analyses if data is available\n",
    "        if has_demographics and global_min_age is not None:\n",
    "            plot_demographic_analysis_complete(X, y, age, sex, RESULTS_OUTPUT_PATH, global_min_age, global_max_age)\n",
    "            plot_individual_features_by_age_complete(features, RESULTS_OUTPUT_PATH, FEATURE_MODE, global_min_age, global_max_age)\n",
    "        else:\n",
    "            print(\"\\nDemographic data not available or insufficient. Skipping demographic-related plots.\")\n",
    "            print(\"Generated plots will focus on class separation using available features only.\")\n",
    "\n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(\"=== Analysis Summary ===\")\n",
    "        print(f\"Dataset: {DATASET} ({DATASET_DISPLAY_NAME})\")\n",
    "        print(f\"Mode: {MODE}\")\n",
    "        print(f\"Feature Mode: {FEATURE_MODE}\")\n",
    "        print(f\"Demographics Available: {has_demographics}\")\n",
    "        print(f\"Total Samples: {len(X)}\")\n",
    "        print(f\"Feature Dimensionality: {X.shape[1] if len(X.shape) > 1 else 'N/A'}\")\n",
    "\n",
    "        generated_files = [\n",
    "            \"method_comparison_summary.png\",\n",
    "            \"method_comparison_metrics.csv\",\n",
    "            \"comprehensive_analysis_complete.png\",\n",
    "            \"comprehensive_analysis_metrics.csv\",\n",
    "            \"individual_feature_analysis_complete.png\",\n",
    "            \"individual_features_metrics.csv\"\n",
    "        ]\n",
    "\n",
    "        if has_demographics:\n",
    "            generated_files.extend([\n",
    "                \"demographic_analysis_complete.png\",\n",
    "                \"individual_feature_analysis_by_age_complete.png\"\n",
    "            ])\n",
    "\n",
    "        print(f\"\\nGenerated Files ({len(generated_files)}):\")\n",
    "        for file in generated_files:\n",
    "            print(f\"  ✓ {file}\")\n",
    "\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"\\nERROR: {e}\")\n",
    "        print(\"Please ensure the features file exists and the path is correct.\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\nAn unexpected error occurred: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "    finally:\n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(\"=== Complete Analysis Finished ===\")\n",
    "        print(f\"All generated files are in: {RESULTS_OUTPUT_PATH}\")\n",
    "        print(\"=\" * 70)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ],
   "id": "f7f2b26c5e0b0fc8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "=== Comprehensive Feature & Demographic Analysis ===\n",
      "=== (NCA + Traditional Methods + Metrics) ===\n",
      "======================================================================\n",
      "Loading features from D:\\Projects\\Voice\\Parkinson-s-Disease-Detector-Using-AI\\Parkinson-s-Disease-Detector-Using-AI\\1\\UAMS\\data\\features_ALL_VALIDS_ALL.npz\n",
      "Loaded data shapes:\n",
      "  - spectrogram: (328, 1025, 94)\n",
      "  - mel_spectrogram: (328, 30, 94)\n",
      "  - fsc: (328, 1, 94)\n",
      "  - mfcc: (328, 30, 94)\n",
      "  - labels: (328,)\n",
      "  - sex: (328,)\n",
      "  - age: (328,)\n",
      "Global age range: 18.0 - 85.0\n",
      "\n",
      "--- Preparing and Cleaning Features for Mode: ALL ---\n",
      "Found 'age' and 'sex' columns in dataset.\n",
      "Demographics check:\n",
      "  - Valid age values: 328 / 328\n",
      "  - Valid sex values: 328 / 328\n",
      "Using all 328 samples for analysis.\n",
      "Final feature matrix shape for visualization: (328, 102084)\n",
      "\n",
      "--- Creating Method Comparison Summary ---\n",
      "Computing NCA...\n",
      "Applying NCA transformation to 2 components...\n",
      "NCA transformation successful. Output shape: (328, 2)\n",
      "Computing PCA...\n",
      "Computing t-SNE...\n",
      "Computing LDA comparison...\n",
      "Applying NCA transformation to 10 components...\n",
      "NCA transformation successful. Output shape: (328, 10)\n",
      "Saved method comparison summary to 'method_comparison_summary.png'\n",
      "Saved method comparison metrics to 'method_comparison_metrics.csv'\n",
      "\n",
      "--- Creating Comprehensive Analysis Plot (NCA + Traditional) ---\n",
      "Computing NCA for 2D projection...\n",
      "Applying NCA transformation to 2 components...\n",
      "NCA transformation successful. Output shape: (328, 2)\n",
      "Computing PCA for comparison...\n",
      "Computing t-SNE...\n",
      "Computing LDA on original features...\n",
      "Computing LDA on PCA features...\n",
      "Computing LDA on NCA features...\n",
      "Applying NCA transformation to 10 components...\n",
      "NCA transformation successful. Output shape: (328, 10)\n",
      "Saved comprehensive analysis plots to 'comprehensive_analysis_complete.png'\n",
      "Saved comprehensive metrics to 'comprehensive_analysis_metrics.csv'\n",
      "\n",
      "--- Creating Individual Audio Feature Analysis (Complete) ---\n",
      "  Processing Spectrogram...\n",
      "Applying NCA transformation to 2 components...\n",
      "NCA transformation successful. Output shape: (328, 2)\n",
      "Applying NCA transformation to 5 components...\n",
      "NCA transformation successful. Output shape: (328, 5)\n",
      "  Processing Mel Spectrogram...\n",
      "Applying NCA transformation to 2 components...\n",
      "NCA transformation successful. Output shape: (328, 2)\n",
      "Applying NCA transformation to 5 components...\n",
      "NCA transformation successful. Output shape: (328, 5)\n",
      "  Processing MFCC...\n",
      "Applying NCA transformation to 2 components...\n",
      "NCA transformation successful. Output shape: (328, 2)\n",
      "Applying NCA transformation to 5 components...\n",
      "NCA transformation successful. Output shape: (328, 5)\n",
      "  Processing Spectral Centroid...\n",
      "Applying NCA transformation to 2 components...\n",
      "NCA transformation successful. Output shape: (328, 2)\n",
      "Applying NCA transformation to 5 components...\n",
      "NCA transformation successful. Output shape: (328, 5)\n",
      "Saved individual feature complete analysis to 'individual_feature_analysis_complete.png'\n",
      "Saved individual features metrics to 'individual_features_metrics.csv'\n",
      "\n",
      "--- Creating Demographic Analysis Plots (Complete) ---\n",
      "Applying NCA transformation to 2 components...\n",
      "NCA transformation successful. Output shape: (328, 2)\n",
      "Saved demographic analysis to 'demographic_analysis_complete.png'\n",
      "\n",
      "--- Creating Individual Audio Feature Analysis by Age (Complete) ---\n",
      "  Processing Spectrogram...\n",
      "Applying NCA transformation to 2 components...\n",
      "NCA transformation successful. Output shape: (328, 2)\n",
      "  Processing Mel Spectrogram...\n",
      "Applying NCA transformation to 2 components...\n",
      "NCA transformation successful. Output shape: (328, 2)\n",
      "  Processing MFCC...\n",
      "Applying NCA transformation to 2 components...\n",
      "NCA transformation successful. Output shape: (328, 2)\n",
      "  Processing Spectral Centroid...\n",
      "Applying NCA transformation to 2 components...\n",
      "NCA transformation successful. Output shape: (328, 2)\n",
      "Saved individual feature analysis by age (complete) to 'individual_feature_analysis_by_age_complete.png'\n",
      "\n",
      "======================================================================\n",
      "=== Analysis Summary ===\n",
      "Dataset: UAMS_DATASET (UAMS)\n",
      "Mode: ALL_VALIDS\n",
      "Feature Mode: ALL\n",
      "Demographics Available: True\n",
      "Total Samples: 328\n",
      "Feature Dimensionality: 102084\n",
      "\n",
      "Generated Files (8):\n",
      "  ✓ method_comparison_summary.png\n",
      "  ✓ method_comparison_metrics.csv\n",
      "  ✓ comprehensive_analysis_complete.png\n",
      "  ✓ comprehensive_analysis_metrics.csv\n",
      "  ✓ individual_feature_analysis_complete.png\n",
      "  ✓ individual_features_metrics.csv\n",
      "  ✓ demographic_analysis_complete.png\n",
      "  ✓ individual_feature_analysis_by_age_complete.png\n",
      "\n",
      "======================================================================\n",
      "=== Complete Analysis Finished ===\n",
      "All generated files are in: D:\\Projects\\Voice\\Parkinson-s-Disease-Detector-Using-AI\\Parkinson-s-Disease-Detector-Using-AI\\1\\UAMS\\results_ALL_VALIDS_ALL\\features_characteristics_complete\n",
      "======================================================================\n"
     ]
    }
   ],
   "execution_count": 1
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
