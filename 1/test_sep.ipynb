{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-09-10T14:12:51.412276Z",
     "start_time": "2025-09-10T14:10:31.884781Z"
    }
   },
   "source": [
    "import os\n",
    "import gc\n",
    "from typing import List, Dict, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "# =============================================================================\n",
    "# --- Configuration ---\n",
    "# =============================================================================\n",
    "\n",
    "# Class definitions\n",
    "HEALTHY_CLASS: str = \"healthy_control\"\n",
    "PARKINSON_CLASS: str = \"parkinson_patient\"\n",
    "CLASSES: List[str] = [HEALTHY_CLASS, PARKINSON_CLASS]\n",
    "\n",
    "ITALIAN_DATASET = \"ITALIAN_DATASET\"\n",
    "UAMS_DATASET = \"UAMS_DATASET\"\n",
    "NEUROVOZ_DATASET = \"NEUROVOZ_DATASET\"\n",
    "MPOWER_DATASET = \"MPOWER_DATASET\"\n",
    "SYNTHETIC_DATASET = \"SYNTHETIC_DATASET\"\n",
    "\n",
    "\n",
    "MODE_A = \"A\"\n",
    "MODE_ALL_VALIDS = \"ALL_VALIDS\"\n",
    "\n",
    "FEATURE_MODE_BASIC = \"BASIC\"\n",
    "FEATURE_MODE_ALL = \"ALL\"\n",
    "\n",
    "# --- SELECT YOUR CONFIGURATION HERE ---\n",
    "DATASET = UAMS_DATASET\n",
    "MODE = MODE_ALL_VALIDS\n",
    "FEATURE_MODE = FEATURE_MODE_ALL\n",
    "MODEL_NAME = \"cnn_att_lstm\"\n",
    "# ------------------------------------\n",
    "\n",
    "# Path Setup\n",
    "\n",
    "if DATASET == ITALIAN_DATASET:\n",
    "    dataset_folder_name = \"Italian\"\n",
    "elif DATASET == UAMS_DATASET:\n",
    "    dataset_folder_name = \"UAMS\"\n",
    "elif DATASET == NEUROVOZ_DATASET:\n",
    "    dataset_folder_name = \"Neurovoz\"\n",
    "\n",
    "FEATURES_FILE: str = os.path.join(os.getcwd(), dataset_folder_name, \"data\", f\"features_{MODE}_{FEATURE_MODE}.npz\")\n",
    "RESULTS_OUTPUT_PATH: str = os.path.join(os.getcwd(), dataset_folder_name, f\"results_{MODE}_{FEATURE_MODE}\", MODEL_NAME)\n",
    "os.makedirs(RESULTS_OUTPUT_PATH, exist_ok=True)\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# --- Data Loading and Preparation ---\n",
    "# =============================================================================\n",
    "\n",
    "def get_feature_keys(feature_mode: str) -> List[str]:\n",
    "    \"\"\"Returns the list of audio feature keys based on the selected mode.\"\"\"\n",
    "    if feature_mode == \"BASIC\":\n",
    "        return ['mel_spectrogram', 'mfcc']\n",
    "    elif feature_mode == \"ALL\":\n",
    "        return ['spectrogram', 'mel_spectrogram', 'mfcc', 'fsc']\n",
    "    raise ValueError(f\"Unknown FEATURE_MODE: {feature_mode}\")\n",
    "\n",
    "def load_features(features_file: str) -> Dict[str, np.ndarray]:\n",
    "    \"\"\"Loads all data arrays from the specified .npz file.\"\"\"\n",
    "    print(f\"Loading features from {features_file}\")\n",
    "    if not os.path.exists(features_file):\n",
    "        raise FileNotFoundError(f\"Features file not found: {features_file}\")\n",
    "\n",
    "    with np.load(features_file) as data:\n",
    "        features = {key: data[key] for key in data.keys()}\n",
    "\n",
    "    print(\"Loaded data shapes:\")\n",
    "    for key, value in features.items():\n",
    "        print(f\"  - {key}: {value.shape}\")\n",
    "    return features\n",
    "\n",
    "def prepare_and_clean_features(\n",
    "    features_dict: Dict[str, np.ndarray],\n",
    "    feature_mode: str\n",
    ") -> Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray, bool]:\n",
    "    \"\"\"\n",
    "    Prepares and cleans feature data for visualization using the full dataset.\n",
    "    \"\"\"\n",
    "    print(f\"\\n--- Preparing and Cleaning Features for Mode: {feature_mode} ---\")\n",
    "    feature_keys = get_feature_keys(feature_mode)\n",
    "    labels = features_dict['labels']\n",
    "\n",
    "    has_demographics = 'age' in features_dict and 'sex' in features_dict\n",
    "    if has_demographics:\n",
    "        ages = features_dict['age']\n",
    "        sexes = features_dict['sex']\n",
    "        print(\"Found 'age' and 'sex' data.\")\n",
    "    else:\n",
    "        ages = np.full_like(labels, np.nan)\n",
    "        sexes = np.full_like(labels, np.nan)\n",
    "\n",
    "    # --- MODIFIED: Subsampling has been removed to use all data ---\n",
    "    n_samples = len(labels)\n",
    "    print(f\"Using all {n_samples} samples for analysis. Note: This may be slow.\")\n",
    "    indices = np.arange(n_samples)\n",
    "\n",
    "    labels_sub, ages_sub, sexes_sub = labels[indices], ages[indices], sexes[indices]\n",
    "    X_sub = np.array([np.concatenate([features_dict[key][idx].flatten() for key in feature_keys]) for idx in indices])\n",
    "\n",
    "    # Clean data by removing rows with NaN in age or sex\n",
    "    if has_demographics:\n",
    "        nan_mask = pd.isna(ages_sub) | pd.isna(sexes_sub)\n",
    "        num_removed = np.sum(nan_mask)\n",
    "        if num_removed > 0:\n",
    "            print(f\"Removing {num_removed} samples with missing age/sex data for clean visualization.\")\n",
    "            clean_mask = ~nan_mask\n",
    "            X_sub, labels_sub, ages_sub, sexes_sub = X_sub[clean_mask], labels_sub[clean_mask], ages_sub[clean_mask], sexes_sub[clean_mask]\n",
    "\n",
    "    print(f\"Final feature matrix shape for visualization: {X_sub.shape}\")\n",
    "    return X_sub, labels_sub, ages_sub, sexes_sub, has_demographics\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# --- Visualization Functions ---\n",
    "# =============================================================================\n",
    "\n",
    "def plot_comprehensive_analysis(X: np.ndarray, y: np.ndarray, age: np.ndarray, output_path: str, min_age: float, max_age: float):\n",
    "    \"\"\"\n",
    "    Creates a comprehensive 3x2 plot including PCA variance curves,\n",
    "    class-based projections, and an age-colored t-SNE projection.\n",
    "    \"\"\"\n",
    "    print(\"\\n--- Creating Comprehensive Analysis Plot ---\")\n",
    "    if X.shape[0] < 2: return\n",
    "\n",
    "    X_scaled = StandardScaler().fit_transform(X)\n",
    "    class_names = [cls.replace('_', ' ').title() for cls in CLASSES]\n",
    "    colors = ['#2E86C1', '#E74C3C']\n",
    "\n",
    "    fig, axes = plt.subplots(3, 2, figsize=(16, 21))\n",
    "    fig.suptitle('Comprehensive Feature Analysis', fontsize=20)\n",
    "\n",
    "    # --- Row 1: PCA Variance Analysis ---\n",
    "    print(\"Computing PCA for variance curves...\")\n",
    "    n_curve_comps = min(50, X_scaled.shape[1], X_scaled.shape[0] - 1)\n",
    "    pca_variance = PCA(n_components=n_curve_comps, random_state=42)\n",
    "    pca_variance.fit(X_scaled)\n",
    "    axes[0, 0].plot(range(1, n_curve_comps + 1), pca_variance.explained_variance_ratio_, 'bo-', markersize=4)\n",
    "    axes[0, 0].set(title='PCA: Explained Variance per Component', xlabel='Principal Component', ylabel='Explained Variance Ratio'); axes[0, 0].grid(True, alpha=0.5, linestyle=':')\n",
    "    cumulative_variance = np.cumsum(pca_variance.explained_variance_ratio_)\n",
    "    axes[0, 1].plot(range(1, n_curve_comps + 1), cumulative_variance, 'ro-', markersize=4)\n",
    "    axes[0, 1].axhline(y=0.95, color='k', linestyle='--', alpha=0.8, label='95% Variance')\n",
    "    axes[0, 1].set(title='PCA: Cumulative Explained Variance', xlabel='Number of Components', ylabel='Cumulative Variance'); axes[0, 1].legend(); axes[0, 1].grid(True, alpha=0.5, linestyle=':')\n",
    "\n",
    "    # --- Row 2: Projections by Class ---\n",
    "    pca_95 = PCA(n_components=0.95, random_state=42); X_pca = pca_95.fit_transform(X_scaled)\n",
    "    for i, name in enumerate(class_names): axes[1, 0].scatter(X_pca[y == i, 0], X_pca[y == i, 1], c=colors[i], label=f'{name} (n={np.sum(y == i)})', alpha=0.7, s=25)\n",
    "    axes[1, 0].set(title=f'PCA Projection (First 2 of {pca_95.n_components_} Components)', xlabel=f'PC1 ({pca_95.explained_variance_ratio_[0]:.2%})', ylabel=f'PC2 ({pca_95.explained_variance_ratio_[1]:.2%})'); axes[1, 0].legend(); axes[1, 0].grid(True, alpha=0.5, linestyle=':')\n",
    "\n",
    "    print(\"Computing t-SNE...\")\n",
    "    perplexity = min(30, max(5, (X.shape[0] // 5) - 1)); tsne = TSNE(n_components=2, random_state=42, perplexity=perplexity, init='pca', learning_rate='auto'); X_tsne = tsne.fit_transform(X_scaled)\n",
    "    for i, name in enumerate(class_names): axes[1, 1].scatter(X_tsne[y == i, 0], X_tsne[y == i, 1], c=colors[i], label=f'{name} (n={np.sum(y == i)})', alpha=0.7, s=25)\n",
    "    axes[1, 1].set(title='t-SNE Projection by Class', xlabel='t-SNE Dimension 1', ylabel='t-SNE Dimension 2'); axes[1, 1].legend(); axes[1, 1].grid(True, alpha=0.5, linestyle=':')\n",
    "\n",
    "    # --- Row 3: LDA and t-SNE by Age ---\n",
    "    lda = LinearDiscriminantAnalysis(n_components=1); X_lda = lda.fit_transform(X_scaled, y)\n",
    "    for i, name in enumerate(class_names): sns.kdeplot(X_lda[y == i].ravel(), ax=axes[2, 0], color=colors[i], label=f'{name} (n={np.sum(y == i)})', fill=True, alpha=0.5)\n",
    "    axes[2, 0].set(title='LDA Projection', xlabel='LD1', ylabel='Density'); axes[2, 0].legend(); axes[2, 0].grid(True, alpha=0.5, linestyle=':')\n",
    "\n",
    "    scatter = axes[2, 1].scatter(X_tsne[:, 0], X_tsne[:, 1], c=age, cmap='plasma', s=25, alpha=0.8, vmin=min_age, vmax=max_age)\n",
    "    fig.colorbar(scatter, ax=axes[2, 1], label='Age'); axes[2, 1].set(title='t-SNE Projection by Age', xlabel='t-SNE Dimension 1', ylabel='t-SNE Dimension 2'); axes[2, 1].grid(True, alpha=0.5, linestyle=':')\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 0.97]); save_path = os.path.join(output_path, \"comprehensive_analysis.png\")\n",
    "    plt.savefig(save_path, dpi=300, bbox_inches='tight'); plt.close()\n",
    "    print(f\"Saved comprehensive analysis plots to '{os.path.basename(save_path)}'\")\n",
    "\n",
    "def plot_demographic_analysis(X: np.ndarray, y: np.ndarray, age: np.ndarray, sex: np.ndarray, output_path: str, min_age: float, max_age: float):\n",
    "    \"\"\"\n",
    "    Creates a 2x2 plot showing demographic distributions and their relation to features,\n",
    "    with age plots stacked and sex plots stacked.\n",
    "    \"\"\"\n",
    "    print(\"\\n--- Creating Demographic Analysis Plots (Stacked) ---\")\n",
    "    if X.shape[0] < 2: return\n",
    "\n",
    "    sex_labels = ['Female' if s == 0 else 'Male' for s in sex]\n",
    "    df = pd.DataFrame({'Age': age, 'Sex': sex_labels, 'Class': [CLASSES[int(label)].replace('_', ' ').title() for label in y]})\n",
    "\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 18)) # Increased height for better stacking\n",
    "    fig.suptitle('Demographic and Feature Analysis', fontsize=20, y=1.02)\n",
    "    class_colors = {'Healthy Control': '#2E86C1', 'Parkinson Patient': '#E74C3C'}\n",
    "    sex_colors = {'Female': '#DB7093', 'Male': '#4682B4'}\n",
    "\n",
    "    X_scaled = StandardScaler().fit_transform(X)\n",
    "    pca = PCA(n_components=2, random_state=42)\n",
    "    X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "    # --- Column 1: Age Plots ---\n",
    "    # 1. Age Distribution by Class (Top-Left)\n",
    "    sns.violinplot(ax=axes[0, 0], data=df, x='Class', y='Age', hue='Class', palette=class_colors, legend=False)\n",
    "    axes[0, 0].set_title('Age Distribution by Class'); axes[0, 0].grid(True, alpha=0.5, linestyle=':')\n",
    "\n",
    "    # 2. PCA of Audio Features, Colored by Age (Bottom-Left)\n",
    "    scatter_age = axes[1, 0].scatter(X_pca[:, 0], X_pca[:, 1], c=age, cmap='plasma', s=25, alpha=0.8, vmin=min_age, vmax=max_age)\n",
    "    fig.colorbar(scatter_age, ax=axes[1, 0], label='Age')\n",
    "    axes[1, 1].set_title('PCA of Audio Features, Colored by Age')\n",
    "    axes[1, 1].set_xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.2%})')\n",
    "    axes[1, 1].set_ylabel(f'PC2 ({pca.explained_variance_ratio_[1]:.2%})')\n",
    "    axes[1, 1].grid(True, alpha=0.5, linestyle=':')\n",
    "\n",
    "    # --- Column 2: Sex Plots ---\n",
    "    # 3. Sex Distribution by Class (Top-Right)\n",
    "    sns.countplot(ax=axes[0, 1], data=df, x='Sex', hue='Class', palette=class_colors, order=['Female', 'Male'])\n",
    "    axes[0, 1].set_title('Sex Distribution by Class'); axes[0, 1].set_ylabel('Count')\n",
    "\n",
    "    # 4. PCA of Audio Features, Colored by Sex (Bottom-Right)\n",
    "    sns.scatterplot(ax=axes[1, 1], x=X_pca[:, 0], y=X_pca[:, 1], hue=df['Sex'], palette=sex_colors, s=25, alpha=0.8)\n",
    "    axes[1, 0].set_title('PCA of Audio Features, Colored by Sex')\n",
    "    axes[1, 0].set_xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.2%})')\n",
    "    axes[1, 0].set_ylabel(f'PC2 ({pca.explained_variance_ratio_[1]:.2%})')\n",
    "    axes[1, 0].grid(True, alpha=0.5, linestyle=':')\n",
    "\n",
    "    # Adjust layout to prevent labels from overlapping\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.98])\n",
    "    save_path = os.path.join(output_path, \"demographic_analysis.png\")\n",
    "    plt.savefig(save_path, dpi=300, bbox_inches='tight'); plt.close()\n",
    "    print(f\"Saved demographic analysis to '{os.path.basename(save_path)}'\")\n",
    "\n",
    "def plot_individual_feature_separation(features_dict: Dict[str, np.ndarray], output_path: str, feature_mode: str):\n",
    "    \"\"\"\n",
    "    Creates separate PCA, t-SNE, and LDA plots for each audio feature type.\n",
    "    Forces PCA to 2 components if the 95% variance rule results in fewer than 2.\n",
    "    \"\"\"\n",
    "    print(\"\\n--- Creating Individual Audio Feature Analysis ---\")\n",
    "    feature_keys = get_feature_keys(feature_mode)\n",
    "    titles = {'spectrogram': 'Spectrogram', 'mel_spectrogram': 'Mel Spectrogram', 'mfcc': 'MFCC', 'fsc': 'Spectral Centroid'}\n",
    "    labels, n_samples = features_dict['labels'], len(features_dict['labels'])\n",
    "\n",
    "    indices = np.arange(n_samples)\n",
    "    labels_sub = labels[indices]\n",
    "    class_names, colors = [\"Healthy Control\", \"Parkinson Patient\"], ['#2E86C1', '#E74C3C']\n",
    "\n",
    "    fig, axes = plt.subplots(3, len(feature_keys), figsize=(7 * len(feature_keys), 15), squeeze=False, constrained_layout=True)\n",
    "    fig.suptitle('Individual Audio Feature Analysis', fontsize=16)\n",
    "\n",
    "    for col, feat_key in enumerate(feature_keys):\n",
    "        feat_title = titles.get(feat_key, feat_key)\n",
    "        print(f\"  Processing {feat_title}...\")\n",
    "        X = np.array([features_dict[feat_key][i].flatten() for i in indices])\n",
    "        X_scaled = StandardScaler().fit_transform(X)\n",
    "\n",
    "        # --- NEW LOGIC: Check components needed and decide PCA strategy ---\n",
    "        # 1. First, check how many components are needed for 95% variance.\n",
    "        pca_check = PCA(n_components=0.95, random_state=42)\n",
    "        pca_check.fit(X_scaled)\n",
    "\n",
    "        # 2. If it's less than 2, force n_components to be 2 for a consistent plot.\n",
    "        if pca_check.n_components_ < 2:\n",
    "            print(f\"  --> Forcing PCA to 2 components for '{feat_title}' (95% rule gave {pca_check.n_components_}).\")\n",
    "            pca = PCA(n_components=2, random_state=42)\n",
    "        else:\n",
    "            # Otherwise, use the standard 95% variance rule.\n",
    "            pca = PCA(n_components=0.95, random_state=42)\n",
    "\n",
    "        # 3. Fit and transform with the chosen PCA settings.\n",
    "        X_pca = pca.fit_transform(X_scaled)\n",
    "        # --- End of New Logic ---\n",
    "\n",
    "        # The scatter plot now safely assumes X_pca has at least 2 columns.\n",
    "        ax = axes[0, col]\n",
    "        for i, name in enumerate(class_names):\n",
    "            ax.scatter(X_pca[labels_sub == i, 0], X_pca[labels_sub == i, 1], c=colors[i], label=name, alpha=0.7, s=15)\n",
    "\n",
    "        # Create a dynamic title\n",
    "        total_var_explained = np.sum(pca.explained_variance_ratio_)\n",
    "        title = f'PCA: {feat_title}\\n({pca.n_components_} comps for {total_var_explained:.1%} var.)'\n",
    "        ax.set(title=title, xlabel=f'PC1 ({pca.explained_variance_ratio_[0]:.2%})', ylabel=f'PC2 ({pca.explained_variance_ratio_[1]:.2%})')\n",
    "        ax.legend(); ax.grid(True, alpha=0.5, linestyle=':')\n",
    "\n",
    "        # t-SNE (unchanged)\n",
    "        perplexity = min(30, max(5, (X_scaled.shape[0] // 5) - 1))\n",
    "        tsne = TSNE(n_components=2, random_state=42, perplexity=perplexity, init='pca', learning_rate='auto')\n",
    "        X_tsne = tsne.fit_transform(X_scaled)\n",
    "        ax = axes[1, col]\n",
    "        for i, name in enumerate(class_names):\n",
    "            ax.scatter(X_tsne[labels_sub == i, 0], X_tsne[labels_sub == i, 1], c=colors[i], label=name, alpha=0.7, s=15)\n",
    "        ax.set(title=f't-SNE: {feat_title}', xlabel='t-SNE Dim 1', ylabel='t-SNE Dim 2'); ax.legend(); ax.grid(True, alpha=0.5, linestyle=':')\n",
    "\n",
    "        # LDA (unchanged)\n",
    "        lda = LinearDiscriminantAnalysis(n_components=1)\n",
    "        X_lda = lda.fit_transform(X_scaled, labels_sub)\n",
    "        ax = axes[2, col]\n",
    "        for i, name in enumerate(class_names):\n",
    "            sns.kdeplot(X_lda[labels_sub == i].ravel(), ax=ax, color=colors[i], label=name, fill=True, alpha=0.6)\n",
    "        ax.set(title=f'LDA: {feat_title}', xlabel='LD1', ylabel='Density'); ax.legend(); ax.grid(True, alpha=0.5, linestyle=':')\n",
    "        del X, X_scaled; gc.collect()\n",
    "\n",
    "    save_path = os.path.join(output_path, \"individual_feature_analysis.png\")\n",
    "    plt.savefig(save_path, dpi=300, bbox_inches='tight'); plt.close()\n",
    "    print(f\"Saved individual feature analysis to '{os.path.basename(save_path)}'\")\n",
    "\n",
    "def plot_individual_features_by_age(\n",
    "    features_dict: Dict[str, np.ndarray],\n",
    "    output_path: str,\n",
    "    feature_mode: str,\n",
    "    min_age: float,\n",
    "    max_age: float\n",
    "):\n",
    "    \"\"\"\n",
    "    Creates separate PCA and t-SNE plots for each audio feature, colored by age.\n",
    "    \"\"\"\n",
    "    print(\"\\n--- Creating Individual Audio Feature Analysis (Colored by Age) ---\")\n",
    "    feature_keys = get_feature_keys(feature_mode)\n",
    "    titles = {'spectrogram': 'Spectrogram', 'mel_spectrogram': 'Mel Spectrogram', 'mfcc': 'MFCC', 'fsc': 'Spectral Centroid'}\n",
    "\n",
    "    # --- MODIFIED: Subsampling removed ---\n",
    "    n_samples = len(features_dict['labels'])\n",
    "    indices = np.arange(n_samples)\n",
    "\n",
    "    ages_sub = features_dict['age'][indices]\n",
    "    clean_mask = ~pd.isna(ages_sub)\n",
    "    indices_clean = indices[clean_mask]\n",
    "    ages_clean = ages_sub[clean_mask]\n",
    "\n",
    "    if len(indices_clean) < 2:\n",
    "        print(\"Not enough data with valid age information to create plots. Skipping.\")\n",
    "        return\n",
    "\n",
    "    fig, axes = plt.subplots(\n",
    "        2, len(feature_keys),\n",
    "        figsize=(7 * len(feature_keys), 10),\n",
    "        squeeze=False,\n",
    "        constrained_layout=True\n",
    "    )\n",
    "    fig.suptitle('Individual Audio Feature Analysis by Age', fontsize=16)\n",
    "\n",
    "    mappable = None\n",
    "\n",
    "    for col, feat_key in enumerate(feature_keys):\n",
    "        feat_title = titles.get(feat_key, feat_key)\n",
    "        print(f\"  Processing {feat_title}...\")\n",
    "\n",
    "        X = np.array([features_dict[feat_key][i].flatten() for i in indices_clean])\n",
    "        X_scaled = StandardScaler().fit_transform(X)\n",
    "\n",
    "        pca_check = PCA(n_components=0.95, random_state=42)\n",
    "        pca_check.fit(X_scaled)\n",
    "\n",
    "        # 2. If it's less than 2, force n_components to be 2 for a consistent plot.\n",
    "        if pca_check.n_components_ < 2:\n",
    "            print(f\"  --> Forcing PCA to 2 components for '{feat_title}' (95% rule gave {pca_check.n_components_}).\")\n",
    "            pca = PCA(n_components=2, random_state=42)\n",
    "        else:\n",
    "            # Otherwise, use the standard 95% variance rule.\n",
    "            pca = PCA(n_components=0.95, random_state=42)\n",
    "\n",
    "        # 3. Fit and transform with the chosen PCA settings.\n",
    "        X_pca = pca.fit_transform(X_scaled)\n",
    "        # --- End of New Logic ---\n",
    "        ax = axes[0, col]\n",
    "        scatter1 = ax.scatter(X_pca[:, 0], X_pca[:, 1], c=ages_clean, cmap='plasma', vmin=min_age, vmax=max_age, alpha=0.8, s=15)\n",
    "        ax.set(title=f'PCA: {feat_title}', xlabel=f'PC1 ({pca.explained_variance_ratio_[0]:.2%})', ylabel=f'PC2 ({pca.explained_variance_ratio_[1]:.2%})')\n",
    "        ax.grid(True, alpha=0.5, linestyle=':')\n",
    "        if mappable is None: mappable = scatter1\n",
    "\n",
    "        # t-SNE colored by Age\n",
    "        perplexity = min(30, max(5, (X_scaled.shape[0] // 5) - 1))\n",
    "        tsne = TSNE(n_components=2, random_state=42, perplexity=perplexity, init='pca', learning_rate='auto')\n",
    "        X_tsne = tsne.fit_transform(X_scaled)\n",
    "        ax = axes[1, col]\n",
    "        ax.scatter(X_tsne[:, 0], X_tsne[:, 1], c=ages_clean, cmap='plasma', vmin=min_age, vmax=max_age, alpha=0.8, s=15)\n",
    "        ax.set(title=f't-SNE: {feat_title}', xlabel='t-SNE Dim 1', ylabel='t-SNE Dim 2')\n",
    "        ax.grid(True, alpha=0.5, linestyle=':')\n",
    "        del X, X_scaled; gc.collect()\n",
    "\n",
    "    fig.colorbar(mappable, ax=axes.ravel().tolist(), label='Age', pad=0.01, aspect=30)\n",
    "\n",
    "    save_path = os.path.join(output_path, \"individual_feature_analysis_by_age.png\")\n",
    "    plt.savefig(save_path, dpi=300, bbox_inches='tight'); plt.close()\n",
    "    print(f\"Saved individual feature analysis by age to '{os.path.basename(save_path)}'\")\n",
    "\n",
    "# =============================================================================\n",
    "# --- Main Execution ---\n",
    "# =============================================================================\n",
    "def main():\n",
    "    \"\"\"Main function to run the complete analysis workflow.\"\"\"\n",
    "    print(\"=\" * 50); print(\"=== Feature & Demographic Analysis ===\"); print(\"=\" * 50)\n",
    "    try:\n",
    "        features = load_features(FEATURES_FILE)\n",
    "\n",
    "        global_min_age, global_max_age = None, None\n",
    "        if 'age' in features:\n",
    "            global_min_age, global_max_age = np.nanmin(features['age']), np.nanmax(features['age'])\n",
    "\n",
    "        X, y, age, sex, has_demographics = prepare_and_clean_features(features, FEATURE_MODE)\n",
    "\n",
    "        plot_individual_feature_separation(features, RESULTS_OUTPUT_PATH, FEATURE_MODE)\n",
    "\n",
    "        if has_demographics:\n",
    "            plot_comprehensive_analysis(X, y, age, RESULTS_OUTPUT_PATH, global_min_age, global_max_age)\n",
    "            plot_demographic_analysis(X, y, age, sex, RESULTS_OUTPUT_PATH, global_min_age, global_max_age)\n",
    "\n",
    "            plot_individual_features_by_age(features, RESULTS_OUTPUT_PATH, FEATURE_MODE, global_min_age, global_max_age)\n",
    "        else:\n",
    "            print(\"\\nDemographic data not found. Skipping demographic-related plots.\")\n",
    "\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"\\nERROR: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\nAn unexpected error occurred: {e}\"); import traceback; traceback.print_exc()\n",
    "    finally:\n",
    "        print(\"\\n\" + \"=\" * 50); print(\"=== Analysis Complete ===\"); print(f\"All generated files are in: {RESULTS_OUTPUT_PATH}\"); print(\"=\" * 50)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "=== Feature & Demographic Analysis ===\n",
      "==================================================\n",
      "Loading features from D:\\Projects\\Voice\\Parkinson-s-Disease-Detector-Using-AI\\Parkinson-s-Disease-Detector-Using-AI\\1\\UAMS\\data\\features_ALL_VALIDS_ALL.npz\n",
      "Loaded data shapes:\n",
      "  - spectrogram: (328, 1025, 94)\n",
      "  - mel_spectrogram: (328, 30, 94)\n",
      "  - fsc: (328, 1, 94)\n",
      "  - mfcc: (328, 30, 94)\n",
      "  - labels: (328,)\n",
      "  - sex: (328,)\n",
      "  - age: (328,)\n",
      "\n",
      "--- Preparing and Cleaning Features for Mode: ALL ---\n",
      "Found 'age' and 'sex' data.\n",
      "Using all 328 samples for analysis. Note: This may be slow.\n",
      "Final feature matrix shape for visualization: (328, 102084)\n",
      "\n",
      "--- Creating Individual Audio Feature Analysis ---\n",
      "  Processing Spectrogram...\n",
      "  Processing Mel Spectrogram...\n",
      "  Processing MFCC...\n",
      "  Processing Spectral Centroid...\n",
      "Saved individual feature analysis to 'individual_feature_analysis.png'\n",
      "\n",
      "--- Creating Comprehensive Analysis Plot ---\n",
      "Computing PCA for variance curves...\n",
      "Computing t-SNE...\n",
      "Saved comprehensive analysis plots to 'comprehensive_analysis.png'\n",
      "\n",
      "--- Creating Demographic Analysis Plots (Stacked) ---\n",
      "Saved demographic analysis to 'demographic_analysis.png'\n",
      "\n",
      "--- Creating Individual Audio Feature Analysis (Colored by Age) ---\n",
      "  Processing Spectrogram...\n",
      "  Processing Mel Spectrogram...\n",
      "  Processing MFCC...\n",
      "  Processing Spectral Centroid...\n",
      "Saved individual feature analysis by age to 'individual_feature_analysis_by_age.png'\n",
      "\n",
      "==================================================\n",
      "=== Analysis Complete ===\n",
      "All generated files are in: D:\\Projects\\Voice\\Parkinson-s-Disease-Detector-Using-AI\\Parkinson-s-Disease-Detector-Using-AI\\1\\UAMS\\results_ALL_VALIDS_ALL\\cnn_att_lstm\n",
      "==================================================\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-10T16:32:10.957038Z",
     "start_time": "2025-09-10T16:32:07.047646Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# =============================================================================\n",
    "# --- Configuration ---\n",
    "# Instructions: Set these variables to match the .npz file you want to inspect.\n",
    "# =============================================================================\n",
    "DATASET = NEUROVOZ_DATASET\n",
    "MODE = \"A\"\n",
    "FEATURE_MODE = \"ALL\"\n",
    "\n",
    "# =============================================================================\n",
    "# --- Inspection Script ---\n",
    "# =============================================================================\n",
    "def inspect_feature_file(dataset, mode, feature_mode):\n",
    "    \"\"\"\n",
    "    Loads and inspects the contents of a .npz feature file.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Build the file path based on your project structure\n",
    "        dataset_folder_name = \"Italian\" if dataset == \"ITALIAN_DATASET\" else \"Neurovoz\"\n",
    "        features_file = os.path.join(os.getcwd(), dataset_folder_name, \"data\", f\"features_{mode}_{feature_mode}.npz\")\n",
    "\n",
    "        print(f\"Inspecting file: {features_file}\\n\")\n",
    "\n",
    "        # Check if the file exists\n",
    "        if not os.path.exists(features_file):\n",
    "            raise FileNotFoundError(f\"The specified file was not found.\")\n",
    "\n",
    "        # Load the .npz file\n",
    "        with np.load(features_file) as data:\n",
    "            print(\"✅ File loaded successfully. Here are its contents:\\n\")\n",
    "\n",
    "            # Get the list of arrays stored in the file\n",
    "            array_keys = list(data.keys())\n",
    "            print(f\"Stored arrays: {array_keys}\\n\")\n",
    "\n",
    "            # Print details for each array\n",
    "            for key in array_keys:\n",
    "                array = data[key]\n",
    "                print(\"-\" * 40)\n",
    "                print(f\"Array Name: '{key}'\")\n",
    "                print(f\"  - Shape: {array.shape}\")\n",
    "                print(f\"  - Data Type: {array.dtype}\")\n",
    "\n",
    "                # Show the first 5 elements for 1D arrays, or a note for multi-dimensional ones\n",
    "                if array.ndim == 1:\n",
    "                    print(f\"  - First 5 values: {array[:5]}\")\n",
    "                else:\n",
    "                    print(f\"  - (Multi-dimensional array, showing shape only)\")\n",
    "\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"❌ ERROR: {e}\")\n",
    "        print(\"Please check that the configuration variables at the top of the script are correct.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred: {e}\")\n",
    "\n",
    "# Run the inspection\n",
    "if __name__ == \"__main__\":\n",
    "    inspect_feature_file(DATASET, MODE, FEATURE_MODE)"
   ],
   "id": "3b3a6e529030dbdc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inspecting file: D:\\Projects\\Voice\\Parkinson-s-Disease-Detector-Using-AI\\Parkinson-s-Disease-Detector-Using-AI\\1\\Neurovoz\\data\\features_A_ALL.npz\n",
      "\n",
      "✅ File loaded successfully. Here are its contents:\n",
      "\n",
      "Stored arrays: ['spectrogram', 'mel_spectrogram', 'fsc', 'mfcc', 'labels', 'sex', 'age']\n",
      "\n",
      "----------------------------------------\n",
      "Array Name: 'spectrogram'\n",
      "  - Shape: (1064, 1025, 94)\n",
      "  - Data Type: float32\n",
      "  - (Multi-dimensional array, showing shape only)\n",
      "----------------------------------------\n",
      "Array Name: 'mel_spectrogram'\n",
      "  - Shape: (1064, 30, 94)\n",
      "  - Data Type: float32\n",
      "  - (Multi-dimensional array, showing shape only)\n",
      "----------------------------------------\n",
      "Array Name: 'fsc'\n",
      "  - Shape: (1064, 1, 94)\n",
      "  - Data Type: float64\n",
      "  - (Multi-dimensional array, showing shape only)\n",
      "----------------------------------------\n",
      "Array Name: 'mfcc'\n",
      "  - Shape: (1064, 30, 94)\n",
      "  - Data Type: float32\n",
      "  - (Multi-dimensional array, showing shape only)\n",
      "----------------------------------------\n",
      "Array Name: 'labels'\n",
      "  - Shape: (1064,)\n",
      "  - Data Type: int32\n",
      "  - First 5 values: [0 0 0 0 0]\n",
      "----------------------------------------\n",
      "Array Name: 'sex'\n",
      "  - Shape: (1064,)\n",
      "  - Data Type: int32\n",
      "  - First 5 values: [1 1 1 1 0]\n",
      "----------------------------------------\n",
      "Array Name: 'age'\n",
      "  - Shape: (1064,)\n",
      "  - Data Type: float64\n",
      "  - First 5 values: [77. 77. 77. 77. 59.]\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-10T14:12:58.274366Z",
     "start_time": "2025-09-10T14:12:58.255298Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# =============================================================================\n",
    "# --- Configuration ---\n",
    "# Instructions: Set these variables to match the .npz file you want to inspect.\n",
    "# =============================================================================\n",
    "DATASET: str = NEUROVOZ_DATASET\n",
    "MODE: str = \"A\"\n",
    "FEATURE_MODE: str = \"ALL\"\n",
    "\n",
    "# =============================================================================\n",
    "# --- Analysis Script ---\n",
    "# =============================================================================\n",
    "\n",
    "def find_age_range(dataset: str, mode: str, feature_mode: str):\n",
    "    \"\"\"\n",
    "    Loads a feature file and calculates the minimum and maximum age.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Build the file path from configuration\n",
    "        dataset_folder_name: str = \"Italian\" if dataset == \"ITALIAN_DATASET\" else \"Neurovoz\"\n",
    "        features_file: str = os.path.join(os.getcwd(), dataset_folder_name, \"data\", f\"features_{mode}_{feature_mode}.npz\")\n",
    "\n",
    "        print(f\"Analyzing file: {features_file}\\n\")\n",
    "\n",
    "        if not os.path.exists(features_file):\n",
    "            raise FileNotFoundError(\"The specified feature file was not found.\")\n",
    "\n",
    "        # Load the data\n",
    "        with np.load(features_file) as data:\n",
    "            if 'age' not in data:\n",
    "                raise KeyError(\"The 'age' array was not found in the feature file.\")\n",
    "\n",
    "            age_array = data['age']\n",
    "\n",
    "            # Calculate min and max, safely ignoring any NaN values\n",
    "            min_age = np.nanmin(age_array)\n",
    "            max_age = np.nanmax(age_array)\n",
    "\n",
    "            print(\"📊 **Age Range Analysis Complete**\")\n",
    "            print(f\"   - Minimum Age: {min_age}\")\n",
    "            print(f\"   - Maximum Age: {max_age}\")\n",
    "\n",
    "    except (FileNotFoundError, KeyError) as e:\n",
    "        print(f\"❌ ERROR: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred: {e}\")\n",
    "\n",
    "# Run the analysis\n",
    "if __name__ == \"__main__\":\n",
    "    find_age_range(DATASET, MODE, FEATURE_MODE)"
   ],
   "id": "b5157cb0712fa711",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing file: D:\\Projects\\Voice\\Parkinson-s-Disease-Detector-Using-AI\\Parkinson-s-Disease-Detector-Using-AI\\1\\Neurovoz\\data\\features_A_ALL.npz\n",
      "\n",
      "📊 **Age Range Analysis Complete**\n",
      "   - Minimum Age: 31.0\n",
      "   - Maximum Age: 88.0\n"
     ]
    }
   ],
   "execution_count": 3
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
