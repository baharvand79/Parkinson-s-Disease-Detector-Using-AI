{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-12T18:08:32.301460Z",
     "start_time": "2025-09-12T18:08:26.667377Z"
    }
   },
   "source": [
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import (Input, Conv2D, MaxPooling2D, Dropout, Flatten,\n",
    "                                     Dense, LSTM, MultiHeadAttention, Concatenate, Reshape)\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score\n",
    "from sklearn.neighbors import NeighborhoodComponentsAnalysis\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from tqdm import tqdm\n",
    "from scipy.stats import ttest_ind\n",
    "import pandas as pd\n",
    "import shap\n",
    "from tensorflow.keras.saving import register_keras_serializable\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import matplotlib.patches as mpatches\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Reshape\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from skimage.transform import resize\n",
    "from matplotlib.colors import ListedColormap\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "# =============================================================================\n",
    "# --- Configuration ---\n",
    "# =============================================================================\n",
    "\n",
    "# --- 1. Core Paths ---\n",
    "ITALIAN_DATASET = \"ITALIAN_DATASET\"\n",
    "UAMS_DATASET = \"UAMS_DATASET\"\n",
    "NEUROVOZ_DATASET = \"NEUROVOZ_DATASET\"\n",
    "MPOWER_DATASET = \"MPOWER_DATASET\"\n",
    "SYNTHETIC_DATASET = \"SYNTHETIC_DATASET\"\n",
    "\n",
    "MODE_ALL_VALIDS = \"ALL_VALIDS\"\n",
    "MODE_A = \"A\"\n",
    "\n",
    "FEATURE_MODE_BASIC = \"BASIC\"        # mel_spectrogram, mfcc, spectrogram\n",
    "FEATURE_MODE_ALL = \"ALL\"            # basic + fsc\n",
    "FEATURE_MODE_DEFAULT = \"DEFAULT\"\n",
    "\n",
    "MODEL_NAME = \"nca_cnn_lstm\"\n",
    "\n",
    "# /////////// SELCET HERE \\\\\\\\\\\\\\\\\\\\\\\n",
    "# ----------------------------------\n",
    "DATASET = UAMS_DATASET\n",
    "MODE = MODE_A\n",
    "FEATURE_MODE = FEATURE_MODE_DEFAULT\n",
    "# ----------------------------------\n",
    "\n",
    "dataset = \"\"\n",
    "if DATASET == NEUROVOZ_DATASET:\n",
    "    dataset = \"Neurovoz\"\n",
    "elif DATASET == UAMS_DATASET:\n",
    "    dataset = \"UAMS\"\n",
    "elif DATASET == MPOWER_DATASET:\n",
    "    dataset = \"mPower\"\n",
    "elif DATASET == SYNTHETIC_DATASET:\n",
    "    dataset = \"Synthetic\"\n",
    "elif DATASET == ITALIAN_DATASET:\n",
    "    dataset = \"Italian\"\n",
    "\n",
    "# Path Setup\n",
    "FEATURES_FILE_PATH = os.path.join(os.getcwd(), dataset, \"data\", f\"features_{MODE}_{FEATURE_MODE}.npz\")\n",
    "\n",
    "MODEL_PATH = os.path.join(os.getcwd(), dataset, f\"results_{MODE}_{FEATURE_MODE}\", MODEL_NAME)\n",
    "os.makedirs(MODEL_PATH, exist_ok=True)\n",
    "EVALUATION_FILE_PATH = os.path.join(MODEL_PATH, \"evaluation.csv\")\n",
    "HISTORY_SAVE_PATH = os.path.join(MODEL_PATH, \"history.csv\")\n",
    "EVALUATION_FILE_PATH = os.path.join(MODEL_PATH, \"evaluation.csv\")\n",
    "BEST_MODEL_PATH = os.path.join(MODEL_PATH, \"best_model.keras\")\n",
    "\n",
    "SHAP_OUTPUT_PATH = os.path.join(MODEL_PATH, \"shap_analysis\")\n",
    "GRADCAM_OUTPUT_PATH = os.path.join(MODEL_PATH, \"gradcam_analysis\")\n",
    "os.makedirs(SHAP_OUTPUT_PATH, exist_ok=True)\n",
    "os.makedirs(GRADCAM_OUTPUT_PATH, exist_ok=True)\n",
    "\n",
    "# Hyperparameters\n",
    "EPOCHS = 30\n",
    "BATCH_SIZE = 32\n",
    "LEARNING_RATE = 0.001\n",
    "DROPOUT_RATE = 0.5\n",
    "L2_STRENGTH = 0.01\n",
    "NCA_COMPONENTS = 128  # Number of components for NCA\n",
    "USE_SMOTE = True      # Whether to apply SMOTE for balancing\n",
    "\n",
    "# Model Checkpoint Callback\n",
    "checkpoint_cb = ModelCheckpoint(BEST_MODEL_PATH, monitor='val_auc', mode='max', save_best_only=True, verbose=1)\n",
    "\n",
    "def load_data(feature_file_path):\n",
    "    mel_spectrograms = None\n",
    "    mfccs = None\n",
    "    spectrograms = None\n",
    "    fcs = None\n",
    "\n",
    "    print(f\"--- Loading data from {feature_file_path} ---\")\n",
    "    with np.load(feature_file_path) as data:\n",
    "        labels = data['labels']\n",
    "\n",
    "        if 'mel_spectrogram' in data.keys():\n",
    "            mel_spectrograms = data['mel_spectrogram']\n",
    "        if 'mfcc' in data:\n",
    "            mfccs = data['mfcc']\n",
    "        if 'spectrogram' in data.keys():\n",
    "            spectrograms = data['spectrogram']\n",
    "\n",
    "        feature_arrays = []\n",
    "\n",
    "        if mel_spectrograms is not None:\n",
    "            feature_arrays.append(mel_spectrograms)\n",
    "            print(f\"Added mel_spectrogram: {mel_spectrograms.shape}\")\n",
    "\n",
    "        if mfccs is not None:\n",
    "            feature_arrays.append(mfccs)\n",
    "            print(f\"Added mfcc: {mfccs.shape}\")\n",
    "\n",
    "        if spectrograms is not None:\n",
    "            feature_arrays.append(spectrograms)\n",
    "            print(f\"Added spectrogram: {spectrograms.shape}\")\n",
    "\n",
    "        if feature_arrays:\n",
    "            X = np.concatenate(feature_arrays, axis=-1)  # concat along last axis\n",
    "            print(f\"Final concatenated shape: {X.shape}\")\n",
    "        else:\n",
    "            raise ValueError(\"No valid features found in the file!\")\n",
    "        return X, labels\n",
    "\n",
    "def apply_nca_smote_preprocessing(X_train, y_train, X_test, n_components=None, use_smote=True, min_dim=16):\n",
    "    \"\"\"\n",
    "    Apply NCA for dimensionality reduction followed by SMOTE for balancing.\n",
    "    Ensures minimum dimensions for CNN compatibility.\n",
    "\n",
    "    Args:\n",
    "        X_train: Training features (samples, height, width)\n",
    "        y_train: Training labels\n",
    "        X_test: Test features (samples, height, width) - ONLY TRANSFORMED, NEVER FITTED\n",
    "        n_components: Number of NCA components\n",
    "        use_smote: Whether to apply SMOTE after NCA\n",
    "        min_dim: Minimum dimension for each axis (height, width)\n",
    "\n",
    "    Returns:\n",
    "        X_train_processed: Processed training features (samples, height, width, 1)\n",
    "        y_train_processed: Processed training labels (may be augmented if SMOTE used)\n",
    "        X_test_processed: Processed test features (samples, height, width, 1)\n",
    "        nca: Fitted NCA object\n",
    "        scaler: Fitted StandardScaler object\n",
    "    \"\"\"\n",
    "    print(\"\\n--- Applying NCA + SMOTE Preprocessing ---\")\n",
    "\n",
    "    # Get original shapes\n",
    "    original_train_shape = X_train.shape\n",
    "    original_test_shape = X_test.shape\n",
    "    print(f\"Original train shape: {original_train_shape}\")\n",
    "    print(f\"Original test shape: {original_test_shape}\")\n",
    "\n",
    "    # Flatten the features for NCA (samples, height*width*channels -> samples, features)\n",
    "    X_train_flat = X_train.reshape(X_train.shape[0], -1)\n",
    "    X_test_flat = X_test.reshape(X_test.shape[0], -1)\n",
    "\n",
    "    print(f\"Flattened train shape: {X_train_flat.shape}\")\n",
    "    print(f\"Flattened test shape: {X_test_flat.shape}\")\n",
    "\n",
    "    # Step 1: Standardize features (fit ONLY on training data)\n",
    "    print(\"Standardizing features...\")\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train_flat)  # FIT on training\n",
    "    X_test_scaled = scaler.transform(X_test_flat)        # ONLY TRANSFORM test\n",
    "\n",
    "    # Step 2: Apply NCA (fit ONLY on training data)\n",
    "    if n_components is None:\n",
    "        n_components = min(len(X_train) - 1, X_train_flat.shape[1])\n",
    "    else:\n",
    "        n_components = min(n_components, len(X_train) - 1, X_train_flat.shape[1])\n",
    "\n",
    "    print(f\"Applying NCA with {n_components} components...\")\n",
    "    nca = NeighborhoodComponentsAnalysis(n_components=n_components, random_state=42, max_iter=200)\n",
    "\n",
    "    X_train_nca = nca.fit_transform(X_train_scaled, y_train)  # FIT on training\n",
    "    X_test_nca = nca.transform(X_test_scaled)                 # ONLY TRANSFORM test\n",
    "\n",
    "    print(f\"NCA transformed train shape: {X_train_nca.shape}\")\n",
    "    print(f\"NCA transformed test shape: {X_test_nca.shape}\")\n",
    "\n",
    "    # Step 3: Apply SMOTE for balancing (ONLY on training data)\n",
    "    if use_smote:\n",
    "        print(\"Applying SMOTE for class balancing...\")\n",
    "        print(f\"Before SMOTE - Class distribution: {np.bincount(y_train)}\")\n",
    "\n",
    "        smote = SMOTE(random_state=42)\n",
    "        X_train_balanced, y_train_balanced = smote.fit_resample(X_train_nca, y_train)\n",
    "\n",
    "        print(f\"After SMOTE - Class distribution: {np.bincount(y_train_balanced)}\")\n",
    "        print(f\"SMOTE balanced train shape: {X_train_balanced.shape}\")\n",
    "    else:\n",
    "        X_train_balanced = X_train_nca\n",
    "        y_train_balanced = y_train\n",
    "\n",
    "    # Step 4: Calculate optimal reshape dimensions for CNN input\n",
    "    n_features = X_train_balanced.shape[1]\n",
    "\n",
    "    # Find factors to create CNN-compatible dimensions\n",
    "    height = max(min_dim, int(np.sqrt(n_features)))\n",
    "    width = max(min_dim, int(np.ceil(n_features / height)))\n",
    "\n",
    "    # Ensure minimum dimensions for CNN compatibility\n",
    "    if height < min_dim:\n",
    "        height = min_dim\n",
    "    if width < min_dim:\n",
    "        width = min_dim\n",
    "\n",
    "    # Ensure it's CNN-friendly (pad if necessary)\n",
    "    target_size = height * width\n",
    "    pad_size = max(0, target_size - n_features)\n",
    "\n",
    "    if pad_size > 0:\n",
    "        print(f\"Padding with {pad_size} zeros for CNN compatibility...\")\n",
    "        X_train_balanced = np.pad(X_train_balanced, ((0, 0), (0, pad_size)), mode='constant', constant_values=0)\n",
    "        X_test_nca = np.pad(X_test_nca, ((0, 0), (0, pad_size)), mode='constant', constant_values=0)\n",
    "    elif pad_size < 0:\n",
    "        # Truncate if we have too many features\n",
    "        print(f\"Truncating {-pad_size} features for CNN compatibility...\")\n",
    "        X_train_balanced = X_train_balanced[:, :target_size]\n",
    "        X_test_nca = X_test_nca[:, :target_size]\n",
    "\n",
    "    # Reshape to 3D for CNN (samples, height, width, channels=1)\n",
    "    X_train_final = X_train_balanced.reshape(X_train_balanced.shape[0], height, width, 1)\n",
    "    X_test_final = X_test_nca.reshape(X_test_nca.shape[0], height, width, 1)\n",
    "\n",
    "    print(f\"Final CNN-ready train shape: {X_train_final.shape}\")\n",
    "    print(f\"Final CNN-ready test shape: {X_test_final.shape}\")\n",
    "    print(\"--- NCA + SMOTE Preprocessing Complete ---\\n\")\n",
    "\n",
    "    return X_train_final, y_train_balanced, X_test_final, nca, scaler\n",
    "\n",
    "# =============================================================================\n",
    "# --- Model Architecture ---\n",
    "# =============================================================================\n",
    "\n",
    "@register_keras_serializable()\n",
    "class ParkinsonDetectorModel(Model):\n",
    "    def __init__(self, input_shape, **kwargs):\n",
    "        super(ParkinsonDetectorModel, self).__init__(**kwargs)\n",
    "        self.input_shape_config = input_shape\n",
    "\n",
    "        # Calculate adaptive pooling sizes based on input dimensions\n",
    "        height, width = input_shape[0], input_shape[1]\n",
    "\n",
    "        # Use smaller pool sizes for small inputs\n",
    "        if height <= 16 or width <= 16:\n",
    "            pool_size1 = 2\n",
    "            pool_size2 = 2\n",
    "        elif height <= 32 or width <= 32:\n",
    "            pool_size1 = 3\n",
    "            pool_size2 = 2\n",
    "        else:\n",
    "            pool_size1 = 5\n",
    "            pool_size2 = 3\n",
    "\n",
    "        print(f\"Using pool sizes: {pool_size1}, {pool_size2} for input shape {input_shape}\")\n",
    "\n",
    "        # CNN layers with adaptive pooling\n",
    "        self.conv1a = Conv2D(32, 3, activation='relu', kernel_regularizer=l2(L2_STRENGTH), padding='same')\n",
    "        self.conv1b = Conv2D(32, 3, activation='relu', kernel_regularizer=l2(L2_STRENGTH), padding='same')\n",
    "        self.pool1 = MaxPooling2D(pool_size1, padding='same')\n",
    "        self.drop1 = Dropout(DROPOUT_RATE)\n",
    "\n",
    "        self.conv2a = Conv2D(64, 3, activation='relu', kernel_regularizer=l2(L2_STRENGTH), padding='same')\n",
    "        self.conv2b = Conv2D(64, 3, activation='relu', kernel_regularizer=l2(L2_STRENGTH), padding='same', name='last_conv_layer')\n",
    "        self.pool2 = MaxPooling2D(pool_size2, padding='same', name='cnn_output')\n",
    "        self.drop2 = Dropout(DROPOUT_RATE)\n",
    "\n",
    "        # Other layers\n",
    "        self.flatten_cnn = Flatten()\n",
    "        self.attention = MultiHeadAttention(num_heads=2, key_dim=32, name='attention_output')\n",
    "        self.flatten_att = Flatten()\n",
    "        self.lstm1 = LSTM(64, return_sequences=True)\n",
    "        self.lstm2 = LSTM(64, return_sequences=False, name='lstm_output')\n",
    "        self.drop_lstm = Dropout(DROPOUT_RATE)\n",
    "        self.concat = Concatenate()\n",
    "        self.dense_bottleneck = Dense(64, activation='relu', name='bottleneck_features')\n",
    "        self.dense_output = Dense(1, activation='sigmoid')\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        \"\"\"Build the model layers\"\"\"\n",
    "        super(ParkinsonDetectorModel, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        # inputs is already (batch, height, width, channels)\n",
    "        x = self.conv1a(inputs)\n",
    "        x = self.conv1b(x)\n",
    "        x = self.pool1(x)\n",
    "        x = self.drop1(x, training=training)\n",
    "\n",
    "        x = self.conv2a(x)\n",
    "        x = self.conv2b(x)\n",
    "        cnn_branch_output = self.pool2(x)\n",
    "        x = self.drop2(cnn_branch_output, training=training)\n",
    "\n",
    "        cnn_flat = self.flatten_cnn(x)\n",
    "\n",
    "        # Prepare sequence for attention and LSTM\n",
    "        shape = tf.shape(cnn_branch_output)\n",
    "        sequence = tf.reshape(cnn_branch_output, [-1, shape[1] * shape[2], shape[3]])\n",
    "\n",
    "        # Attention branch\n",
    "        att_branch_output = self.attention(query=sequence, key=sequence, value=sequence)\n",
    "        att_flat = self.flatten_att(att_branch_output)\n",
    "\n",
    "        # LSTM branch\n",
    "        lstm_seq = self.lstm1(sequence)\n",
    "        lstm_branch_output = self.lstm2(lstm_seq)\n",
    "        lstm_out = self.drop_lstm(lstm_branch_output, training=training)\n",
    "\n",
    "        # Combine all branches\n",
    "        concatenated = self.concat([cnn_flat, att_flat, lstm_out])\n",
    "        bottleneck = self.dense_bottleneck(concatenated)\n",
    "        final_output = self.dense_output(bottleneck)\n",
    "\n",
    "        return final_output\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super(ParkinsonDetectorModel, self).get_config()\n",
    "        config.update({\"input_shape\": self.input_shape_config})\n",
    "        return config\n",
    "\n",
    "    @classmethod\n",
    "    def from_config(cls, config):\n",
    "        return cls(**config)\n",
    "\n",
    "def build_model(input_shape: tuple) -> Model:\n",
    "    \"\"\"Builds the hybrid model by wrapping the custom class in a Functional API model.\"\"\"\n",
    "    print(\"--- Building the model ---\")\n",
    "    print(f\"Input shape: {input_shape}\")\n",
    "\n",
    "    inputs = Input(shape=input_shape)\n",
    "    parkinson_detector = ParkinsonDetectorModel(input_shape=input_shape)\n",
    "    outputs = parkinson_detector(inputs)\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "    print(\"Model built successfully.\")\n",
    "    return model\n",
    "\n",
    "# =============================================================================\n",
    "# --- Model Performance ---\n",
    "# =============================================================================\n",
    "def save_metrics_to_csv(y_true, y_pred_proba, filename=\"classification_report.csv\", threshold=0.5):\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred_binary = (np.array(y_pred_proba) > threshold).astype(int)\n",
    "\n",
    "    cm = confusion_matrix(y_true, y_pred_binary)\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "    total_samples = cm.sum()\n",
    "    if total_samples == 0:\n",
    "        tn_percent, fp_percent, fn_percent, tp_percent = 0, 0, 0, 0\n",
    "    else:\n",
    "        tn_percent = (tn / total_samples) * 100\n",
    "        fp_percent = (fp / total_samples) * 100\n",
    "        fn_percent = (fn / total_samples) * 100\n",
    "        tp_percent = (tp / total_samples) * 100\n",
    "\n",
    "    precision = precision_score(y_true, y_pred_binary, zero_division=0)\n",
    "    recall = recall_score(y_true, y_pred_binary, zero_division=0)\n",
    "    f1 = f1_score(y_true, y_pred_binary, zero_division=0)\n",
    "    sensitivity = recall\n",
    "\n",
    "    report_data = {\n",
    "        'Metric': [\n",
    "            'True Positive (TP)',\n",
    "            'True Negative (TN)',\n",
    "            'False Positive (FP)',\n",
    "            'False Negative (FN)',\n",
    "            'Precision',\n",
    "            'Recall (Sensitivity)',\n",
    "            'F1-Score'\n",
    "        ],\n",
    "        'Value': [\n",
    "            f\"{tp} ({tp_percent:.2f}%)\",\n",
    "            f\"{tn} ({tn_percent:.2f}%)\",\n",
    "            f\"{fp} ({fp_percent:.2f}%)\",\n",
    "            f\"{fn} ({fn_percent:.2f}%)\",\n",
    "            f\"{precision:.4f}\",\n",
    "            f\"{recall:.4f}\",\n",
    "            f\"{f1:.4f}\"\n",
    "        ]\n",
    "    }\n",
    "    df = pd.DataFrame(report_data)\n",
    "\n",
    "    try:\n",
    "        df.to_csv(filename, index=False, encoding='utf-8-sig')\n",
    "        print(f\"The evaluation results is stored: {filename}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error while saving the evaluation report: {e}\")\n",
    "\n",
    "# =============================================================================\n",
    "# --- Model Explainability (SHAP & Grad-CAM) ---\n",
    "# =============================================================================\n",
    "\n",
    "def generate_nca_feature_map_info(nca_shape):\n",
    "    \"\"\"\n",
    "    Generate feature layout information for NCA-transformed data.\n",
    "    \"\"\"\n",
    "    height, width = nca_shape[1], nca_shape[2]\n",
    "\n",
    "    feature_layout = {\n",
    "        'nca_transformed_features': height\n",
    "    }\n",
    "\n",
    "    colors = plt.get_cmap('viridis', 1)\n",
    "    feature_names = list(feature_layout.keys())\n",
    "    total_rows = sum(feature_layout.values())\n",
    "\n",
    "    color_mask = np.zeros((total_rows, width), dtype=int)\n",
    "\n",
    "    legend_patches = [mpatches.Patch(color=colors(0), label=f\"NCA Features ({height} rows)\")]\n",
    "\n",
    "    return {\n",
    "        'color_mask': color_mask,\n",
    "        'feature_layout': feature_layout,\n",
    "        'feature_names': feature_names,\n",
    "        'colors': colors,\n",
    "        'legend_patches': legend_patches,\n",
    "        'total_rows': total_rows\n",
    "    }\n",
    "def run_full_shap_analysis(model, X_train, X_test, y_test, output_path, nca_data_shape, samples_per_class=50, top_n=20):\n",
    "    \"\"\"\n",
    "    Run SHAP analysis with balanced sample selection for NCA-transformed data.\n",
    "    \"\"\"\n",
    "    print(\"\\n--- Running Full SHAP Analysis on NCA Data ---\")\n",
    "    os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "    feature_map_info = generate_nca_feature_map_info(nca_data_shape)\n",
    "    legend_patches = feature_map_info['legend_patches']\n",
    "    total_rows = feature_map_info['total_rows']\n",
    "\n",
    "    # Balanced sample selection\n",
    "    healthy_indices = np.where(y_test == 0)[0]\n",
    "    parkinson_indices = np.where(y_test == 1)[0]\n",
    "    num_healthy_to_select = min(samples_per_class, len(healthy_indices))\n",
    "    num_parkinson_to_select = min(samples_per_class, len(parkinson_indices))\n",
    "\n",
    "    selected_healthy_indices = np.random.choice(healthy_indices, num_healthy_to_select, replace=False)\n",
    "    selected_parkinson_indices = np.random.choice(parkinson_indices, num_parkinson_to_select, replace=False)\n",
    "    final_indices = np.concatenate([selected_healthy_indices, selected_parkinson_indices])\n",
    "    np.random.shuffle(final_indices)\n",
    "\n",
    "    test_samples = X_test[final_indices]\n",
    "    y_true_samples = y_test[final_indices]\n",
    "\n",
    "    print(f\"Calculating SHAP values for {len(test_samples)} balanced samples...\")\n",
    "    explainer = shap.GradientExplainer(model, X_train[:50].astype(np.float32))\n",
    "    shap_values_list = []\n",
    "\n",
    "    for sample in tqdm(test_samples, desc=\"SHAP Progress\"):\n",
    "        sample_batch = np.expand_dims(sample, axis=0).astype(np.float32)\n",
    "        sv = explainer.shap_values(sample_batch)\n",
    "        if isinstance(sv, list):\n",
    "            sv = sv[0]\n",
    "\n",
    "        # Handle the shape properly - squeeze all singleton dimensions except batch\n",
    "        # Expected shape after processing: (1, height, width)\n",
    "        sv_squeezed = np.squeeze(sv)  # Remove all singleton dimensions\n",
    "\n",
    "        # Ensure we have the right shape (height, width)\n",
    "        if sv_squeezed.ndim == 3:  # (height, width, 1)\n",
    "            sv_squeezed = np.squeeze(sv_squeezed, axis=-1)  # Remove channel dimension\n",
    "        elif sv_squeezed.ndim == 1:  # Flattened\n",
    "            height, width = nca_data_shape[1], nca_data_shape[2]\n",
    "            sv_squeezed = sv_squeezed.reshape(height, width)\n",
    "\n",
    "        shap_values_list.append(sv_squeezed)\n",
    "\n",
    "    shap_values = np.array(shap_values_list)\n",
    "    print(f\"\\nSHAP values shape: {shap_values.shape}\")\n",
    "\n",
    "    # Ensure we have the right dimensions\n",
    "    if shap_values.ndim == 3:  # (samples, height, width)\n",
    "        height, width = shap_values.shape[1], shap_values.shape[2]\n",
    "    else:\n",
    "        print(f\"Unexpected SHAP values shape: {shap_values.shape}\")\n",
    "        return\n",
    "\n",
    "    actual_data_time_steps = width\n",
    "\n",
    "    # Global Top-N analysis\n",
    "    flat_shap = shap_values.reshape(shap_values.shape[0], -1)\n",
    "    mean_abs = np.mean(np.abs(flat_shap), axis=0)\n",
    "    top_idx = np.argsort(mean_abs)[::-1][:top_n]\n",
    "\n",
    "    # Fix the coordinate calculation\n",
    "    coords = [np.unravel_index(i, (height, width)) for i in top_idx]\n",
    "    labels = [f\"R{r}C{c}\" for r, c in coords]\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.bar(range(len(top_idx)), mean_abs[top_idx])\n",
    "    plt.xticks(range(len(top_idx)), labels, rotation=45, ha=\"right\")\n",
    "    plt.title(f\"Top-{top_n} Global SHAP Features (NCA transformed)\")\n",
    "    plt.xlabel(\"Row × Column\")\n",
    "    plt.ylabel(\"Mean |SHAP value|\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(output_path, \"shap_global_bar_nca.png\"), dpi=300, bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "    print(\"-> Saved 'shap_global_bar_nca.png'\")\n",
    "\n",
    "    def plot_aligned_heatmap(heatmap_data, title, filename_suffix, cmap, label, vmin=None, vmax=None):\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(14, 7))\n",
    "        ax_shap, ax_feature_map = axes[0], axes[1]\n",
    "\n",
    "        # SHAP Heatmap\n",
    "        img = ax_shap.imshow(heatmap_data, cmap=cmap, aspect='auto', interpolation='nearest', vmin=vmin, vmax=vmax)\n",
    "        ax_shap.set_title(title, fontsize=12)\n",
    "        ax_shap.set_xlabel(f\"NCA Columns ({actual_data_time_steps})\", fontsize=10)\n",
    "        ax_shap.set_ylabel(f\"NCA Rows ({total_rows})\", fontsize=10)\n",
    "\n",
    "        divider = make_axes_locatable(ax_shap)\n",
    "        cax = divider.append_axes(\"right\", size=\"5%\", pad=0.1)\n",
    "        fig.colorbar(img, cax=cax, label=label)\n",
    "\n",
    "        # Feature Map\n",
    "        ax_feature_map.imshow(feature_map_info['color_mask'], cmap=feature_map_info['colors'],\n",
    "                             aspect='auto', interpolation='nearest')\n",
    "        ax_feature_map.set_title(\"NCA Feature Map\", fontsize=12)\n",
    "        ax_feature_map.set_xlabel(f\"NCA Columns ({actual_data_time_steps})\", fontsize=10)\n",
    "        ax_feature_map.tick_params(axis='y', labelleft=False)\n",
    "\n",
    "        ax_feature_map.legend(handles=legend_patches, loc='upper left', bbox_to_anchor=(1.02, 1),\n",
    "                             borderaxespad=0., fontsize=8)\n",
    "\n",
    "        fig.suptitle(f\"NCA-SHAP Analysis: {title}\", fontsize=16, fontweight='bold')\n",
    "        plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "\n",
    "        plt.savefig(os.path.join(output_path, f\"shap_aligned_nca_{filename_suffix}.png\"), dpi=300)\n",
    "        plt.close(fig)\n",
    "        print(f\"-> Saved 'shap_aligned_nca_{filename_suffix}.png'\")\n",
    "\n",
    "    # Generate class-specific and difference maps\n",
    "    hc_mask, pd_mask = (y_true_samples == 0), (y_true_samples == 1)\n",
    "\n",
    "    if np.any(hc_mask):\n",
    "        hc_mean = shap_values[hc_mask].mean(axis=0)\n",
    "        plot_aligned_heatmap(hc_mean, \"Average SHAP - Healthy (NCA)\", \"summary_healthy\", \"bwr\", \"Mean SHAP Value\")\n",
    "    if np.any(pd_mask):\n",
    "        pd_mean = shap_values[pd_mask].mean(axis=0)\n",
    "        plot_aligned_heatmap(pd_mean, \"Average SHAP - Parkinson (NCA)\", \"summary_parkinson\", \"bwr\", \"Mean SHAP Value\")\n",
    "    if np.any(hc_mask) and np.any(pd_mask):\n",
    "        diff_map = pd_mean - hc_mean\n",
    "        max_abs_diff = np.max(np.abs(diff_map))\n",
    "        plot_aligned_heatmap(diff_map, \"SHAP Difference (PD - HC, NCA)\", \"difference\", \"seismic\", \"Δ SHAP (PD - HC)\", vmin=-max_abs_diff, vmax=max_abs_diff)\n",
    "\n",
    "    print(\"\\n--- NCA-SHAP Analysis Complete ---\")\n",
    "\n",
    "def run_gradcam_analysis(model, X_test, y_test, output_path, nca_data_shape, num_samples=50):\n",
    "    \"\"\"\n",
    "    Run Grad-CAM analysis for NCA-transformed data.\n",
    "    \"\"\"\n",
    "    print(\"\\n--- Running Grad-CAM Analysis with NCA Data ---\")\n",
    "    os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "    parkinson_detector = None\n",
    "    for layer in model.layers:\n",
    "        if 'ParkinsonDetectorModel' in str(type(layer)):\n",
    "            parkinson_detector = layer\n",
    "            break\n",
    "\n",
    "    if parkinson_detector is None:\n",
    "        print(\"ParkinsonDetectorModel not found in the model layers.\")\n",
    "        return\n",
    "\n",
    "    last_conv_layer = parkinson_detector.conv2b\n",
    "    print(f\"Using last conv layer: {last_conv_layer.name}\")\n",
    "\n",
    "    def get_conv_and_output(inputs):\n",
    "        x = parkinson_detector.conv1a(inputs)\n",
    "        x = parkinson_detector.conv1b(x)\n",
    "        x = parkinson_detector.pool1(x)\n",
    "        x = parkinson_detector.drop1(x, training=False)\n",
    "        x = parkinson_detector.conv2a(x)\n",
    "        conv_output = parkinson_detector.conv2b(x)\n",
    "        x = parkinson_detector.pool2(conv_output)\n",
    "        x = parkinson_detector.drop2(x, training=False)\n",
    "        cnn_flat = parkinson_detector.flatten_cnn(x)\n",
    "        shape = tf.shape(x)\n",
    "        sequence = tf.reshape(x, [-1, shape[1] * shape[2], shape[3]])\n",
    "        att_out = parkinson_detector.attention(query=sequence, key=sequence, value=sequence)\n",
    "        att_flat = parkinson_detector.flatten_att(att_out)\n",
    "        lstm_seq = parkinson_detector.lstm1(sequence)\n",
    "        lstm_out = parkinson_detector.lstm2(lstm_seq)\n",
    "        lstm_out = parkinson_detector.drop_lstm(lstm_out, training=False)\n",
    "        concatenated = parkinson_detector.concat([cnn_flat, att_flat, lstm_out])\n",
    "        bottleneck = parkinson_detector.dense_bottleneck(concatenated)\n",
    "        final_output = parkinson_detector.dense_output(bottleneck)\n",
    "        return conv_output, final_output\n",
    "\n",
    "    # Sample selection\n",
    "    parkinson_indices = np.where(y_test == 1)[0]\n",
    "    healthy_indices = np.where(y_test == 0)[0]\n",
    "\n",
    "    selected_pd_indices = list(np.random.choice(parkinson_indices, min(num_samples, len(parkinson_indices)), replace=False))\n",
    "    selected_hc_indices = list(np.random.choice(healthy_indices, min(num_samples, len(healthy_indices)), replace=False))\n",
    "\n",
    "    print(f\"Selected {len(selected_pd_indices)} PD and {len(selected_hc_indices)} HC samples for Grad-CAM.\")\n",
    "\n",
    "    # Calculate heatmaps\n",
    "    def calculate_gradcam_heatmaps(indices):\n",
    "        heatmaps = []\n",
    "        for i in indices:\n",
    "            img = X_test[i:i+1]\n",
    "            with tf.GradientTape() as tape:\n",
    "                img_tensor = tf.cast(img, tf.float32)\n",
    "                tape.watch(img_tensor)\n",
    "                conv_outputs, preds = get_conv_and_output(img_tensor)\n",
    "                loss = preds[:, 0]\n",
    "            grads = tape.gradient(loss, conv_outputs)\n",
    "            pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
    "            conv_outputs_np = conv_outputs[0].numpy()\n",
    "            pooled_grads_np = pooled_grads.numpy()\n",
    "            heatmap = np.zeros(conv_outputs_np.shape[:-1])\n",
    "            for j in range(conv_outputs_np.shape[-1]):\n",
    "                heatmap += pooled_grads_np[j] * conv_outputs_np[:, :, j]\n",
    "            heatmap = np.maximum(heatmap, 0)\n",
    "            heatmap /= (heatmap.max() + 1e-10)\n",
    "            heatmaps.append(heatmap)\n",
    "        return heatmaps\n",
    "\n",
    "    tp_heatmaps = calculate_gradcam_heatmaps(selected_pd_indices)\n",
    "    tn_heatmaps = calculate_gradcam_heatmaps(selected_hc_indices)\n",
    "\n",
    "    avg_pd_heatmap = np.mean(tp_heatmaps, axis=0) if tp_heatmaps else np.zeros((nca_data_shape[1], nca_data_shape[2]))\n",
    "    avg_hc_heatmap = np.mean(tn_heatmaps, axis=0) if tn_heatmaps else np.zeros((nca_data_shape[1], nca_data_shape[2]))\n",
    "\n",
    "    # Resize heatmaps to match input dimensions\n",
    "    original_height, original_width = nca_data_shape[1], nca_data_shape[2]\n",
    "\n",
    "    upscaled_avg_pd_heatmap = resize(avg_pd_heatmap, (original_height, original_width),\n",
    "                                     order=3, mode='reflect', anti_aliasing=True)\n",
    "    upscaled_avg_hc_heatmap = resize(avg_hc_heatmap, (original_height, original_width),\n",
    "                                     order=3, mode='reflect', anti_aliasing=True)\n",
    "\n",
    "    # Get sample inputs for visualization\n",
    "    sample_input_pd = X_test[selected_pd_indices[0]].squeeze() if selected_pd_indices else None\n",
    "    sample_input_hc = X_test[selected_hc_indices[0]].squeeze() if selected_hc_indices else None\n",
    "\n",
    "    def normalize_for_display(img_data):\n",
    "        if img_data is None: return None\n",
    "        return (img_data - img_data.min()) / (img_data.max() - img_data.min() + 1e-10)\n",
    "\n",
    "    normalized_input_pd = normalize_for_display(sample_input_pd)\n",
    "    normalized_input_hc = normalize_for_display(sample_input_hc)\n",
    "\n",
    "    # Create comprehensive visualization\n",
    "    fig, axes = plt.subplots(1, 5, figsize=(25, 6))\n",
    "    fig.suptitle(\"Grad-CAM: NCA Model Analysis\", fontsize=18, fontweight='bold')\n",
    "\n",
    "    # PD Input\n",
    "    if normalized_input_pd is not None:\n",
    "        axes[0].imshow(normalized_input_pd, cmap='gray', aspect='auto', origin='lower')\n",
    "        axes[0].set_title(f'PD Input (NCA)\\n(Sample {selected_pd_indices[0] if selected_pd_indices else \"\"})')\n",
    "        axes[0].set_xlabel(\"NCA Columns\")\n",
    "        axes[0].set_ylabel(\"NCA Rows\")\n",
    "\n",
    "    # PD Heatmap\n",
    "    im_pd = axes[1].imshow(upscaled_avg_pd_heatmap, cmap='jet', aspect='auto', origin='lower')\n",
    "    axes[1].set_title(f'Avg. PD Attention\\n({len(selected_pd_indices)} samples)')\n",
    "    axes[1].set_xlabel(\"NCA Columns\")\n",
    "    axes[1].set_yticklabels([])\n",
    "    divider_pd = make_axes_locatable(axes[1])\n",
    "    cax_pd = divider_pd.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "    fig.colorbar(im_pd, cax=cax_pd)\n",
    "\n",
    "    # HC Input\n",
    "    if normalized_input_hc is not None:\n",
    "        axes[2].imshow(normalized_input_hc, cmap='gray', aspect='auto', origin='lower')\n",
    "        axes[2].set_title(f'HC Input (NCA)\\n(Sample {selected_hc_indices[0] if selected_hc_indices else \"\"})')\n",
    "        axes[2].set_xlabel(\"NCA Columns\")\n",
    "        axes[2].set_yticklabels([])\n",
    "\n",
    "    # HC Heatmap\n",
    "    im_hc = axes[3].imshow(upscaled_avg_hc_heatmap, cmap='jet', aspect='auto', origin='lower')\n",
    "    axes[3].set_title(f'Avg. HC Attention\\n({len(selected_hc_indices)} samples)')\n",
    "    axes[3].set_xlabel(\"NCA Columns\")\n",
    "    axes[3].set_yticklabels([])\n",
    "    divider_hc = make_axes_locatable(axes[3])\n",
    "    cax_hc = divider_hc.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "    fig.colorbar(im_hc, cax=cax_hc)\n",
    "\n",
    "    # Feature Map\n",
    "    feature_map_info = generate_nca_feature_map_info(nca_data_shape)\n",
    "    if feature_map_info:\n",
    "        legend_colors = [patch.get_facecolor() for patch in feature_map_info['legend_patches']]\n",
    "        cmap = ListedColormap(legend_colors)\n",
    "        axes[4].imshow(feature_map_info['color_mask'], cmap=cmap, aspect='auto',\n",
    "                      interpolation='nearest', origin='lower')\n",
    "        axes[4].set_title(\"NCA Feature\\nLayout\")\n",
    "        axes[4].set_xlabel(\"NCA Columns\")\n",
    "        axes[4].set_yticklabels([])\n",
    "\n",
    "        fig.legend(handles=feature_map_info['legend_patches'], loc='center left',\n",
    "                  bbox_to_anchor=(0.93, 0.5), borderaxespad=0.)\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0, 0.93, 0.93])\n",
    "\n",
    "    save_path = os.path.join(output_path, \"gradcam_nca_full_comparison.png\")\n",
    "    plt.savefig(save_path, dpi=300, bbox_inches=\"tight\")\n",
    "    plt.close(fig)\n",
    "    print(f\"✅ Saved NCA Grad-CAM comparison to {save_path}\")"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-12T18:08:32.343045Z",
     "start_time": "2025-09-12T18:08:32.307750Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def generate_nca_feature_map_info(nca_shape, original_feature_info=None):\n",
    "    \"\"\"\n",
    "    Generate feature layout information for NCA-transformed data with original feature type tracking.\n",
    "\n",
    "    Args:\n",
    "        nca_shape: Shape of NCA-transformed data (batch, height, width, channels)\n",
    "        original_feature_info: Dict containing original feature information\n",
    "    \"\"\"\n",
    "    height, width = nca_shape[1], nca_shape[2]\n",
    "\n",
    "    if original_feature_info is None:\n",
    "        # Fallback to generic NCA features\n",
    "        feature_layout = {'nca_transformed_features': height}\n",
    "        colors = plt.get_cmap('viridis', 1)\n",
    "        legend_patches = [mpatches.Patch(color=colors(0), label=f\"NCA Features ({height} rows)\")]\n",
    "        color_mask = np.zeros((height, width), dtype=int)\n",
    "    else:\n",
    "        # Create meaningful feature mapping based on original features\n",
    "        mel_contrib = original_feature_info.get('mel_spectrogram_contrib', 0)\n",
    "        mfcc_contrib = original_feature_info.get('mfcc_contrib', 0)\n",
    "        spectrogram_contrib = original_feature_info.get('spectrogram_contrib', 0)\n",
    "\n",
    "        total_contrib = mel_contrib + mfcc_contrib + spectrogram_contrib\n",
    "\n",
    "        if total_contrib > 0:\n",
    "            # Calculate proportional rows for each feature type\n",
    "            mel_rows = max(1, int((mel_contrib / total_contrib) * height))\n",
    "            mfcc_rows = max(1, int((mfcc_contrib / total_contrib) * height))\n",
    "            spectrogram_rows = height - mel_rows - mfcc_rows  # Remaining rows\n",
    "\n",
    "            feature_layout = {\n",
    "                'mel_spectrogram': mel_rows,\n",
    "                'mfcc': mfcc_rows,\n",
    "                'spectrogram': spectrogram_rows\n",
    "            }\n",
    "        else:\n",
    "            feature_layout = {'nca_transformed_features': height}\n",
    "\n",
    "        # Create color mapping\n",
    "        n_features = len(feature_layout)\n",
    "        colors = plt.get_cmap('Set3', n_features)\n",
    "\n",
    "        color_mask = np.zeros((height, width), dtype=int)\n",
    "        legend_patches = []\n",
    "\n",
    "        current_row = 0\n",
    "        for i, (feature_name, rows) in enumerate(feature_layout.items()):\n",
    "            if rows > 0:\n",
    "                color_mask[current_row:current_row + rows, :] = i\n",
    "                legend_patches.append(mpatches.Patch(color=colors(i), label=f\"{feature_name} ({rows} rows)\"))\n",
    "                current_row += rows\n",
    "\n",
    "    return {\n",
    "        'color_mask': color_mask,\n",
    "        'feature_layout': feature_layout,\n",
    "        'feature_names': list(feature_layout.keys()),\n",
    "        'colors': colors,\n",
    "        'legend_patches': legend_patches,\n",
    "        'total_rows': height\n",
    "    }\n",
    "\n",
    "def calculate_original_feature_contributions(original_shapes):\n",
    "    \"\"\"\n",
    "    Calculate how much each original feature type contributes to the flattened feature vector.\n",
    "\n",
    "    Args:\n",
    "        original_shapes: Dict with keys like 'mel_spectrogram', 'mfcc', 'spectrogram' and their shapes\n",
    "\n",
    "    Returns:\n",
    "        Dict with contribution percentages\n",
    "    \"\"\"\n",
    "    contributions = {}\n",
    "    total_features = 0\n",
    "\n",
    "    for feature_name, shape in original_shapes.items():\n",
    "        if len(shape) >= 2:  # (samples, height, width) or (samples, features)\n",
    "            feature_count = np.prod(shape[1:])  # Product of all dimensions except samples\n",
    "            contributions[f\"{feature_name}_contrib\"] = feature_count\n",
    "            total_features += feature_count\n",
    "\n",
    "    # Normalize to percentages\n",
    "    if total_features > 0:\n",
    "        for key in contributions:\n",
    "            contributions[key] = contributions[key] / total_features\n",
    "\n",
    "    return contributions\n",
    "\n",
    "def apply_nca_smote_preprocessing(X_train, y_train, X_test, n_components=None, use_smote=True, min_dim=16, original_feature_info=None):\n",
    "    \"\"\"\n",
    "    Apply NCA for dimensionality reduction followed by SMOTE for balancing.\n",
    "    Ensures minimum dimensions for CNN compatibility.\n",
    "\n",
    "    Args:\n",
    "        X_train: Training features (samples, height, width)\n",
    "        y_train: Training labels\n",
    "        X_test: Test features (samples, height, width) - ONLY TRANSFORMED, NEVER FITTED\n",
    "        n_components: Number of NCA components\n",
    "        use_smote: Whether to apply SMOTE after NCA\n",
    "        min_dim: Minimum dimension for each axis (height, width)\n",
    "        original_feature_info: Dict containing original feature information\n",
    "\n",
    "    Returns:\n",
    "        X_train_processed: Processed training features (samples, height, width, 1)\n",
    "        y_train_processed: Processed training labels (may be augmented if SMOTE used)\n",
    "        X_test_processed: Processed test features (samples, height, width, 1)\n",
    "        nca: Fitted NCA object\n",
    "        scaler: Fitted StandardScaler object\n",
    "        feature_info: Enhanced feature information for visualization\n",
    "    \"\"\"\n",
    "    print(\"\\n--- Applying NCA + SMOTE Preprocessing ---\")\n",
    "\n",
    "    # Get original shapes\n",
    "    original_train_shape = X_train.shape\n",
    "    original_test_shape = X_test.shape\n",
    "    print(f\"Original train shape: {original_train_shape}\")\n",
    "    print(f\"Original test shape: {original_test_shape}\")\n",
    "\n",
    "    # Flatten the features for NCA (samples, height*width*channels -> samples, features)\n",
    "    X_train_flat = X_train.reshape(X_train.shape[0], -1)\n",
    "    X_test_flat = X_test.reshape(X_test.shape[0], -1)\n",
    "\n",
    "    print(f\"Flattened train shape: {X_train_flat.shape}\")\n",
    "    print(f\"Flattened test shape: {X_test_flat.shape}\")\n",
    "\n",
    "    # Step 1: Standardize features (fit ONLY on training data)\n",
    "    print(\"Standardizing features...\")\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train_flat)  # FIT on training\n",
    "    X_test_scaled = scaler.transform(X_test_flat)        # ONLY TRANSFORM test\n",
    "\n",
    "    # Step 2: Apply NCA (fit ONLY on training data)\n",
    "    if n_components is None:\n",
    "        n_components = min(len(X_train) - 1, X_train_flat.shape[1])\n",
    "    else:\n",
    "        n_components = min(n_components, len(X_train) - 1, X_train_flat.shape[1])\n",
    "\n",
    "    print(f\"Applying NCA with {n_components} components...\")\n",
    "    nca = NeighborhoodComponentsAnalysis(n_components=n_components, random_state=42, max_iter=200)\n",
    "\n",
    "    X_train_nca = nca.fit_transform(X_train_scaled, y_train)  # FIT on training\n",
    "    X_test_nca = nca.transform(X_test_scaled)                 # ONLY TRANSFORM test\n",
    "\n",
    "    print(f\"NCA transformed train shape: {X_train_nca.shape}\")\n",
    "    print(f\"NCA transformed test shape: {X_test_nca.shape}\")\n",
    "\n",
    "    # Step 3: Apply SMOTE for balancing (ONLY on training data)\n",
    "    if use_smote:\n",
    "        print(\"Applying SMOTE for class balancing...\")\n",
    "        print(f\"Before SMOTE - Class distribution: {np.bincount(y_train)}\")\n",
    "\n",
    "        smote = SMOTE(random_state=42)\n",
    "        X_train_balanced, y_train_balanced = smote.fit_resample(X_train_nca, y_train)\n",
    "\n",
    "        print(f\"After SMOTE - Class distribution: {np.bincount(y_train_balanced)}\")\n",
    "        print(f\"SMOTE balanced train shape: {X_train_balanced.shape}\")\n",
    "    else:\n",
    "        X_train_balanced = X_train_nca\n",
    "        y_train_balanced = y_train\n",
    "\n",
    "    # Step 4: Calculate optimal reshape dimensions for CNN input\n",
    "    n_features = X_train_balanced.shape[1]\n",
    "\n",
    "    # Find factors to create CNN-compatible dimensions\n",
    "    height = max(min_dim, int(np.sqrt(n_features)))\n",
    "    width = max(min_dim, int(np.ceil(n_features / height)))\n",
    "\n",
    "    # Ensure minimum dimensions for CNN compatibility\n",
    "    if height < min_dim:\n",
    "        height = min_dim\n",
    "    if width < min_dim:\n",
    "        width = min_dim\n",
    "\n",
    "    # Ensure it's CNN-friendly (pad if necessary)\n",
    "    target_size = height * width\n",
    "    pad_size = max(0, target_size - n_features)\n",
    "\n",
    "    if pad_size > 0:\n",
    "        print(f\"Padding with {pad_size} zeros for CNN compatibility...\")\n",
    "        X_train_balanced = np.pad(X_train_balanced, ((0, 0), (0, pad_size)), mode='constant', constant_values=0)\n",
    "        X_test_nca = np.pad(X_test_nca, ((0, 0), (0, pad_size)), mode='constant', constant_values=0)\n",
    "    elif pad_size < 0:\n",
    "        # Truncate if we have too many features\n",
    "        print(f\"Truncating {-pad_size} features for CNN compatibility...\")\n",
    "        X_train_balanced = X_train_balanced[:, :target_size]\n",
    "        X_test_nca = X_test_nca[:, :target_size]\n",
    "\n",
    "    # Reshape to 3D for CNN (samples, height, width, channels=1)\n",
    "    X_train_final = X_train_balanced.reshape(X_train_balanced.shape[0], height, width, 1)\n",
    "    X_test_final = X_test_nca.reshape(X_test_nca.shape[0], height, width, 1)\n",
    "\n",
    "    # Enhanced feature information for visualization\n",
    "    enhanced_feature_info = original_feature_info.copy() if original_feature_info else {}\n",
    "    enhanced_feature_info.update({\n",
    "        'nca_shape': (X_train_final.shape[0], height, width, 1),\n",
    "        'nca_components': n_components,\n",
    "        'original_features': n_features,\n",
    "        'padded_features': target_size\n",
    "    })\n",
    "\n",
    "    print(f\"Final CNN-ready train shape: {X_train_final.shape}\")\n",
    "    print(f\"Final CNN-ready test shape: {X_test_final.shape}\")\n",
    "    print(\"--- NCA + SMOTE Preprocessing Complete ---\\n\")\n",
    "\n",
    "    return X_train_final, y_train_balanced, X_test_final, nca, scaler, enhanced_feature_info\n",
    "\n",
    "def run_full_shap_analysis(model, X_train, X_test, y_test, output_path, nca_data_shape, feature_info=None, samples_per_class=50, top_n=20):\n",
    "    \"\"\"\n",
    "    Run SHAP analysis with balanced sample selection for NCA-transformed data.\n",
    "    \"\"\"\n",
    "    print(\"\\n--- Running Full SHAP Analysis on NCA Data ---\")\n",
    "    os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "    feature_map_info = generate_nca_feature_map_info(nca_data_shape, feature_info)\n",
    "    legend_patches = feature_map_info['legend_patches']\n",
    "    total_rows = feature_map_info['total_rows']\n",
    "\n",
    "    # Balanced sample selection\n",
    "    healthy_indices = np.where(y_test == 0)[0]\n",
    "    parkinson_indices = np.where(y_test == 1)[0]\n",
    "    num_healthy_to_select = min(samples_per_class, len(healthy_indices))\n",
    "    num_parkinson_to_select = min(samples_per_class, len(parkinson_indices))\n",
    "\n",
    "    selected_healthy_indices = np.random.choice(healthy_indices, num_healthy_to_select, replace=False)\n",
    "    selected_parkinson_indices = np.random.choice(parkinson_indices, num_parkinson_to_select, replace=False)\n",
    "    final_indices = np.concatenate([selected_healthy_indices, selected_parkinson_indices])\n",
    "    np.random.shuffle(final_indices)\n",
    "\n",
    "    test_samples = X_test[final_indices]\n",
    "    y_true_samples = y_test[final_indices]\n",
    "\n",
    "    print(f\"Calculating SHAP values for {len(test_samples)} balanced samples...\")\n",
    "    explainer = shap.GradientExplainer(model, X_train[:50].astype(np.float32))\n",
    "    shap_values_list = []\n",
    "\n",
    "    for sample in tqdm(test_samples, desc=\"SHAP Progress\"):\n",
    "        sample_batch = np.expand_dims(sample, axis=0).astype(np.float32)\n",
    "        sv = explainer.shap_values(sample_batch)\n",
    "        if isinstance(sv, list):\n",
    "            sv = sv[0]\n",
    "\n",
    "        # Handle the shape properly - squeeze all singleton dimensions except batch\n",
    "        sv_squeezed = np.squeeze(sv)  # Remove all singleton dimensions\n",
    "\n",
    "        # Ensure we have the right shape (height, width)\n",
    "        if sv_squeezed.ndim == 3:  # (height, width, 1)\n",
    "            sv_squeezed = np.squeeze(sv_squeezed, axis=-1)  # Remove channel dimension\n",
    "        elif sv_squeezed.ndim == 1:  # Flattened\n",
    "            height, width = nca_data_shape[1], nca_data_shape[2]\n",
    "            sv_squeezed = sv_squeezed.reshape(height, width)\n",
    "\n",
    "        shap_values_list.append(sv_squeezed)\n",
    "\n",
    "    shap_values = np.array(shap_values_list)\n",
    "    print(f\"\\nSHAP values shape: {shap_values.shape}\")\n",
    "\n",
    "    # Ensure we have the right dimensions\n",
    "    if shap_values.ndim == 3:  # (samples, height, width)\n",
    "        height, width = shap_values.shape[1], shap_values.shape[2]\n",
    "    else:\n",
    "        print(f\"Unexpected SHAP values shape: {shap_values.shape}\")\n",
    "        return\n",
    "\n",
    "    actual_data_time_steps = width\n",
    "\n",
    "    # Global Top-N analysis\n",
    "    flat_shap = shap_values.reshape(shap_values.shape[0], -1)\n",
    "    mean_abs = np.mean(np.abs(flat_shap), axis=0)\n",
    "    top_idx = np.argsort(mean_abs)[::-1][:top_n]\n",
    "\n",
    "    # Fix the coordinate calculation\n",
    "    coords = [np.unravel_index(i, (height, width)) for i in top_idx]\n",
    "    labels = [f\"R{r}C{c}\" for r, c in coords]\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.bar(range(len(top_idx)), mean_abs[top_idx])\n",
    "    plt.xticks(range(len(top_idx)), labels, rotation=45, ha=\"right\")\n",
    "    plt.title(f\"Top-{top_n} Global SHAP Features (NCA transformed)\")\n",
    "    plt.xlabel(\"Row × Column\")\n",
    "    plt.ylabel(\"Mean |SHAP value|\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(output_path, \"shap_global_bar_nca.png\"), dpi=300, bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "    print(\"-> Saved 'shap_global_bar_nca.png'\")\n",
    "\n",
    "    def plot_aligned_heatmap(heatmap_data, title, filename_suffix, cmap, label, vmin=None, vmax=None):\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(14, 7))\n",
    "        ax_shap, ax_feature_map = axes[0], axes[1]\n",
    "\n",
    "        # SHAP Heatmap\n",
    "        img = ax_shap.imshow(heatmap_data, cmap=cmap, aspect='auto', interpolation='nearest', vmin=vmin, vmax=vmax)\n",
    "        ax_shap.set_title(title, fontsize=12)\n",
    "        ax_shap.set_xlabel(f\"NCA Columns ({actual_data_time_steps})\", fontsize=10)\n",
    "        ax_shap.set_ylabel(f\"NCA Rows ({total_rows})\", fontsize=10)\n",
    "\n",
    "        divider = make_axes_locatable(ax_shap)\n",
    "        cax = divider.append_axes(\"right\", size=\"5%\", pad=0.1)\n",
    "        fig.colorbar(img, cax=cax, label=label)\n",
    "\n",
    "        # Feature Map\n",
    "        ax_feature_map.imshow(feature_map_info['color_mask'], cmap=feature_map_info['colors'],\n",
    "                             aspect='auto', interpolation='nearest')\n",
    "        ax_feature_map.set_title(\"NCA Feature Map\", fontsize=12)\n",
    "        ax_feature_map.set_xlabel(f\"NCA Columns ({actual_data_time_steps})\", fontsize=10)\n",
    "        ax_feature_map.tick_params(axis='y', labelleft=False)\n",
    "\n",
    "        ax_feature_map.legend(handles=legend_patches, loc='upper left', bbox_to_anchor=(1.02, 1),\n",
    "                             borderaxespad=0., fontsize=8)\n",
    "\n",
    "        fig.suptitle(f\"NCA-SHAP Analysis: {title}\", fontsize=16, fontweight='bold')\n",
    "        plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "\n",
    "        plt.savefig(os.path.join(output_path, f\"shap_aligned_nca_{filename_suffix}.png\"), dpi=300)\n",
    "        plt.close(fig)\n",
    "        print(f\"-> Saved 'shap_aligned_nca_{filename_suffix}.png'\")\n",
    "\n",
    "    # Generate class-specific and difference maps\n",
    "    hc_mask, pd_mask = (y_true_samples == 0), (y_true_samples == 1)\n",
    "\n",
    "    if np.any(hc_mask):\n",
    "        hc_mean = shap_values[hc_mask].mean(axis=0)\n",
    "        plot_aligned_heatmap(hc_mean, \"Average SHAP - Healthy (NCA)\", \"summary_healthy\", \"bwr\", \"Mean SHAP Value\")\n",
    "    if np.any(pd_mask):\n",
    "        pd_mean = shap_values[pd_mask].mean(axis=0)\n",
    "        plot_aligned_heatmap(pd_mean, \"Average SHAP - Parkinson (NCA)\", \"summary_parkinson\", \"bwr\", \"Mean SHAP Value\")\n",
    "    if np.any(hc_mask) and np.any(pd_mask):\n",
    "        diff_map = pd_mean - hc_mean\n",
    "        max_abs_diff = np.max(np.abs(diff_map))\n",
    "        plot_aligned_heatmap(diff_map, \"SHAP Difference (PD - HC, NCA)\", \"difference\", \"seismic\", \"Δ SHAP (PD - HC)\", vmin=-max_abs_diff, vmax=max_abs_diff)\n",
    "\n",
    "    # NEW: Aligned Significance Analysis\n",
    "    print(\"\\n--- Running Aligned Significance Analysis ---\")\n",
    "    run_aligned_significance_analysis(shap_values, y_true_samples, output_path, feature_map_info, actual_data_time_steps)\n",
    "\n",
    "    print(\"\\n--- NCA-SHAP Analysis Complete ---\")\n",
    "\n",
    "def run_aligned_significance_analysis(shap_values, y_true_samples, output_path, feature_map_info, actual_data_time_steps, alpha=0.05):\n",
    "    \"\"\"\n",
    "    Run statistical significance analysis on SHAP values between classes.\n",
    "    \"\"\"\n",
    "    print(\"Computing statistical significance of SHAP differences...\")\n",
    "\n",
    "    # Separate SHAP values by class\n",
    "    hc_mask = (y_true_samples == 0)\n",
    "    pd_mask = (y_true_samples == 1)\n",
    "\n",
    "    if not np.any(hc_mask) or not np.any(pd_mask):\n",
    "        print(\"Cannot perform significance analysis: need both classes present\")\n",
    "        return\n",
    "\n",
    "    hc_shap = shap_values[hc_mask]  # (n_hc, height, width)\n",
    "    pd_shap = shap_values[pd_mask]  # (n_pd, height, width)\n",
    "\n",
    "    height, width = shap_values.shape[1], shap_values.shape[2]\n",
    "    p_values = np.zeros((height, width))\n",
    "    t_statistics = np.zeros((height, width))\n",
    "\n",
    "    # Perform t-test for each spatial location\n",
    "    for i in range(height):\n",
    "        for j in range(width):\n",
    "            hc_values = hc_shap[:, i, j]\n",
    "            pd_values = pd_shap[:, i, j]\n",
    "\n",
    "            # Perform independent t-test\n",
    "            t_stat, p_val = ttest_ind(pd_values, hc_values, equal_var=False)\n",
    "            t_statistics[i, j] = t_stat\n",
    "            p_values[i, j] = p_val\n",
    "\n",
    "    # Apply significance threshold\n",
    "    significant_mask = p_values < alpha\n",
    "\n",
    "    # Create significance-weighted difference map\n",
    "    mean_diff = pd_shap.mean(axis=0) - hc_shap.mean(axis=0)\n",
    "    significant_diff = np.where(significant_mask, mean_diff, 0)\n",
    "\n",
    "    # Calculate significance statistics\n",
    "    total_positions = height * width\n",
    "    significant_positions = np.sum(significant_mask)\n",
    "    significance_percentage = (significant_positions / total_positions) * 100\n",
    "\n",
    "    print(f\"Significant positions: {significant_positions}/{total_positions} ({significance_percentage:.1f}%)\")\n",
    "\n",
    "    # Create comprehensive significance visualization\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "    fig.suptitle(f\"Statistical Significance Analysis (α = {alpha})\", fontsize=16, fontweight='bold')\n",
    "\n",
    "    # Row 1: Raw data\n",
    "    # 1. Mean difference map\n",
    "    im1 = axes[0,0].imshow(mean_diff, cmap='seismic', aspect='auto', interpolation='nearest')\n",
    "    axes[0,0].set_title('Mean SHAP Difference\\n(PD - HC)')\n",
    "    axes[0,0].set_xlabel(f\"NCA Columns ({actual_data_time_steps})\")\n",
    "    axes[0,0].set_ylabel(\"NCA Rows\")\n",
    "    divider1 = make_axes_locatable(axes[0,0])\n",
    "    cax1 = divider1.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "    fig.colorbar(im1, cax=cax1, label=\"Δ SHAP\")\n",
    "\n",
    "    # 2. P-values map\n",
    "    im2 = axes[0,1].imshow(p_values, cmap='viridis_r', aspect='auto', interpolation='nearest', vmax=0.1)\n",
    "    axes[0,1].set_title('P-values Map\\n(darker = more significant)')\n",
    "    axes[0,1].set_xlabel(f\"NCA Columns ({actual_data_time_steps})\")\n",
    "    axes[0,1].set_yticklabels([])\n",
    "    divider2 = make_axes_locatable(axes[0,1])\n",
    "    cax2 = divider2.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "    fig.colorbar(im2, cax=cax2, label=\"p-value\")\n",
    "\n",
    "    # 3. Feature map\n",
    "    axes[0,2].imshow(feature_map_info['color_mask'], cmap=feature_map_info['colors'],\n",
    "                     aspect='auto', interpolation='nearest')\n",
    "    axes[0,2].set_title(\"Feature Layout\")\n",
    "    axes[0,2].set_xlabel(f\"NCA Columns ({actual_data_time_steps})\")\n",
    "    axes[0,2].set_yticklabels([])\n",
    "    axes[0,2].legend(handles=feature_map_info['legend_patches'], loc='upper left',\n",
    "                     bbox_to_anchor=(1.02, 1), borderaxespad=0., fontsize=8)\n",
    "\n",
    "    # Row 2: Significance analysis\n",
    "    # 4. Significance mask\n",
    "    im4 = axes[1,0].imshow(significant_mask.astype(int), cmap='RdYlBu_r', aspect='auto',\n",
    "                          interpolation='nearest', vmin=0, vmax=1)\n",
    "    axes[1,0].set_title(f'Significance Mask\\n({significance_percentage:.1f}% significant)')\n",
    "    axes[1,0].set_xlabel(f\"NCA Columns ({actual_data_time_steps})\")\n",
    "    axes[1,0].set_ylabel(\"NCA Rows\")\n",
    "    divider4 = make_axes_locatable(axes[1,0])\n",
    "    cax4 = divider4.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "    cbar4 = fig.colorbar(im4, cax=cax4, ticks=[0, 1])\n",
    "    cbar4.set_ticklabels(['Non-sig.', 'Significant'])\n",
    "\n",
    "    # 5. Significant differences only\n",
    "    max_abs_sig_diff = np.max(np.abs(significant_diff)) if np.any(significant_diff) else 1\n",
    "    im5 = axes[1,1].imshow(significant_diff, cmap='seismic', aspect='auto', interpolation='nearest',\n",
    "                          vmin=-max_abs_sig_diff, vmax=max_abs_sig_diff)\n",
    "    axes[1,1].set_title('Significant Differences Only\\n(PD - HC, masked)')\n",
    "    axes[1,1].set_xlabel(f\"NCA Columns ({actual_data_time_steps})\")\n",
    "    axes[1,1].set_yticklabels([])\n",
    "    divider5 = make_axes_locatable(axes[1,1])\n",
    "    cax5 = divider5.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "    fig.colorbar(im5, cax=cax5, label=\"Significant Δ SHAP\")\n",
    "\n",
    "    # 6. T-statistics\n",
    "    im6 = axes[1,2].imshow(t_statistics, cmap='seismic', aspect='auto', interpolation='nearest')\n",
    "    axes[1,2].set_title('T-statistics\\n(PD vs HC)')\n",
    "    axes[1,2].set_xlabel(f\"NCA Columns ({actual_data_time_steps})\")\n",
    "    axes[1,2].set_yticklabels([])\n",
    "    divider6 = make_axes_locatable(axes[1,2])\n",
    "    cax6 = divider6.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "    fig.colorbar(im6, cax=cax6, label=\"t-statistic\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Save the significance analysis\n",
    "    significance_path = os.path.join(output_path, \"shap_aligned_nca_significance.png\")\n",
    "    plt.savefig(significance_path, dpi=300, bbox_inches=\"tight\")\n",
    "    plt.close(fig)\n",
    "    print(f\"-> Saved significance analysis to '{significance_path}'\")\n",
    "\n",
    "    # Save significance statistics\n",
    "    significance_stats = {\n",
    "        'total_positions': total_positions,\n",
    "        'significant_positions': significant_positions,\n",
    "        'significance_percentage': significance_percentage,\n",
    "        'alpha_threshold': alpha,\n",
    "        'max_significant_difference': float(max_abs_sig_diff),\n",
    "        'mean_p_value': float(np.mean(p_values)),\n",
    "        'min_p_value': float(np.min(p_values))\n",
    "    }\n",
    "\n",
    "    stats_df = pd.DataFrame([significance_stats])\n",
    "    stats_path = os.path.join(output_path, \"significance_statistics.csv\")\n",
    "    stats_df.to_csv(stats_path, index=False)\n",
    "    print(f\"-> Saved significance statistics to '{stats_path}'\")\n",
    "\n",
    "def load_data(feature_file_path):\n",
    "    \"\"\"\n",
    "    Load data and return both features and original feature information for tracking.\n",
    "    \"\"\"\n",
    "    mel_spectrograms = None\n",
    "    mfccs = None\n",
    "    spectrograms = None\n",
    "    original_shapes = {}\n",
    "\n",
    "    print(f\"--- Loading data from {feature_file_path} ---\")\n",
    "    with np.load(feature_file_path) as data:\n",
    "        labels = data['labels']\n",
    "\n",
    "        if 'mel_spectrogram' in data.keys():\n",
    "            mel_spectrograms = data['mel_spectrogram']\n",
    "            original_shapes['mel_spectrogram'] = mel_spectrograms.shape\n",
    "            print(f\"Added mel_spectrogram: {mel_spectrograms.shape}\")\n",
    "\n",
    "        if 'mfcc' in data:\n",
    "            mfccs = data['mfcc']\n",
    "            original_shapes['mfcc'] = mfccs.shape\n",
    "            print(f\"Added mfcc: {mfccs.shape}\")\n",
    "\n",
    "        if 'spectrogram' in data.keys():\n",
    "            spectrograms = data['spectrogram']\n",
    "            original_shapes['spectrogram'] = spectrograms.shape\n",
    "            print(f\"Added spectrogram: {spectrograms.shape}\")\n",
    "\n",
    "        feature_arrays = []\n",
    "\n",
    "        if mel_spectrograms is not None:\n",
    "            feature_arrays.append(mel_spectrograms)\n",
    "\n",
    "        if mfccs is not None:\n",
    "            feature_arrays.append(mfccs)\n",
    "\n",
    "        if spectrograms is not None:\n",
    "            feature_arrays.append(spectrograms)\n",
    "\n",
    "        if feature_arrays:\n",
    "            X = np.concatenate(feature_arrays, axis=-1)  # concat along last axis\n",
    "            print(f\"Final concatenated shape: {X.shape}\")\n",
    "        else:\n",
    "            raise ValueError(\"No valid features found in the file!\")\n",
    "\n",
    "        # Calculate feature contributions\n",
    "        feature_contributions = calculate_original_feature_contributions(original_shapes)\n",
    "\n",
    "        return X, labels, feature_contributions\n"
   ],
   "id": "eb9276ecc55b097a",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-12T18:09:14.807317Z",
     "start_time": "2025-09-12T18:08:32.347235Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if __name__ == '__main__':\n",
    "\n",
    "    X, y, original_feature_info = load_data(FEATURES_FILE_PATH)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42, stratify=y\n",
    "    )\n",
    "    print(f\"\\nData split into training ({len(y_train)}) and testing ({len(y_test)}) sets.\")\n",
    "\n",
    "    # Apply NCA + SMOTE preprocessing with feature tracking\n",
    "    X_train_processed, y_train_processed, X_test_processed, nca_transformer, scaler, enhanced_feature_info = apply_nca_smote_preprocessing(\n",
    "        X_train, y_train, X_test, n_components=NCA_COMPONENTS, use_smote=USE_SMOTE,\n",
    "        original_feature_info=original_feature_info\n",
    "    )\n",
    "\n",
    "    # Build model with proper 3D input shape (height, width, channels)\n",
    "    model = build_model(input_shape=(X_train_processed.shape[1], X_train_processed.shape[2], X_train_processed.shape[3]))\n",
    "    model.summary()\n",
    "\n",
    "    optimizer = Adam(learning_rate=LEARNING_RATE)\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy',\n",
    "                 metrics=['accuracy', tf.keras.metrics.AUC(name='auc')])\n",
    "\n",
    "    print(\"\\n--- Starting model training with NCA+SMOTE processed data ---\")\n",
    "    history = model.fit(\n",
    "        X_train_processed, y_train_processed,\n",
    "        validation_data=(X_test_processed, y_test),\n",
    "        epochs=EPOCHS,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        callbacks=[checkpoint_cb],\n",
    "        verbose=1\n",
    "    )\n",
    "    print(\"--- Model training finished ---\")\n",
    "\n",
    "    pd.DataFrame(history.history).to_csv(HISTORY_SAVE_PATH, index_label='epoch')\n",
    "    print(f\"\\nTraining history saved to '{HISTORY_SAVE_PATH}'\")\n",
    "\n",
    "    print(\"\\n--- Start evaluating model ---\")\n",
    "    y_pred_probabilities = model.predict(X_test_processed)\n",
    "    save_metrics_to_csv(y_test, y_pred_probabilities, EVALUATION_FILE_PATH)\n",
    "\n",
    "    if os.path.exists(BEST_MODEL_PATH):\n",
    "        print(\"\\n--- Loading best saved model for explainability analysis ---\")\n",
    "        best_model = load_model(BEST_MODEL_PATH, custom_objects={'ParkinsonDetectorModel': ParkinsonDetectorModel})\n",
    "\n",
    "        # Run SHAP analysis with enhanced feature information\n",
    "        run_full_shap_analysis(model, X_train_processed, X_test_processed, y_test,\n",
    "                              SHAP_OUTPUT_PATH, X_test_processed.shape, enhanced_feature_info, 50, 20)\n",
    "\n",
    "        # Run Grad-CAM analysis with enhanced feature information\n",
    "        run_gradcam_analysis(best_model, X_test_processed, y_test, GRADCAM_OUTPUT_PATH,\n",
    "                           X_test_processed.shape, 50)\n",
    "    else:\n",
    "        print(\"\\nCould not find best model file. Skipping SHAP and Grad-CAM analysis.\")\n"
   ],
   "id": "95a9b4e7ba48537e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Loading data from D:\\Projects\\Voice\\Parkinson-s-Disease-Detector-Using-AI\\Parkinson-s-Disease-Detector-Using-AI\\1\\UAMS\\data\\features_A_DEFAULT.npz ---\n",
      "Added mel_spectrogram: (328, 30, 94)\n",
      "Added mfcc: (328, 30, 94)\n",
      "Final concatenated shape: (328, 30, 188)\n",
      "\n",
      "Data split into training (262) and testing (66) sets.\n",
      "\n",
      "--- Applying NCA + SMOTE Preprocessing ---\n",
      "Original train shape: (262, 30, 188)\n",
      "Original test shape: (66, 30, 188)\n",
      "Flattened train shape: (262, 5640)\n",
      "Flattened test shape: (66, 5640)\n",
      "Standardizing features...\n",
      "Applying NCA with 128 components...\n",
      "NCA transformed train shape: (262, 128)\n",
      "NCA transformed test shape: (66, 128)\n",
      "Applying SMOTE for class balancing...\n",
      "Before SMOTE - Class distribution: [131 131]\n",
      "After SMOTE - Class distribution: [131 131]\n",
      "SMOTE balanced train shape: (262, 128)\n",
      "Padding with 128 zeros for CNN compatibility...\n",
      "Final CNN-ready train shape: (262, 16, 16, 1)\n",
      "Final CNN-ready test shape: (66, 16, 16, 1)\n",
      "--- NCA + SMOTE Preprocessing Complete ---\n",
      "\n",
      "--- Building the model ---\n",
      "Input shape: (16, 16, 1)\n",
      "Using pool sizes: 2, 2 for input shape (16, 16, 1)\n",
      "WARNING:tensorflow:From C:\\Users\\bahar\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\core.py:232: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "Model built successfully.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1mModel: \"functional\"\u001B[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001B[1m \u001B[0m\u001B[1mLayer (type)                   \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mOutput Shape          \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m      Param #\u001B[0m\u001B[1m \u001B[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (\u001B[38;5;33mInputLayer\u001B[0m)        │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m16\u001B[0m, \u001B[38;5;34m16\u001B[0m, \u001B[38;5;34m1\u001B[0m)      │             \u001B[38;5;34m0\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ parkinson_detector_model        │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m1\u001B[0m)              │       \u001B[38;5;34m282,977\u001B[0m │\n",
       "│ (\u001B[38;5;33mParkinsonDetectorModel\u001B[0m)        │                        │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ parkinson_detector_model        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │       <span style=\"color: #00af00; text-decoration-color: #00af00\">282,977</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ParkinsonDetectorModel</span>)        │                        │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Total params: \u001B[0m\u001B[38;5;34m282,977\u001B[0m (1.08 MB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">282,977</span> (1.08 MB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Trainable params: \u001B[0m\u001B[38;5;34m282,977\u001B[0m (1.08 MB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">282,977</span> (1.08 MB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Non-trainable params: \u001B[0m\u001B[38;5;34m0\u001B[0m (0.00 B)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Starting model training with NCA+SMOTE processed data ---\n",
      "Epoch 1/30\n",
      "\u001B[1m8/9\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━\u001B[0m \u001B[1m0s\u001B[0m 17ms/step - accuracy: 0.5437 - auc: 0.5091 - loss: 2.1282\n",
      "Epoch 1: val_auc improved from None to 0.62580, saving model to D:\\Projects\\Voice\\Parkinson-s-Disease-Detector-Using-AI\\Parkinson-s-Disease-Detector-Using-AI\\1\\UAMS\\results_A_DEFAULT\\nca_cnn_lstm\\best_model.keras\n",
      "\u001B[1m9/9\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 100ms/step - accuracy: 0.5344 - auc: 0.5175 - loss: 2.0997 - val_accuracy: 0.5909 - val_auc: 0.6258 - val_loss: 1.9880\n",
      "Epoch 2/30\n",
      "\u001B[1m7/9\u001B[0m \u001B[32m━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━\u001B[0m \u001B[1m0s\u001B[0m 18ms/step - accuracy: 0.4692 - auc: 0.5664 - loss: 1.9840\n",
      "Epoch 2: val_auc improved from 0.62580 to 0.69651, saving model to D:\\Projects\\Voice\\Parkinson-s-Disease-Detector-Using-AI\\Parkinson-s-Disease-Detector-Using-AI\\1\\UAMS\\results_A_DEFAULT\\nca_cnn_lstm\\best_model.keras\n",
      "\u001B[1m9/9\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - accuracy: 0.4962 - auc: 0.5718 - loss: 1.9599 - val_accuracy: 0.6515 - val_auc: 0.6965 - val_loss: 1.8789\n",
      "Epoch 3/30\n",
      "\u001B[1m8/9\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━\u001B[0m \u001B[1m0s\u001B[0m 17ms/step - accuracy: 0.5787 - auc: 0.6796 - loss: 1.8543\n",
      "Epoch 3: val_auc did not improve from 0.69651\n",
      "\u001B[1m9/9\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.5878 - auc: 0.6397 - loss: 1.8395 - val_accuracy: 0.6212 - val_auc: 0.6965 - val_loss: 1.7737\n",
      "Epoch 4/30\n",
      "\u001B[1m9/9\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.5452 - auc: 0.5792 - loss: 1.7679\n",
      "Epoch 4: val_auc did not improve from 0.69651\n",
      "\u001B[1m9/9\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step - accuracy: 0.5305 - auc: 0.5348 - loss: 1.7611 - val_accuracy: 0.5000 - val_auc: 0.6566 - val_loss: 1.6830\n",
      "Epoch 5/30\n",
      "\u001B[1m8/9\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - accuracy: 0.4816 - auc: 0.6609 - loss: 1.6978\n",
      "Epoch 5: val_auc did not improve from 0.69651\n",
      "\u001B[1m9/9\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step - accuracy: 0.5153 - auc: 0.6152 - loss: 1.6607 - val_accuracy: 0.6061 - val_auc: 0.6359 - val_loss: 1.5924\n",
      "Epoch 6/30\n",
      "\u001B[1m9/9\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.6002 - auc: 0.6367 - loss: 1.5741\n",
      "Epoch 6: val_auc did not improve from 0.69651\n",
      "\u001B[1m9/9\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step - accuracy: 0.5954 - auc: 0.6347 - loss: 1.5588 - val_accuracy: 0.5606 - val_auc: 0.6419 - val_loss: 1.5050\n",
      "Epoch 7/30\n",
      "\u001B[1m9/9\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.6112 - auc: 0.6951 - loss: 1.4701\n",
      "Epoch 7: val_auc did not improve from 0.69651\n",
      "\u001B[1m9/9\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step - accuracy: 0.5992 - auc: 0.6714 - loss: 1.4675 - val_accuracy: 0.6061 - val_auc: 0.6873 - val_loss: 1.4189\n",
      "Epoch 8/30\n",
      "\u001B[1m9/9\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.6032 - auc: 0.6035 - loss: 1.4232\n",
      "Epoch 8: val_auc improved from 0.69651 to 0.71809, saving model to D:\\Projects\\Voice\\Parkinson-s-Disease-Detector-Using-AI\\Parkinson-s-Disease-Detector-Using-AI\\1\\UAMS\\results_A_DEFAULT\\nca_cnn_lstm\\best_model.keras\n",
      "\u001B[1m9/9\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - accuracy: 0.5534 - auc: 0.5612 - loss: 1.4221 - val_accuracy: 0.5758 - val_auc: 0.7181 - val_loss: 1.3397\n",
      "Epoch 9/30\n",
      "\u001B[1m9/9\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - accuracy: 0.6209 - auc: 0.6925 - loss: 1.3352\n",
      "Epoch 9: val_auc did not improve from 0.71809\n",
      "\u001B[1m9/9\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - accuracy: 0.6412 - auc: 0.7023 - loss: 1.3189 - val_accuracy: 0.5606 - val_auc: 0.7167 - val_loss: 1.2777\n",
      "Epoch 10/30\n",
      "\u001B[1m8/9\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - accuracy: 0.6240 - auc: 0.6764 - loss: 1.2799\n",
      "Epoch 10: val_auc did not improve from 0.71809\n",
      "\u001B[1m9/9\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step - accuracy: 0.6679 - auc: 0.7139 - loss: 1.2574 - val_accuracy: 0.5758 - val_auc: 0.7135 - val_loss: 1.2156\n",
      "Epoch 11/30\n",
      "\u001B[1m9/9\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.6723 - auc: 0.7347 - loss: 1.1928\n",
      "Epoch 11: val_auc improved from 0.71809 to 0.73691, saving model to D:\\Projects\\Voice\\Parkinson-s-Disease-Detector-Using-AI\\Parkinson-s-Disease-Detector-Using-AI\\1\\UAMS\\results_A_DEFAULT\\nca_cnn_lstm\\best_model.keras\n",
      "\u001B[1m9/9\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - accuracy: 0.6718 - auc: 0.7325 - loss: 1.1881 - val_accuracy: 0.5909 - val_auc: 0.7369 - val_loss: 1.2226\n",
      "Epoch 12/30\n",
      "\u001B[1m8/9\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.6025 - auc: 0.6298 - loss: 1.2244\n",
      "Epoch 12: val_auc did not improve from 0.73691\n",
      "\u001B[1m9/9\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step - accuracy: 0.5611 - auc: 0.6294 - loss: 1.2396 - val_accuracy: 0.5909 - val_auc: 0.6795 - val_loss: 1.1651\n",
      "Epoch 13/30\n",
      "\u001B[1m8/9\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━\u001B[0m \u001B[1m0s\u001B[0m 17ms/step - accuracy: 0.5616 - auc: 0.7027 - loss: 1.1669\n",
      "Epoch 13: val_auc improved from 0.73691 to 0.74105, saving model to D:\\Projects\\Voice\\Parkinson-s-Disease-Detector-Using-AI\\Parkinson-s-Disease-Detector-Using-AI\\1\\UAMS\\results_A_DEFAULT\\nca_cnn_lstm\\best_model.keras\n",
      "\u001B[1m9/9\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - accuracy: 0.5382 - auc: 0.7225 - loss: 1.1540 - val_accuracy: 0.6364 - val_auc: 0.7410 - val_loss: 1.1170\n",
      "Epoch 14/30\n",
      "\u001B[1m9/9\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - accuracy: 0.6604 - auc: 0.8009 - loss: 1.0700\n",
      "Epoch 14: val_auc improved from 0.74105 to 0.74564, saving model to D:\\Projects\\Voice\\Parkinson-s-Disease-Detector-Using-AI\\Parkinson-s-Disease-Detector-Using-AI\\1\\UAMS\\results_A_DEFAULT\\nca_cnn_lstm\\best_model.keras\n",
      "\u001B[1m9/9\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.6450 - auc: 0.7454 - loss: 1.0840 - val_accuracy: 0.6212 - val_auc: 0.7456 - val_loss: 1.0679\n",
      "Epoch 15/30\n",
      "\u001B[1m5/9\u001B[0m \u001B[32m━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.6966 - auc: 0.8220 - loss: 1.0323\n",
      "Epoch 15: val_auc improved from 0.74564 to 0.74793, saving model to D:\\Projects\\Voice\\Parkinson-s-Disease-Detector-Using-AI\\Parkinson-s-Disease-Detector-Using-AI\\1\\UAMS\\results_A_DEFAULT\\nca_cnn_lstm\\best_model.keras\n",
      "\u001B[1m9/9\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - accuracy: 0.6870 - auc: 0.7915 - loss: 1.0227 - val_accuracy: 0.6515 - val_auc: 0.7479 - val_loss: 1.0423\n",
      "Epoch 16/30\n",
      "\u001B[1m8/9\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - accuracy: 0.6598 - auc: 0.7471 - loss: 1.0361\n",
      "Epoch 16: val_auc did not improve from 0.74793\n",
      "\u001B[1m9/9\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step - accuracy: 0.6832 - auc: 0.7405 - loss: 1.0091 - val_accuracy: 0.6212 - val_auc: 0.7020 - val_loss: 1.0228\n",
      "Epoch 17/30\n",
      "\u001B[1m7/9\u001B[0m \u001B[32m━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━\u001B[0m \u001B[1m0s\u001B[0m 18ms/step - accuracy: 0.7209 - auc: 0.8373 - loss: 0.9415\n",
      "Epoch 17: val_auc improved from 0.74793 to 0.77732, saving model to D:\\Projects\\Voice\\Parkinson-s-Disease-Detector-Using-AI\\Parkinson-s-Disease-Detector-Using-AI\\1\\UAMS\\results_A_DEFAULT\\nca_cnn_lstm\\best_model.keras\n",
      "\u001B[1m9/9\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - accuracy: 0.7214 - auc: 0.8005 - loss: 0.9369 - val_accuracy: 0.7121 - val_auc: 0.7773 - val_loss: 0.9355\n",
      "Epoch 18/30\n",
      "\u001B[1m9/9\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.6844 - auc: 0.8184 - loss: 0.8748\n",
      "Epoch 18: val_auc improved from 0.77732 to 0.79798, saving model to D:\\Projects\\Voice\\Parkinson-s-Disease-Detector-Using-AI\\Parkinson-s-Disease-Detector-Using-AI\\1\\UAMS\\results_A_DEFAULT\\nca_cnn_lstm\\best_model.keras\n",
      "\u001B[1m9/9\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.7023 - auc: 0.8020 - loss: 0.8881 - val_accuracy: 0.7121 - val_auc: 0.7980 - val_loss: 0.8883\n",
      "Epoch 19/30\n",
      "\u001B[1m9/9\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - accuracy: 0.7980 - auc: 0.8747 - loss: 0.8170\n",
      "Epoch 19: val_auc improved from 0.79798 to 0.80624, saving model to D:\\Projects\\Voice\\Parkinson-s-Disease-Detector-Using-AI\\Parkinson-s-Disease-Detector-Using-AI\\1\\UAMS\\results_A_DEFAULT\\nca_cnn_lstm\\best_model.keras\n",
      "\u001B[1m9/9\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - accuracy: 0.7824 - auc: 0.8544 - loss: 0.8308 - val_accuracy: 0.6818 - val_auc: 0.8062 - val_loss: 0.9067\n",
      "Epoch 20/30\n",
      "\u001B[1m9/9\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.7307 - auc: 0.8259 - loss: 0.8560\n",
      "Epoch 20: val_auc improved from 0.80624 to 0.82369, saving model to D:\\Projects\\Voice\\Parkinson-s-Disease-Detector-Using-AI\\Parkinson-s-Disease-Detector-Using-AI\\1\\UAMS\\results_A_DEFAULT\\nca_cnn_lstm\\best_model.keras\n",
      "\u001B[1m9/9\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.7405 - auc: 0.8254 - loss: 0.8422 - val_accuracy: 0.7121 - val_auc: 0.8237 - val_loss: 0.8583\n",
      "Epoch 21/30\n",
      "\u001B[1m5/9\u001B[0m \u001B[32m━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.8045 - auc: 0.9162 - loss: 0.7394\n",
      "Epoch 21: val_auc improved from 0.82369 to 0.86134, saving model to D:\\Projects\\Voice\\Parkinson-s-Disease-Detector-Using-AI\\Parkinson-s-Disease-Detector-Using-AI\\1\\UAMS\\results_A_DEFAULT\\nca_cnn_lstm\\best_model.keras\n",
      "\u001B[1m9/9\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - accuracy: 0.7939 - auc: 0.8824 - loss: 0.7519 - val_accuracy: 0.6970 - val_auc: 0.8613 - val_loss: 0.8219\n",
      "Epoch 22/30\n",
      "\u001B[1m5/9\u001B[0m \u001B[32m━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - accuracy: 0.8264 - auc: 0.9146 - loss: 0.7198\n",
      "Epoch 22: val_auc did not improve from 0.86134\n",
      "\u001B[1m9/9\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - accuracy: 0.8092 - auc: 0.8898 - loss: 0.7327 - val_accuracy: 0.7576 - val_auc: 0.8512 - val_loss: 0.7961\n",
      "Epoch 23/30\n",
      "\u001B[1m9/9\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.8116 - auc: 0.9013 - loss: 0.7035\n",
      "Epoch 23: val_auc improved from 0.86134 to 0.86823, saving model to D:\\Projects\\Voice\\Parkinson-s-Disease-Detector-Using-AI\\Parkinson-s-Disease-Detector-Using-AI\\1\\UAMS\\results_A_DEFAULT\\nca_cnn_lstm\\best_model.keras\n",
      "\u001B[1m9/9\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - accuracy: 0.7824 - auc: 0.8921 - loss: 0.7231 - val_accuracy: 0.7121 - val_auc: 0.8682 - val_loss: 0.8289\n",
      "Epoch 24/30\n",
      "\u001B[1m9/9\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.7828 - auc: 0.8899 - loss: 0.7556\n",
      "Epoch 24: val_auc did not improve from 0.86823\n",
      "\u001B[1m9/9\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - accuracy: 0.8130 - auc: 0.8852 - loss: 0.7225 - val_accuracy: 0.7576 - val_auc: 0.8600 - val_loss: 0.7536\n",
      "Epoch 25/30\n",
      "\u001B[1m8/9\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.8219 - auc: 0.9315 - loss: 0.6596\n",
      "Epoch 25: val_auc did not improve from 0.86823\n",
      "\u001B[1m9/9\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step - accuracy: 0.8321 - auc: 0.9295 - loss: 0.6505 - val_accuracy: 0.7879 - val_auc: 0.8457 - val_loss: 0.7647\n",
      "Epoch 26/30\n",
      "\u001B[1m5/9\u001B[0m \u001B[32m━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.8737 - auc: 0.9571 - loss: 0.5703\n",
      "Epoch 26: val_auc did not improve from 0.86823\n",
      "\u001B[1m9/9\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - accuracy: 0.8702 - auc: 0.9485 - loss: 0.5853 - val_accuracy: 0.7576 - val_auc: 0.8177 - val_loss: 0.8402\n",
      "Epoch 27/30\n",
      "\u001B[1m8/9\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - accuracy: 0.8479 - auc: 0.9372 - loss: 0.6085\n",
      "Epoch 27: val_auc did not improve from 0.86823\n",
      "\u001B[1m9/9\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step - accuracy: 0.8511 - auc: 0.9361 - loss: 0.5954 - val_accuracy: 0.7727 - val_auc: 0.8356 - val_loss: 0.7974\n",
      "Epoch 28/30\n",
      "\u001B[1m8/9\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.8991 - auc: 0.9661 - loss: 0.5240\n",
      "Epoch 28: val_auc did not improve from 0.86823\n",
      "\u001B[1m9/9\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - accuracy: 0.8779 - auc: 0.9462 - loss: 0.5692 - val_accuracy: 0.6970 - val_auc: 0.8365 - val_loss: 0.8934\n",
      "Epoch 29/30\n",
      "\u001B[1m9/9\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.8800 - auc: 0.9480 - loss: 0.6021\n",
      "Epoch 29: val_auc did not improve from 0.86823\n",
      "\u001B[1m9/9\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step - accuracy: 0.9008 - auc: 0.9636 - loss: 0.5443 - val_accuracy: 0.7879 - val_auc: 0.8613 - val_loss: 0.7293\n",
      "Epoch 30/30\n",
      "\u001B[1m8/9\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - accuracy: 0.9221 - auc: 0.9807 - loss: 0.4851\n",
      "Epoch 30: val_auc improved from 0.86823 to 0.87328, saving model to D:\\Projects\\Voice\\Parkinson-s-Disease-Detector-Using-AI\\Parkinson-s-Disease-Detector-Using-AI\\1\\UAMS\\results_A_DEFAULT\\nca_cnn_lstm\\best_model.keras\n",
      "\u001B[1m9/9\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - accuracy: 0.9160 - auc: 0.9756 - loss: 0.4956 - val_accuracy: 0.7727 - val_auc: 0.8733 - val_loss: 0.7881\n",
      "--- Model training finished ---\n",
      "\n",
      "Training history saved to 'D:\\Projects\\Voice\\Parkinson-s-Disease-Detector-Using-AI\\Parkinson-s-Disease-Detector-Using-AI\\1\\UAMS\\results_A_DEFAULT\\nca_cnn_lstm\\history.csv'\n",
      "\n",
      "--- Start evaluating model ---\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 148ms/step\n",
      "The evaluation results is stored: D:\\Projects\\Voice\\Parkinson-s-Disease-Detector-Using-AI\\Parkinson-s-Disease-Detector-Using-AI\\1\\UAMS\\results_A_DEFAULT\\nca_cnn_lstm\\evaluation.csv\n",
      "\n",
      "--- Loading best saved model for explainability analysis ---\n",
      "Using pool sizes: 2, 2 for input shape [16, 16, 1]\n",
      "\n",
      "--- Running Full SHAP Analysis on NCA Data ---\n",
      "Calculating SHAP values for 66 balanced samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SHAP Progress:   0%|          | 0/66 [00:00<?, ?it/s]C:\\Users\\bahar\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\models\\functional.py:241: UserWarning: The structure of `inputs` doesn't match the expected structure.\n",
      "Expected: keras_tensor\n",
      "Received: inputs=['Tensor(shape=(1, 16, 16, 1))']\n",
      "  warnings.warn(msg)\n",
      "C:\\Users\\bahar\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\models\\functional.py:241: UserWarning: The structure of `inputs` doesn't match the expected structure.\n",
      "Expected: keras_tensor\n",
      "Received: inputs=['Tensor(shape=(50, 16, 16, 1))']\n",
      "  warnings.warn(msg)\n",
      "SHAP Progress: 100%|██████████| 66/66 [00:09<00:00,  6.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SHAP values shape: (66, 16, 16)\n",
      "-> Saved 'shap_global_bar_nca.png'\n",
      "-> Saved 'shap_aligned_nca_summary_healthy.png'\n",
      "-> Saved 'shap_aligned_nca_summary_parkinson.png'\n",
      "-> Saved 'shap_aligned_nca_difference.png'\n",
      "\n",
      "--- Running Aligned Significance Analysis ---\n",
      "Computing statistical significance of SHAP differences...\n",
      "Significant positions: 22/256 (8.6%)\n",
      "-> Saved significance analysis to 'D:\\Projects\\Voice\\Parkinson-s-Disease-Detector-Using-AI\\Parkinson-s-Disease-Detector-Using-AI\\1\\UAMS\\results_A_DEFAULT\\nca_cnn_lstm\\shap_analysis\\shap_aligned_nca_significance.png'\n",
      "-> Saved significance statistics to 'D:\\Projects\\Voice\\Parkinson-s-Disease-Detector-Using-AI\\Parkinson-s-Disease-Detector-Using-AI\\1\\UAMS\\results_A_DEFAULT\\nca_cnn_lstm\\shap_analysis\\significance_statistics.csv'\n",
      "\n",
      "--- NCA-SHAP Analysis Complete ---\n",
      "\n",
      "--- Running Grad-CAM Analysis with NCA Data ---\n",
      "Using last conv layer: last_conv_layer\n",
      "Selected 33 PD and 33 HC samples for Grad-CAM.\n",
      "✅ Saved NCA Grad-CAM comparison to D:\\Projects\\Voice\\Parkinson-s-Disease-Detector-Using-AI\\Parkinson-s-Disease-Detector-Using-AI\\1\\UAMS\\results_A_DEFAULT\\nca_cnn_lstm\\gradcam_analysis\\gradcam_nca_full_comparison.png\n"
     ]
    }
   ],
   "execution_count": 3
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
