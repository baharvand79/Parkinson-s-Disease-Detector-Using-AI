{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-09-11T11:17:19.249610Z",
     "start_time": "2025-09-11T11:17:10.018878Z"
    }
   },
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import (Input, Conv2D, MaxPooling2D, Dropout, Flatten,\n",
    "                                     Dense, LSTM, MultiHeadAttention, Concatenate, Reshape)\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.saving import register_keras_serializable\n",
    "\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier, NeighborhoodComponentsAnalysis\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "# =============================================================================\n",
    "# --- Configuration ---\n",
    "# =============================================================================\n",
    "# DATASET = \"MPOWER_DATASET\"\n",
    "MODE = \"ALL_VALIDS\"\n",
    "FEATURE_MODE = \"ALL\"\n",
    "MODEL_NAME = \"test\" # MODIFIED: Model name updated\n",
    "# ------------------------------------\n",
    "\n",
    "# Path Setup\n",
    "dataset = \"UAMS\"\n",
    "FEATURES_FILE_PATH = os.path.join(os.getcwd(), dataset, \"data\", f\"features_{MODE}_{FEATURE_MODE}.npz\")\n",
    "RESULTS_PATH = os.path.join(os.getcwd(), dataset, f\"results_{MODE}_{FEATURE_MODE}\")\n",
    "MODEL_PATH = os.path.join(RESULTS_PATH, MODEL_NAME)\n",
    "os.makedirs(MODEL_PATH, exist_ok=True)\n",
    "\n",
    "HISTORY_SAVE_PATH = os.path.join(MODEL_PATH, \"history.csv\")\n",
    "BEST_EXTRACTOR_PATH = os.path.join(MODEL_PATH, \"best_feature_extractor.keras\") # MODIFIED: Path name updated\n",
    "KNN_MODEL_PATH = os.path.join(MODEL_PATH, \"knn_classifier.joblib\") # NEW: Path for k-NN model\n",
    "\n",
    "# Hyperparameters\n",
    "EPOCHS = 30\n",
    "BATCH_SIZE = 32\n",
    "LEARNING_RATE = 0.001\n",
    "DROPOUT_RATE = 0.5\n",
    "L2_STRENGTH = 0.01\n"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-11T11:17:40.548799Z",
     "start_time": "2025-09-11T11:17:40.534213Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Import the correct Pipeline from imblearn\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.metrics import roc_auc_score, classification_report\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.neighbors import NeighborhoodComponentsAnalysis\n",
    "from sklearn.decomposition import PCA\n",
    "import os\n",
    "import joblib\n",
    "\n",
    "def tune_and_evaluate_knn_pipeline(X_train, y_train, X_test, y_test, results_path, model_name, dim_reduction_method='pca_nca'):\n",
    "    \"\"\"\n",
    "    Finds the best k-NN pipeline using specified dimensionality reduction methods.\n",
    "\n",
    "    Parameters:\n",
    "    - dim_reduction_method (str): 'pca', 'nca', 'pca_nca', or 'none' to specify the method.\n",
    "    \"\"\"\n",
    "    print(f\"\\n--- Tuning and Evaluating k-NN Pipeline for: {model_name} ---\")\n",
    "\n",
    "    # Define the pipeline steps and parameter distributions\n",
    "    steps = [\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('smote', SMOTE(random_state=42))\n",
    "    ]\n",
    "    param_dist = {\n",
    "        'classifier__n_neighbors': [5, 7, 9, 11, 13],\n",
    "        'classifier__weights': ['distance'],\n",
    "        'classifier__metric': ['manhattan']\n",
    "    }\n",
    "\n",
    "    if dim_reduction_method == 'pca':\n",
    "        steps.append(('pca', PCA(random_state=42)))\n",
    "        param_dist['pca__n_components'] = [10, 20, 30, 40, 50]\n",
    "    elif dim_reduction_method == 'nca':\n",
    "        steps.append(('nca', NeighborhoodComponentsAnalysis(random_state=42, max_iter=200)))\n",
    "        param_dist['nca__n_components'] = [10, 20, 30, 40, 50]\n",
    "    elif dim_reduction_method == 'pca_nca':\n",
    "        steps.append(('pca', PCA(random_state=42)))\n",
    "        steps.append(('nca', NeighborhoodComponentsAnalysis(random_state=42, max_iter=200)))\n",
    "        param_dist['pca__n_components'] = [50, 75, 100]\n",
    "        param_dist['nca__n_components'] = [10, 20, 30]\n",
    "    elif dim_reduction_method == 'none':\n",
    "        # No dimensionality reduction step is added\n",
    "        pass\n",
    "    else:\n",
    "        raise ValueError(\"Invalid dimensionality reduction method. Choose 'pca', 'nca', 'pca_nca', or 'none'.\")\n",
    "\n",
    "    # Add the final classifier to the pipeline\n",
    "    steps.append(('classifier', KNeighborsClassifier()))\n",
    "\n",
    "    # Use imblearn's Pipeline\n",
    "    pipeline = Pipeline(steps)\n",
    "\n",
    "    # Use 'roc_auc' as the scoring metric for RandomizedSearchCV\n",
    "    search = RandomizedSearchCV(pipeline, param_dist, n_iter=15, cv=5, scoring='roc_auc', n_jobs=1, random_state=42, verbose=1)\n",
    "    search.fit(X_train, y_train)\n",
    "\n",
    "    print(f\"\\n--- Results for {model_name} ---\")\n",
    "    print(f\"Best cross-validation AUC: {search.best_score_:.4f}\")\n",
    "\n",
    "    y_pred_proba = search.predict_proba(X_test)[:, 1]\n",
    "    test_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "    print(f\"Test Set AUC: {test_auc:.4f}\")\n",
    "\n",
    "    y_pred = search.predict(X_test)\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, y_pred, digits=4))\n",
    "\n",
    "    pipeline_path = os.path.join(results_path, f\"{model_name}_pipeline.joblib\")\n",
    "    joblib.dump(search.best_estimator_, pipeline_path)\n",
    "    print(f\"âœ… Best k-NN pipeline saved to: {pipeline_path}\")\n",
    "    return test_auc\n",
    "# Example usage to train and evaluate all three models\n",
    "def run_all_models(X_train, y_train, X_test, y_test, results_path):\n",
    "    # Model 1: k-NN with PCA\n",
    "    tune_and_evaluate_knn_pipeline(X_train, y_train, X_test, y_test, results_path, 'PCA_Model', 'pca')\n",
    "\n",
    "    # Model 2: k-NN with NCA\n",
    "    tune_and_evaluate_knn_pipeline(X_train, y_train, X_test, y_test, results_path, 'NCA_Model', 'nca')\n",
    "\n",
    "    # Model 3: k-NN with PCA then NCA\n",
    "    tune_and_evaluate_knn_pipeline(X_train, y_train, X_test, y_test, results_path, 'PCA_NCA_Model', 'pca_nca')\n",
    "\n",
    "    # Model 4: k-NN with no feature selection\n",
    "    tune_and_evaluate_knn_pipeline(X_train, y_train, X_test, y_test, results_path, 'No_DR_Model', 'none')"
   ],
   "id": "9699d631501cf46f",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-09-11T11:17:42.318840Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data_path = r\"UAMS/data/features_ALL_VALIDS_ALL.npz\"\n",
    "\n",
    "# Load the data, which returns a dictionary-like object\n",
    "data = np.load(data_path)\n",
    "\n",
    "# Extract the labels (y)\n",
    "y = data['labels']\n",
    "\n",
    "# Get the list of feature names\n",
    "array_names = list(data.keys())\n",
    "feature_names = [name for name in array_names if name not in ['labels', 'sex', 'age']]\n",
    "\n",
    "# Corrected: Flatten and concatenate each feature array\n",
    "feature_arrays_2d = []\n",
    "for name in feature_names:\n",
    "    feature = data[name]\n",
    "    # Check if the feature array is not already 2D\n",
    "    if feature.ndim > 1:\n",
    "        # Reshape to (n_samples, n_features), where n_features is the product of the original dimensions\n",
    "        n_samples = feature.shape[0]\n",
    "        feature_2d = feature.reshape(n_samples, -1)\n",
    "    else:\n",
    "        # If it's a 1D array, reshape it to (n_samples, 1)\n",
    "        feature_2d = feature.reshape(-1, 1)\n",
    "    feature_arrays_2d.append(feature_2d)\n",
    "\n",
    "# Concatenate all reshaped 2D arrays along the feature axis (axis=1)\n",
    "X = np.concatenate(feature_arrays_2d, axis=1)\n",
    "\n",
    "# The rest of your code remains the same\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Assuming RESULTS_PATH and MODEL_NAME are defined elsewhere\n",
    "results_path = os.path.join(RESULTS_PATH, MODEL_NAME)\n",
    "\n",
    "# Call the function to run all models\n",
    "run_all_models(X_train, y_train, X_test, y_test, results_path)"
   ],
   "id": "c4a6e024c49c1e15",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Tuning and Evaluating k-NN Pipeline for: PCA_Model ---\n",
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n"
     ]
    }
   ],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
