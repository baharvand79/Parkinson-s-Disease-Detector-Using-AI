{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-10T12:38:43.020814Z",
     "start_time": "2025-09-10T12:35:04.398755Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import (Input, Conv2D, MaxPooling2D, Dropout, Flatten,\n",
    "                                     Dense, LSTM, MultiHeadAttention, Concatenate, Reshape)\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# =============================================================================\n",
    "# --- Configuration ---\n",
    "# =============================================================================\n",
    "\n",
    "ITALIAN_DATASET = \"ITALIAN_DATASET\"\n",
    "UAMS_DATASET = \"UAMS_DATASET\"\n",
    "NEUROVOZ_DATASET = \"NEUROVOZ_DATASET\"\n",
    "MPOWER_DATASET = \"MPOWER_DATASET\"\n",
    "\n",
    "MODE_A = \"A\"\n",
    "MODE_ALL_VALIDS = \"ALL_VALIDS\"\n",
    "\n",
    "FEATURE_MODE_BASIC = \"BASIC\"\n",
    "FEATURE_MODE_ALL = \"ALL\"\n",
    "\n",
    "\n",
    "# --- SELECT YOUR CONFIGURATION HERE ---\n",
    "DATASET = ITALIAN_DATASET\n",
    "MODE = MODE_A\n",
    "FEATURE_MODE = FEATURE_MODE_ALL\n",
    "MODEL_NAME = \"cnn_att_lstm\"\n",
    "# ------------------------------------\n",
    "\n",
    "# Path Setup\n",
    "dataset = \"Italian\" if DATASET == \"ITALIAN_DATASET\" else \"Neurovoz\"\n",
    "FEATURES_FILE_PATH = os.path.join(os.getcwd(), dataset, \"data\", f\"features_{MODE}_{FEATURE_MODE}.npz\")\n",
    "MODEL_PATH = os.path.join(os.getcwd(), dataset, f\"results_{MODE}_{FEATURE_MODE}\", MODEL_NAME)\n",
    "os.makedirs(MODEL_PATH, exist_ok=True)\n",
    "\n",
    "HISTORY_SAVE_PATH = os.path.join(MODEL_PATH, \"history.csv\")\n",
    "EVALUATION_SAVE_PATH = os.path.join(MODEL_PATH, \"evaluation_results.npz\")\n",
    "CONFUSION_MATRIX_SAVE_PATH = os.path.join(MODEL_PATH, \"confusion_matrix.csv\")\n",
    "BEST_MODEL_PATH = os.path.join(MODEL_PATH, \"best_model.keras\")\n",
    "# --- NEW: Path for saving the layer features ---\n",
    "LAYER_FEATURES_PATH = os.path.join(MODEL_PATH, \"best_model_layer_features.npz\")\n",
    "\n",
    "# Hyperparameters\n",
    "EPOCHS = 30\n",
    "BATCH_SIZE = 32\n",
    "LEARNING_RATE = 0.001\n",
    "DROPOUT_RATE = 0.5\n",
    "L2_STRENGTH = 0.01\n",
    "\n",
    "# Model Checkpoint Callback\n",
    "checkpoint_cb = ModelCheckpoint(\n",
    "    BEST_MODEL_PATH,\n",
    "    monitor='val_auc',\n",
    "    mode='max',\n",
    "    save_best_only=True,\n",
    "    save_weights_only=False,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# =============================================================================\n",
    "# --- Data Loading and Preparation ---\n",
    "# =============================================================================\n",
    "\n",
    "def load_data(path: str) -> tuple:\n",
    "    \"\"\"\n",
    "    Loads features, demographics, and labels from the .npz file.\n",
    "    Combines Mel Spectrogram and MFCCs as required by the model.\n",
    "    \"\"\"\n",
    "    print(f\"--- Loading data from {path} ---\")\n",
    "    with np.load(path) as data:\n",
    "        mel_spectrograms = data['mel_spectrogram']\n",
    "        mfccs = data['mfcc']\n",
    "        labels = data['labels']\n",
    "\n",
    "        # --- MODIFIED: Load age and sex, with a fallback for older files ---\n",
    "        try:\n",
    "            ages = data['age']\n",
    "            sexes = data['sex']\n",
    "        except KeyError:\n",
    "            print(\"Warning: 'age' or 'sex' not found in .npz file. Creating placeholder NaN arrays.\")\n",
    "            ages = np.full_like(labels, np.nan)\n",
    "            sexes = np.full_like(labels, np.nan)\n",
    "\n",
    "        X = np.concatenate((mel_spectrograms, mfccs), axis=1)\n",
    "        y = labels\n",
    "\n",
    "    print(\"Data loaded successfully.\")\n",
    "    print(f\"  - Input shape (X): {X.shape}\")\n",
    "    print(f\"  - Labels shape (y): {y.shape}\")\n",
    "    print(f\"  - Ages shape: {ages.shape}\")\n",
    "    print(f\"  - Sexes shape: {sexes.shape}\")\n",
    "    return X, y, ages, sexes\n",
    "\n",
    "# =============================================================================\n",
    "# --- Model Architecture ---\n",
    "# =============================================================================\n",
    "\n",
    "def build_model(input_shape: tuple) -> Model:\n",
    "    \"\"\"Builds the hybrid CNN-Attention-LSTM model with named layers for feature extraction.\"\"\"\n",
    "    print(\"--- Building the model ---\")\n",
    "    inputs = Input(shape=input_shape)\n",
    "    reshaped_input = Reshape((input_shape[0], input_shape[1], 1))(inputs)\n",
    "\n",
    "    # --- CNN Blocks ---\n",
    "    x = Conv2D(64, kernel_size=5, activation='relu', kernel_regularizer=l2(L2_STRENGTH), padding='same')(reshaped_input)\n",
    "    x = Conv2D(64, kernel_size=5, activation='relu', kernel_regularizer=l2(L2_STRENGTH), padding='same')(x)\n",
    "    x = MaxPooling2D(pool_size=(5, 5))(x)\n",
    "    x = Dropout(DROPOUT_RATE)(x)\n",
    "    x = Conv2D(64, kernel_size=5, activation='relu', kernel_regularizer=l2(L2_STRENGTH), padding='same')(x)\n",
    "    x = Conv2D(64, kernel_size=5, activation='relu', kernel_regularizer=l2(L2_STRENGTH), padding='same')(x)\n",
    "    x = MaxPooling2D(pool_size=(5, 5), name='cnn_output')(x) # --- MODIFIED: Added name ---\n",
    "    x = Dropout(DROPOUT_RATE)(x)\n",
    "\n",
    "    cnn_output_flattened = Flatten()(x)\n",
    "    _, H, W, C = x.shape\n",
    "    sequence_output = Reshape((H * W, C))(x)\n",
    "\n",
    "    # --- Attention and LSTM ---\n",
    "    attention_output = MultiHeadAttention(num_heads=2, key_dim=64, name='attention_output')( # --- MODIFIED: Added name ---\n",
    "        query=sequence_output, key=sequence_output, value=sequence_output)\n",
    "    attention_output_flattened = Flatten()(attention_output)\n",
    "\n",
    "    lstm_sequence = LSTM(128, return_sequences=True)(sequence_output)\n",
    "    lstm_output = LSTM(128, return_sequences=False, name='lstm_output')(lstm_sequence) # --- MODIFIED: Added name ---\n",
    "    lstm_output = Dropout(DROPOUT_RATE)(lstm_output)\n",
    "\n",
    "    # --- Concatenation and Output ---\n",
    "    concatenated = Concatenate()([cnn_output_flattened, attention_output_flattened, lstm_output])\n",
    "    bottleneck = Dense(128, activation='relu', name='bottleneck_features')(concatenated) # --- MODIFIED: Added name ---\n",
    "    outputs = Dense(1, activation='sigmoid')(bottleneck)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    print(\"Model built successfully.\")\n",
    "    return model\n",
    "\n",
    "# =============================================================================\n",
    "# --- Feature Extraction and Evaluation ---\n",
    "# =============================================================================\n",
    "\n",
    "def evaluate_and_save_results(model: Model, X_test: np.ndarray, y_test: np.ndarray):\n",
    "    \"\"\"Evaluates the model and saves metrics and predictions.\"\"\"\n",
    "    print(\"\\n--- Evaluating model on test data ---\")\n",
    "    loss, accuracy, auc = model.evaluate(X_test, y_test, verbose=0)\n",
    "    print(f\"Test Accuracy: {accuracy:.4f}, Test Loss: {loss:.4f}, Test AUC: {auc:.4f}\")\n",
    "\n",
    "    y_pred_probs = model.predict(X_test).flatten()\n",
    "    y_pred_classes = (y_pred_probs > 0.5).astype(int)\n",
    "\n",
    "    print(\"\\nClassification Report:\")\n",
    "    report = classification_report(y_test, y_pred_classes, target_names=['Healthy Control', 'Parkinson Patient'])\n",
    "    print(report)\n",
    "    cm = confusion_matrix(y_test, y_pred_classes)\n",
    "    pd.DataFrame(cm, index=['True HC', 'True PD'], columns=['Pred HC', 'Pred PD']).to_csv(CONFUSION_MATRIX_SAVE_PATH)\n",
    "    print(f\"Confusion matrix saved to '{CONFUSION_MATRIX_SAVE_PATH}'\")\n",
    "\n",
    "    np.savez_compressed(EVALUATION_SAVE_PATH, y_true=y_test, y_pred_probs=y_pred_probs)\n",
    "    print(f\"Evaluation results saved to '{EVALUATION_SAVE_PATH}'\")\n",
    "\n",
    "def extract_and_save_layer_features(model_path: str, X_data: np.ndarray, y_data: np.ndarray, age_data: np.ndarray, sex_data: np.ndarray):\n",
    "    \"\"\"\n",
    "    Loads a saved model, extracts features from key layers, and saves them\n",
    "    along with labels and demographics for later analysis.\n",
    "    \"\"\"\n",
    "    print(\"\\n--- Extracting features from best model's layers ---\")\n",
    "    if not os.path.exists(model_path):\n",
    "        print(f\"Warning: Best model file not found at '{model_path}'. Skipping feature extraction.\")\n",
    "        return\n",
    "\n",
    "    # 1. Load the best saved model\n",
    "    model = load_model(model_path)\n",
    "\n",
    "    # 2. Define the layers from which to extract features\n",
    "    layer_names = ['cnn_output', 'attention_output', 'lstm_output', 'bottleneck_features']\n",
    "    layers_to_extract = [model.get_layer(name).output for name in layer_names]\n",
    "\n",
    "    # 3. Create a new feature extraction model\n",
    "    extractor_model = Model(inputs=model.inputs, outputs=layers_to_extract)\n",
    "\n",
    "    # 4. Get the feature outputs by running prediction\n",
    "    print(f\"Extracting features for {X_data.shape[0]} samples...\")\n",
    "    layer_outputs = extractor_model.predict(X_data)\n",
    "\n",
    "    # 5. Save the features, labels, and demographics to a single .npz file\n",
    "    features_to_save = {\n",
    "        'labels': y_data,\n",
    "        'age': age_data,\n",
    "        'sex': sex_data\n",
    "    }\n",
    "    for name, features in zip(layer_names, layer_outputs):\n",
    "        # Flatten the features to be 2D: (samples, feature_dim)\n",
    "        features_to_save[name] = features.reshape(features.shape[0], -1)\n",
    "\n",
    "    np.savez_compressed(LAYER_FEATURES_PATH, **features_to_save)\n",
    "    print(f\"Layer features saved successfully to '{LAYER_FEATURES_PATH}'\")\n",
    "    for name, features in features_to_save.items():\n",
    "        print(f\"  - Saved '{name}' with shape {features.shape}\")\n",
    "\n",
    "# =============================================================================\n",
    "# --- Main Execution ---\n",
    "# =============================================================================\n",
    "if __name__ == '__main__':\n",
    "    # 1. Load Data\n",
    "    X, y, age, sex = load_data(FEATURES_FILE_PATH)\n",
    "\n",
    "    # 2. Split Data (now includes age and sex)\n",
    "    X_train, X_test, y_train, y_test, age_train, age_test, sex_train, sex_test = train_test_split(\n",
    "        X, y, age, sex, test_size=0.2, random_state=42, stratify=y\n",
    "    )\n",
    "    print(f\"\\nData split into training ({len(y_train)}) and testing ({len(y_test)}) sets.\")\n",
    "\n",
    "    # 3. Build and Compile Model\n",
    "    model = build_model(input_shape=(X_train.shape[1], X_train.shape[2]))\n",
    "    model.summary()\n",
    "    optimizer = Adam(learning_rate=LEARNING_RATE)\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy', tf.keras.metrics.AUC(name='auc')])\n",
    "\n",
    "    # 4. Train Model\n",
    "    print(\"\\n--- Starting model training ---\")\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_test, y_test),\n",
    "        epochs=EPOCHS,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        callbacks=[checkpoint_cb],\n",
    "        verbose=1\n",
    "    )\n",
    "    print(\"--- Model training finished ---\")\n",
    "\n",
    "    # 5. Save Training History\n",
    "    pd.DataFrame(history.history).to_csv(HISTORY_SAVE_PATH, index_label='epoch')\n",
    "    print(f\"\\nTraining history saved to '{HISTORY_SAVE_PATH}'\")\n",
    "\n",
    "    # 6. Evaluate the final model\n",
    "    evaluate_and_save_results(model, X_test, y_test)\n",
    "\n",
    "    # 7. --- NEW: Extract features from the BEST model ---\n",
    "    extract_and_save_layer_features(BEST_MODEL_PATH, X_test, y_test, age_test, sex_test)"
   ],
   "id": "6c2f459b9708b06e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Loading data from D:\\Projects\\Voice\\Parkinson-s-Disease-Detector-Using-AI\\Parkinson-s-Disease-Detector-Using-AI\\1\\Italian\\data\\features_A_ALL.npz ---\n",
      "Data loaded successfully.\n",
      "  - Input shape (X): (440, 60, 94)\n",
      "  - Labels shape (y): (440,)\n",
      "  - Ages shape: (440,)\n",
      "  - Sexes shape: (440,)\n",
      "\n",
      "Data split into training (352) and testing (88) sets.\n",
      "--- Building the model ---\n",
      "Model built successfully.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1mModel: \"functional\"\u001B[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001B[1m \u001B[0m\u001B[1mLayer (type)       \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mOutput Shape     \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m   Param #\u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mConnected to     \u001B[0m\u001B[1m \u001B[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer         │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m60\u001B[0m, \u001B[38;5;34m94\u001B[0m)    │          \u001B[38;5;34m0\u001B[0m │ -                 │\n",
       "│ (\u001B[38;5;33mInputLayer\u001B[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ reshape (\u001B[38;5;33mReshape\u001B[0m)   │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m60\u001B[0m, \u001B[38;5;34m94\u001B[0m, \u001B[38;5;34m1\u001B[0m) │          \u001B[38;5;34m0\u001B[0m │ input_layer[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d (\u001B[38;5;33mConv2D\u001B[0m)     │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m60\u001B[0m, \u001B[38;5;34m94\u001B[0m,    │      \u001B[38;5;34m1,664\u001B[0m │ reshape[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m]     │\n",
       "│                     │ \u001B[38;5;34m64\u001B[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_1 (\u001B[38;5;33mConv2D\u001B[0m)   │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m60\u001B[0m, \u001B[38;5;34m94\u001B[0m,    │    \u001B[38;5;34m102,464\u001B[0m │ conv2d[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m]      │\n",
       "│                     │ \u001B[38;5;34m64\u001B[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d       │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m12\u001B[0m, \u001B[38;5;34m18\u001B[0m,    │          \u001B[38;5;34m0\u001B[0m │ conv2d_1[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m]    │\n",
       "│ (\u001B[38;5;33mMaxPooling2D\u001B[0m)      │ \u001B[38;5;34m64\u001B[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout (\u001B[38;5;33mDropout\u001B[0m)   │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m12\u001B[0m, \u001B[38;5;34m18\u001B[0m,    │          \u001B[38;5;34m0\u001B[0m │ max_pooling2d[\u001B[38;5;34m0\u001B[0m]… │\n",
       "│                     │ \u001B[38;5;34m64\u001B[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_2 (\u001B[38;5;33mConv2D\u001B[0m)   │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m12\u001B[0m, \u001B[38;5;34m18\u001B[0m,    │    \u001B[38;5;34m102,464\u001B[0m │ dropout[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m]     │\n",
       "│                     │ \u001B[38;5;34m64\u001B[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_3 (\u001B[38;5;33mConv2D\u001B[0m)   │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m12\u001B[0m, \u001B[38;5;34m18\u001B[0m,    │    \u001B[38;5;34m102,464\u001B[0m │ conv2d_2[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m]    │\n",
       "│                     │ \u001B[38;5;34m64\u001B[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ cnn_output          │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m2\u001B[0m, \u001B[38;5;34m3\u001B[0m, \u001B[38;5;34m64\u001B[0m)  │          \u001B[38;5;34m0\u001B[0m │ conv2d_3[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m]    │\n",
       "│ (\u001B[38;5;33mMaxPooling2D\u001B[0m)      │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_1 (\u001B[38;5;33mDropout\u001B[0m) │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m2\u001B[0m, \u001B[38;5;34m3\u001B[0m, \u001B[38;5;34m64\u001B[0m)  │          \u001B[38;5;34m0\u001B[0m │ cnn_output[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ reshape_1 (\u001B[38;5;33mReshape\u001B[0m) │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m6\u001B[0m, \u001B[38;5;34m64\u001B[0m)     │          \u001B[38;5;34m0\u001B[0m │ dropout_1[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm (\u001B[38;5;33mLSTM\u001B[0m)         │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m6\u001B[0m, \u001B[38;5;34m128\u001B[0m)    │     \u001B[38;5;34m98,816\u001B[0m │ reshape_1[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ attention_output    │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m6\u001B[0m, \u001B[38;5;34m64\u001B[0m)     │     \u001B[38;5;34m33,216\u001B[0m │ reshape_1[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m],  │\n",
       "│ (\u001B[38;5;33mMultiHeadAttentio…\u001B[0m │                   │            │ reshape_1[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m],  │\n",
       "│                     │                   │            │ reshape_1[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_output (\u001B[38;5;33mLSTM\u001B[0m)  │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m128\u001B[0m)       │    \u001B[38;5;34m131,584\u001B[0m │ lstm[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m]        │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten (\u001B[38;5;33mFlatten\u001B[0m)   │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m384\u001B[0m)       │          \u001B[38;5;34m0\u001B[0m │ dropout_1[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten_1 (\u001B[38;5;33mFlatten\u001B[0m) │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m384\u001B[0m)       │          \u001B[38;5;34m0\u001B[0m │ attention_output… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_3 (\u001B[38;5;33mDropout\u001B[0m) │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m128\u001B[0m)       │          \u001B[38;5;34m0\u001B[0m │ lstm_output[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate         │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m896\u001B[0m)       │          \u001B[38;5;34m0\u001B[0m │ flatten[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m],    │\n",
       "│ (\u001B[38;5;33mConcatenate\u001B[0m)       │                   │            │ flatten_1[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m],  │\n",
       "│                     │                   │            │ dropout_3[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ bottleneck_features │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m128\u001B[0m)       │    \u001B[38;5;34m114,816\u001B[0m │ concatenate[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m] │\n",
       "│ (\u001B[38;5;33mDense\u001B[0m)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense (\u001B[38;5;33mDense\u001B[0m)       │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m1\u001B[0m)         │        \u001B[38;5;34m129\u001B[0m │ bottleneck_featu… │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">94</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ reshape (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">94</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">94</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,664</span> │ reshape[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">94</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">102,464</span> │ conv2d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ max_pooling2d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">102,464</span> │ dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">102,464</span> │ conv2d_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ cnn_output          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ cnn_output[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ reshape_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">98,816</span> │ reshape_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ attention_output    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │     <span style=\"color: #00af00; text-decoration-color: #00af00\">33,216</span> │ reshape_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttentio…</span> │                   │            │ reshape_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
       "│                     │                   │            │ reshape_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │    <span style=\"color: #00af00; text-decoration-color: #00af00\">131,584</span> │ lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ attention_output… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lstm_output[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ flatten[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ flatten_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
       "│                     │                   │            │ dropout_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ bottleneck_features │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │    <span style=\"color: #00af00; text-decoration-color: #00af00\">114,816</span> │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │ bottleneck_featu… │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Total params: \u001B[0m\u001B[38;5;34m687,617\u001B[0m (2.62 MB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">687,617</span> (2.62 MB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Trainable params: \u001B[0m\u001B[38;5;34m687,617\u001B[0m (2.62 MB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">687,617</span> (2.62 MB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Non-trainable params: \u001B[0m\u001B[38;5;34m0\u001B[0m (0.00 B)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Starting model training ---\n",
      "Epoch 1/30\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 460ms/step - accuracy: 0.5275 - auc: 0.5494 - loss: 6.8362\n",
      "Epoch 1: val_auc improved from None to 0.73528, saving model to D:\\Projects\\Voice\\Parkinson-s-Disease-Detector-Using-AI\\Parkinson-s-Disease-Detector-Using-AI\\1\\Italian\\results_A_ALL\\cnn_att_lstm\\best_model.keras\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m15s\u001B[0m 632ms/step - accuracy: 0.5597 - auc: 0.5856 - loss: 4.6240 - val_accuracy: 0.6250 - val_auc: 0.7353 - val_loss: 2.6196\n",
      "Epoch 2/30\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 430ms/step - accuracy: 0.6233 - auc: 0.6437 - loss: 2.7091\n",
      "Epoch 2: val_auc improved from 0.73528 to 0.82696, saving model to D:\\Projects\\Voice\\Parkinson-s-Disease-Detector-Using-AI\\Parkinson-s-Disease-Detector-Using-AI\\1\\Italian\\results_A_ALL\\cnn_att_lstm\\best_model.keras\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 490ms/step - accuracy: 0.6136 - auc: 0.6919 - loss: 2.6192 - val_accuracy: 0.7386 - val_auc: 0.8270 - val_loss: 2.5214\n",
      "Epoch 3/30\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 420ms/step - accuracy: 0.6915 - auc: 0.7784 - loss: 2.5403\n",
      "Epoch 3: val_auc did not improve from 0.82696\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 461ms/step - accuracy: 0.7102 - auc: 0.7883 - loss: 2.5464 - val_accuracy: 0.7500 - val_auc: 0.8195 - val_loss: 2.4544\n",
      "Epoch 4/30\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 440ms/step - accuracy: 0.6949 - auc: 0.8020 - loss: 2.4730\n",
      "Epoch 4: val_auc improved from 0.82696 to 0.84452, saving model to D:\\Projects\\Voice\\Parkinson-s-Disease-Detector-Using-AI\\Parkinson-s-Disease-Detector-Using-AI\\1\\Italian\\results_A_ALL\\cnn_att_lstm\\best_model.keras\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 498ms/step - accuracy: 0.6989 - auc: 0.7858 - loss: 2.4494 - val_accuracy: 0.7955 - val_auc: 0.8445 - val_loss: 2.4054\n",
      "Epoch 5/30\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 462ms/step - accuracy: 0.7614 - auc: 0.8369 - loss: 2.3581\n",
      "Epoch 5: val_auc improved from 0.84452 to 0.90548, saving model to D:\\Projects\\Voice\\Parkinson-s-Disease-Detector-Using-AI\\Parkinson-s-Disease-Detector-Using-AI\\1\\Italian\\results_A_ALL\\cnn_att_lstm\\best_model.keras\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 522ms/step - accuracy: 0.7670 - auc: 0.8458 - loss: 2.3363 - val_accuracy: 0.8523 - val_auc: 0.9055 - val_loss: 2.3296\n",
      "Epoch 6/30\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 441ms/step - accuracy: 0.7671 - auc: 0.8605 - loss: 2.2919\n",
      "Epoch 6: val_auc improved from 0.90548 to 0.92743, saving model to D:\\Projects\\Voice\\Parkinson-s-Disease-Detector-Using-AI\\Parkinson-s-Disease-Detector-Using-AI\\1\\Italian\\results_A_ALL\\cnn_att_lstm\\best_model.keras\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 499ms/step - accuracy: 0.8040 - auc: 0.8978 - loss: 2.2390 - val_accuracy: 0.8523 - val_auc: 0.9274 - val_loss: 2.2253\n",
      "Epoch 7/30\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 430ms/step - accuracy: 0.8037 - auc: 0.9144 - loss: 2.1657\n",
      "Epoch 7: val_auc improved from 0.92743 to 0.94060, saving model to D:\\Projects\\Voice\\Parkinson-s-Disease-Detector-Using-AI\\Parkinson-s-Disease-Detector-Using-AI\\1\\Italian\\results_A_ALL\\cnn_att_lstm\\best_model.keras\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 486ms/step - accuracy: 0.8239 - auc: 0.9062 - loss: 2.1580 - val_accuracy: 0.8636 - val_auc: 0.9406 - val_loss: 2.0983\n",
      "Epoch 8/30\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 433ms/step - accuracy: 0.8388 - auc: 0.9287 - loss: 2.0710\n",
      "Epoch 8: val_auc improved from 0.94060 to 0.94757, saving model to D:\\Projects\\Voice\\Parkinson-s-Disease-Detector-Using-AI\\Parkinson-s-Disease-Detector-Using-AI\\1\\Italian\\results_A_ALL\\cnn_att_lstm\\best_model.keras\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 493ms/step - accuracy: 0.8409 - auc: 0.9252 - loss: 2.0661 - val_accuracy: 0.8977 - val_auc: 0.9476 - val_loss: 1.9931\n",
      "Epoch 9/30\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 450ms/step - accuracy: 0.8519 - auc: 0.9254 - loss: 2.0272\n",
      "Epoch 9: val_auc improved from 0.94757 to 0.96565, saving model to D:\\Projects\\Voice\\Parkinson-s-Disease-Detector-Using-AI\\Parkinson-s-Disease-Detector-Using-AI\\1\\Italian\\results_A_ALL\\cnn_att_lstm\\best_model.keras\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 511ms/step - accuracy: 0.8665 - auc: 0.9357 - loss: 1.9912 - val_accuracy: 0.9205 - val_auc: 0.9657 - val_loss: 1.9174\n",
      "Epoch 10/30\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 432ms/step - accuracy: 0.8621 - auc: 0.9435 - loss: 1.9366\n",
      "Epoch 10: val_auc improved from 0.96565 to 0.98192, saving model to D:\\Projects\\Voice\\Parkinson-s-Disease-Detector-Using-AI\\Parkinson-s-Disease-Detector-Using-AI\\1\\Italian\\results_A_ALL\\cnn_att_lstm\\best_model.keras\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 492ms/step - accuracy: 0.8892 - auc: 0.9580 - loss: 1.8886 - val_accuracy: 0.9091 - val_auc: 0.9819 - val_loss: 1.7897\n",
      "Epoch 11/30\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 437ms/step - accuracy: 0.9004 - auc: 0.9664 - loss: 1.8177\n",
      "Epoch 11: val_auc improved from 0.98192 to 0.98295, saving model to D:\\Projects\\Voice\\Parkinson-s-Disease-Detector-Using-AI\\Parkinson-s-Disease-Detector-Using-AI\\1\\Italian\\results_A_ALL\\cnn_att_lstm\\best_model.keras\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 499ms/step - accuracy: 0.9176 - auc: 0.9747 - loss: 1.7858 - val_accuracy: 0.9545 - val_auc: 0.9830 - val_loss: 1.7303\n",
      "Epoch 12/30\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 472ms/step - accuracy: 0.9106 - auc: 0.9772 - loss: 1.7398\n",
      "Epoch 12: val_auc improved from 0.98295 to 0.99329, saving model to D:\\Projects\\Voice\\Parkinson-s-Disease-Detector-Using-AI\\Parkinson-s-Disease-Detector-Using-AI\\1\\Italian\\results_A_ALL\\cnn_att_lstm\\best_model.keras\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 531ms/step - accuracy: 0.9205 - auc: 0.9771 - loss: 1.7263 - val_accuracy: 0.9545 - val_auc: 0.9933 - val_loss: 1.6285\n",
      "Epoch 13/30\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 496ms/step - accuracy: 0.9350 - auc: 0.9840 - loss: 1.6670\n",
      "Epoch 13: val_auc did not improve from 0.99329\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 540ms/step - accuracy: 0.9318 - auc: 0.9863 - loss: 1.6424 - val_accuracy: 0.8750 - val_auc: 0.9491 - val_loss: 1.8834\n",
      "Epoch 14/30\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 464ms/step - accuracy: 0.8927 - auc: 0.9721 - loss: 1.7229\n",
      "Epoch 14: val_auc did not improve from 0.99329\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 510ms/step - accuracy: 0.8949 - auc: 0.9641 - loss: 1.7147 - val_accuracy: 0.9318 - val_auc: 0.9742 - val_loss: 1.6384\n",
      "Epoch 15/30\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 559ms/step - accuracy: 0.8885 - auc: 0.9629 - loss: 1.6838\n",
      "Epoch 15: val_auc did not improve from 0.99329\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 608ms/step - accuracy: 0.9176 - auc: 0.9749 - loss: 1.6227 - val_accuracy: 0.9205 - val_auc: 0.9907 - val_loss: 1.5642\n",
      "Epoch 16/30\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 485ms/step - accuracy: 0.9410 - auc: 0.9804 - loss: 1.5765\n",
      "Epoch 16: val_auc did not improve from 0.99329\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 534ms/step - accuracy: 0.9347 - auc: 0.9790 - loss: 1.5668 - val_accuracy: 0.9318 - val_auc: 0.9925 - val_loss: 1.5079\n",
      "Epoch 17/30\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 566ms/step - accuracy: 0.8749 - auc: 0.9696 - loss: 1.6035\n",
      "Epoch 17: val_auc did not improve from 0.99329\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 618ms/step - accuracy: 0.9062 - auc: 0.9776 - loss: 1.5455 - val_accuracy: 0.9432 - val_auc: 0.9894 - val_loss: 1.4793\n",
      "Epoch 18/30\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 573ms/step - accuracy: 0.9454 - auc: 0.9889 - loss: 1.4500\n",
      "Epoch 18: val_auc improved from 0.99329 to 0.99458, saving model to D:\\Projects\\Voice\\Parkinson-s-Disease-Detector-Using-AI\\Parkinson-s-Disease-Detector-Using-AI\\1\\Italian\\results_A_ALL\\cnn_att_lstm\\best_model.keras\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 665ms/step - accuracy: 0.9517 - auc: 0.9881 - loss: 1.4424 - val_accuracy: 0.9318 - val_auc: 0.9946 - val_loss: 1.3882\n",
      "Epoch 19/30\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 624ms/step - accuracy: 0.9477 - auc: 0.9908 - loss: 1.4000\n",
      "Epoch 19: val_auc improved from 0.99458 to 0.99690, saving model to D:\\Projects\\Voice\\Parkinson-s-Disease-Detector-Using-AI\\Parkinson-s-Disease-Detector-Using-AI\\1\\Italian\\results_A_ALL\\cnn_att_lstm\\best_model.keras\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m8s\u001B[0m 719ms/step - accuracy: 0.9517 - auc: 0.9887 - loss: 1.3966 - val_accuracy: 0.9545 - val_auc: 0.9969 - val_loss: 1.3423\n",
      "Epoch 20/30\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 669ms/step - accuracy: 0.9738 - auc: 0.9964 - loss: 1.3172\n",
      "Epoch 20: val_auc did not improve from 0.99690\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m8s\u001B[0m 752ms/step - accuracy: 0.9744 - auc: 0.9964 - loss: 1.3127 - val_accuracy: 0.9659 - val_auc: 0.9969 - val_loss: 1.2943\n",
      "Epoch 21/30\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 553ms/step - accuracy: 0.9946 - auc: 0.9984 - loss: 1.2638\n",
      "Epoch 21: val_auc improved from 0.99690 to 0.99845, saving model to D:\\Projects\\Voice\\Parkinson-s-Disease-Detector-Using-AI\\Parkinson-s-Disease-Detector-Using-AI\\1\\Italian\\results_A_ALL\\cnn_att_lstm\\best_model.keras\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 642ms/step - accuracy: 0.9886 - auc: 0.9965 - loss: 1.2679 - val_accuracy: 0.9659 - val_auc: 0.9985 - val_loss: 1.2353\n",
      "Epoch 22/30\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 594ms/step - accuracy: 0.9774 - auc: 0.9951 - loss: 1.2478\n",
      "Epoch 22: val_auc did not improve from 0.99845\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 646ms/step - accuracy: 0.9688 - auc: 0.9922 - loss: 1.2622 - val_accuracy: 0.9205 - val_auc: 0.9982 - val_loss: 1.3300\n",
      "Epoch 23/30\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 560ms/step - accuracy: 0.9442 - auc: 0.9893 - loss: 1.2714\n",
      "Epoch 23: val_auc improved from 0.99845 to 0.99897, saving model to D:\\Projects\\Voice\\Parkinson-s-Disease-Detector-Using-AI\\Parkinson-s-Disease-Detector-Using-AI\\1\\Italian\\results_A_ALL\\cnn_att_lstm\\best_model.keras\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 656ms/step - accuracy: 0.9631 - auc: 0.9918 - loss: 1.2290 - val_accuracy: 0.9773 - val_auc: 0.9990 - val_loss: 1.1696\n",
      "Epoch 24/30\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 551ms/step - accuracy: 0.9822 - auc: 0.9975 - loss: 1.1633\n",
      "Epoch 24: val_auc did not improve from 0.99897\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 608ms/step - accuracy: 0.9801 - auc: 0.9959 - loss: 1.1647 - val_accuracy: 0.9659 - val_auc: 0.9990 - val_loss: 1.1243\n",
      "Epoch 25/30\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 547ms/step - accuracy: 0.9913 - auc: 0.9983 - loss: 1.1105\n",
      "Epoch 25: val_auc did not improve from 0.99897\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 607ms/step - accuracy: 0.9886 - auc: 0.9980 - loss: 1.1074 - val_accuracy: 0.9773 - val_auc: 0.9990 - val_loss: 1.1072\n",
      "Epoch 26/30\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 552ms/step - accuracy: 0.9858 - auc: 0.9975 - loss: 1.0852\n",
      "Epoch 26: val_auc improved from 0.99897 to 1.00000, saving model to D:\\Projects\\Voice\\Parkinson-s-Disease-Detector-Using-AI\\Parkinson-s-Disease-Detector-Using-AI\\1\\Italian\\results_A_ALL\\cnn_att_lstm\\best_model.keras\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 624ms/step - accuracy: 0.9830 - auc: 0.9970 - loss: 1.0836 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_loss: 1.0285\n",
      "Epoch 27/30\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 528ms/step - accuracy: 0.9873 - auc: 0.9991 - loss: 1.0457\n",
      "Epoch 27: val_auc did not improve from 1.00000\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 577ms/step - accuracy: 0.9830 - auc: 0.9989 - loss: 1.0442 - val_accuracy: 0.9659 - val_auc: 0.9995 - val_loss: 1.0432\n",
      "Epoch 28/30\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 564ms/step - accuracy: 0.9879 - auc: 0.9982 - loss: 1.0082\n",
      "Epoch 28: val_auc did not improve from 1.00000\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 626ms/step - accuracy: 0.9915 - auc: 0.9973 - loss: 1.0046 - val_accuracy: 0.9659 - val_auc: 0.9985 - val_loss: 1.0033\n",
      "Epoch 29/30\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 566ms/step - accuracy: 0.9916 - auc: 0.9998 - loss: 0.9583\n",
      "Epoch 29: val_auc did not improve from 1.00000\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 619ms/step - accuracy: 0.9858 - auc: 0.9994 - loss: 0.9632 - val_accuracy: 0.9659 - val_auc: 0.9985 - val_loss: 0.9886\n",
      "Epoch 30/30\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 480ms/step - accuracy: 0.9622 - auc: 0.9915 - loss: 1.0205\n",
      "Epoch 30: val_auc did not improve from 1.00000\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 534ms/step - accuracy: 0.9659 - auc: 0.9933 - loss: 1.0017 - val_accuracy: 0.9659 - val_auc: 0.9987 - val_loss: 0.9677\n",
      "--- Model training finished ---\n",
      "\n",
      "Training history saved to 'D:\\Projects\\Voice\\Parkinson-s-Disease-Detector-Using-AI\\Parkinson-s-Disease-Detector-Using-AI\\1\\Italian\\results_A_ALL\\cnn_att_lstm\\history.csv'\n",
      "\n",
      "--- Evaluating model on test data ---\n",
      "Test Accuracy: 0.9659, Test Loss: 0.9677, Test AUC: 0.9987\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 524ms/step\n",
      "\n",
      "Classification Report:\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "  Healthy Control       0.94      1.00      0.97        44\n",
      "Parkinson Patient       1.00      0.93      0.96        44\n",
      "\n",
      "         accuracy                           0.97        88\n",
      "        macro avg       0.97      0.97      0.97        88\n",
      "     weighted avg       0.97      0.97      0.97        88\n",
      "\n",
      "Confusion matrix saved to 'D:\\Projects\\Voice\\Parkinson-s-Disease-Detector-Using-AI\\Parkinson-s-Disease-Detector-Using-AI\\1\\Italian\\results_A_ALL\\cnn_att_lstm\\confusion_matrix.csv'\n",
      "Evaluation results saved to 'D:\\Projects\\Voice\\Parkinson-s-Disease-Detector-Using-AI\\Parkinson-s-Disease-Detector-Using-AI\\1\\Italian\\results_A_ALL\\cnn_att_lstm\\evaluation_results.npz'\n",
      "\n",
      "--- Extracting features from best model's layers ---\n",
      "Extracting features for 88 samples...\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 407ms/step\n",
      "Layer features saved successfully to 'D:\\Projects\\Voice\\Parkinson-s-Disease-Detector-Using-AI\\Parkinson-s-Disease-Detector-Using-AI\\1\\Italian\\results_A_ALL\\cnn_att_lstm\\best_model_layer_features.npz'\n",
      "  - Saved 'labels' with shape (88,)\n",
      "  - Saved 'age' with shape (88,)\n",
      "  - Saved 'sex' with shape (88,)\n",
      "  - Saved 'cnn_output' with shape (88, 384)\n",
      "  - Saved 'attention_output' with shape (88, 384)\n",
      "  - Saved 'lstm_output' with shape (88, 128)\n",
      "  - Saved 'bottleneck_features' with shape (88, 128)\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-10T12:38:43.581845Z",
     "start_time": "2025-09-10T12:38:43.569759Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "215d8a75ddd5ec84",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
